<!DOCTYPE html> <html lang="cn"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> OMSCS-ML课程笔记15-Game Theory | Bo Peng </title> <meta name="author" content="Bo Peng"> <meta name="description" content="博弈论"> <meta name="keywords" content="Computer Graphics, Geometry Processing"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.css" integrity="sha256-uRX+PiRTR4ysKFRCykT8HLuRCub26LgXJZym3Yeom1c=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@400..900&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="/assets/img/favicon.png?cc76d8e6f4495e4cf26b99e34f8aefe4"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://peng00bo00.github.io/blog/2021/OMSCS-ML-NOTES-15/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Bo</span> Peng </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Post </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Quick Link </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/blog/tag/formatting">Formatting Guide</a> <a class="dropdown-item " href="/blog/category/leetcode">LeetCode</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">OMSCS-ML课程笔记15-Game Theory</h1> <p class="post-meta"> Created in November 08, 2021 </p> <p class="post-tags"> <a href="/blog/2021"> <i class="fa-solid fa-calendar fa-sm"></i> 2021 </a>   ·   <a href="/blog/tag/cs7641-ml"> <i class="fa-solid fa-hashtag fa-sm"></i> CS7641-ML</a>   ·   <a href="/blog/category/omscs"> <i class="fa-solid fa-tag fa-sm"></i> OMSCS</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <blockquote class="block-preface"> <p>这个系列是Gatech OMSCS 机器学习课程(<a href="https://omscs.gatech.edu/cs-7641-machine-learning" rel="external nofollow noopener" target="_blank">CS 7641: Machine Learning</a>)的同步课程笔记。课程内容涉及监督学习、无监督学习和强化学习三个部分，本节介绍博弈论的相关内容。</p> </blockquote> <h2 id="games">Games</h2> <p><strong>博弈论(game theory)</strong>是研究个体之间如何相互合作竞争并寻找最优策略的学科。和强化学习相比，博弈论的特点是同一个系统中有多个<strong>玩家(player)</strong>，同时每个玩家都想要在博弈过程中最大化自身的收益。博弈论在现实生活中的应用已经超出了计算机科学的范畴，在金融市场、军事战略甚至社会科学中都能见到博弈论的身影。</p> <h3 id="minimax">Minimax</h3> <p>最简单的博弈只包含2个玩家，且他们之间的信息是对等的。我们称这样的博弈为<strong>2-player, zero-sum, finite, deterministic game with perfect information</strong>：</p> <ul> <li>2-player是指只有2个玩家；</li> <li>zero-sum是指博弈是零和的，两个玩家的收益之和为0；</li> <li>finite是指玩家的状态和策略都是有限的；</li> <li>deterministic是指系统是确定的，没有随机因素；</li> <li>perfect information是指两个玩家都能获得全部的信息。</li> </ul> <p>我们通过一个简单的例子来进行介绍。假设博弈过程可以通过如下图所示的树来表示，其中节点表示状态边表示玩家可选的行为。由\(A\)玩家先行从状态1中选择向左或是向右，然后\(B\)选择下一个动作，再回到\(A\)进行选择。当状态到达叶节点时游戏结束，叶节点对应的数字为玩家\(A\)的收益(由于是零和博弈，玩家\(B\)的收益为它的相反数)。玩家\(A\)的目标是最大化收益，相应地玩家\(B\)的目标是最小化收益。</p> <div align="center"> <img src="https://i.imgur.com/zCx3SnZ.png" width="40%"> </div> <p>根据玩家\(A\)和玩家\(B\)所有可能的行为，我们可以利用一个矩阵来表示整个博弈过程的所有可能结果，如下图所示：</p> <div align="center"> <img src="https://i.imgur.com/LdhuXXd.png" width="30%"> </div> <p>矩阵的每一行表示玩家\(A\)采取的行为(策略)，每一列表示玩家\(B\)采取的行为(策略)；矩阵中的每个元素表示玩家\(A\)和玩家\(B\)的行为所导致的最终收益。对于玩家\(A\)来说，无论他做出什么样的选择玩家\(B\)都会试图最小化收益，因此\(A\)的最优策略是选择第2行；类似地，对玩家\(B\)而言，玩家\(A\)会试图最大化每一列的数字，因此玩家\(B\)的最优策略是选择第2列。</p> <p>上文所述的过程实际上就是minimax算法。我们假设自身是玩家\(A\)，我们需要在玩家\(B\)最小化收益的策略中选择收益最大的那个策略，该策略即为最优策略。实际上Von Neumann证明了对于2-player, zero-sum, finite, deterministic game with perfect information，每个玩家都存在最优策略且他们的按照最优策略行动的话博弈过程的解是确定的，即minimax=maximin。</p> <h3 id="relaxation-non-determinism">Relaxation: Non-Determinism</h3> <p>接下来我们放松一下系统的限制，假设系统存在随机性。以下图为例，当系统状态到达方块的位置时我们可能会依据概率得到不同的收益：</p> <div align="center"> <img src="https://i.imgur.com/grhs70u.png" width="40%"> </div> <p>在这种情况下我们只需要用收益的期望来代替原本的收益即可，这样就可以得到这个博弈过程的矩阵表示：</p> <div align="center"> <img src="https://i.imgur.com/AkP40b6.png" width="20%"> </div> <h3 id="relaxation-hidden-information">Relaxation: Hidden Information</h3> <p>我们进一步放松对系统的限制，假设现在玩家不再具有全部的信息。这里我们还是用一个例子进行说明：假设玩家\(A\)在开局会得到红色或是黑色的牌且这张牌只有他自己可见。如果\(A\)开始获得的是红色的牌则\(A\)可以选择<code class="language-plaintext highlighter-rouge">hold</code>或是<code class="language-plaintext highlighter-rouge">resign</code>，如果是<code class="language-plaintext highlighter-rouge">hold</code>收益由\(B\)的行为来决定，而如果\(A\)选择<code class="language-plaintext highlighter-rouge">resign</code>则会获得-20的收益。类似地，如果\(A\)开始获得的是黑色的牌则他必须选择<code class="language-plaintext highlighter-rouge">hold</code>，最终的收益仍然由\(B\)的行为来决定。整个博弈过程可以利用下图所示的树来表示：</p> <div align="center"> <img src="https://i.imgur.com/ebYkGCF.png" width="40%"> </div> <p>我们同样利用收益的期望来计算不同策略的收益，从而得到收益矩阵如下所示：</p> <div align="center"> <img src="https://i.imgur.com/FfXI2eN.png" width="30%"> </div> <p>此时从\(A\)的角度上看他无论选择<code class="language-plaintext highlighter-rouge">hold</code>还是<code class="language-plaintext highlighter-rouge">resign</code>都会得到-5的收益，但从\(B\)的角度上看他会选择<code class="language-plaintext highlighter-rouge">see</code>从而得到5的收益。此时\(A\)和\(B\)按照最优策略行动会得到不同的解，这说明由于隐藏信息的存在会导致minimax \(\neq\) maximin。</p> <p>实际上如果玩家\(B\)知道\(A\)的行为模式的话仍然可以保证minimax=maximin。假设当\(A\)手上的是红牌的时候他会选择<code class="language-plaintext highlighter-rouge">resign</code>而且\(B\)也知道这点，那么当\(A\)选择了<code class="language-plaintext highlighter-rouge">hold</code>时\(B\)一定会选择<code class="language-plaintext highlighter-rouge">resign</code>从而最小化收益。</p> <h3 id="mixed-strategies">Mixed Strategies</h3> <p>所谓的mixed strategy是指关于关于策略的分布。我们假设\(A\)会以\(P\)的概率选择<code class="language-plaintext highlighter-rouge">hold</code>这个行为，同时假设\(B\)永远会选择<code class="language-plaintext highlighter-rouge">resign</code>，则当前策略下\(A\)的收益为：</p> \[\begin{aligned} \mathbb{E}[\text{profit}] &amp;= (0.5 \times 10) + (0.5 \times ((P \times 10) + ((1-P) \times (-20)))) \\ &amp;= 15 P - 5 \end{aligned}\] <p>类似地，如果\(B\)永远会选择<code class="language-plaintext highlighter-rouge">see</code>则\(A\)的收益为：</p> \[\begin{aligned} \mathbb{E}[\text{profit}] &amp;= (0.5 \times 30) + (0.5 \times ((P \times -40) + ((1-P) \times -20))) \\ &amp;= -10 P + 5 \end{aligned}\] <p>接下来我们把这两种情况下\(A\)的收益函数画在一张图上，得到它们的交点\(P=0.4\)。这个点表示当\(P\)取0.4时，无论\(B\)采取什么样的策略(pure strategy或者mixed strategy)\(A\)获得的期望收益都是相同的。但需要注意的是这一点并不意味着最优概率或是最优收益。</p> <div align="center"> <img src="https://i.imgur.com/qsrX1jm.png" width="40%"> </div> <h3 id="prisoners-dilemma">Prisoner’s Dilemma</h3> <p>接下来我们再去掉零和博弈的约束，然后介绍著名的<strong>囚徒困境(prisoner’s dilemma)</strong>：</p> <ul> <li>假设有两个囚犯分开接受审讯；</li> <li>每个囚徒可以选择和对方合作(cooperate)或是向警方招供(snitch)；</li> <li>如果两名囚犯都保持和对方合作的话每个人获得1年的刑期；</li> <li>如果两名囚犯都招供的话每个人获得6年的刑期；</li> <li>如果一名囚犯招供而另一名囚犯选择合作，则招供的可以免罪而选择合作的获得9年刑期。</li> </ul> <p>整个博弈过程的收益可以用如下所示的矩阵来表示：</p> <div align="center"> <img src="https://i.imgur.com/GaABC13.png" width="40%"> </div> <p>对于每一名囚犯来说他的最优策略都是选择招供，这是因为此时无论另一名囚犯如何选择他的刑期都是最短的。这种策略保证无论其它人如何选择自身的收益都是最大，因此这样的策略也被称为<strong>支配策略(dominant strategy)</strong>。但在这种情况下两个人都会获得6年的刑期，而如果两个人都选择合作的话每个人只有1年的刑期。换句话说每名囚犯的最优策略并不会导致总体的最优，要想达到总体最优每名囚犯的策略都依赖于另一名囚犯的策略。</p> <h3 id="nash-equilibrium">Nash Equilibrium</h3> <p>囚徒困境对于多名玩家的情况同样成立。假设有\(n\)名玩家，每名玩家可行的策略为集合\(s_i\)，我们称策略\(s_1^* \in s_1, s_2^* \in s_2, ..., s_n^* \in s_n\)达到了<strong>Nash均衡(Nash equilibrium)</strong>当且仅当对每名玩家有：</p> \[s_i^* = \arg \max_{s_i} U_i(s_1^*, ..., s_i, ..., s_n^*)\] <p>更直观来说，当系统达到Nash均衡时每个玩家都不会再试图改变自身的策略。回到囚徒困境的例子中，不难发现两名囚犯都选择招供就达到了Nash均衡，对于每个囚犯来说如果他选择了沉默都会增加自身的刑期。类似地可以证明其它的情况都不是Nash均衡。</p> <p>Nash均衡有很多优秀的性质，比如说我们可以不断地删除所有可能的<strong>被支配策略(strictly dominated strategies)</strong>，而Nash均衡总是会保留下来。更重要的是对于有限玩家和有限策略的博弈，至少存在一个Nash均衡点。</p> <h2 id="repeated-games">Repeated Games</h2> <p>接下来我们假设两名囚犯会进行多轮博弈，同时在每轮博弈中有\(\gamma\)的概率终止后续的过程。后面我们会看到在这样的情况下博弈过程与MDP后有非常多的相似之处。</p> <h3 id="tit-for-tat">Tit-for-Tat</h3> <p>假设其中一名囚犯可以采取以牙还牙的策略(tit-for-tat)，即他会在博弈一开始选择合作，如果另一名囚犯选择告密的话就会进行同等的报复。具体来说，此时这名囚犯的行为取决于另一名囚犯：</p> <ul> <li>如果另一名囚犯选择一直合作则他们会一直合作下去；</li> <li>如果另一名囚犯选择一直告密则他们会一直相互告密；</li> <li>如果另一名囚犯选择了一样的tit-for-tat策略，他们会一直合作下去；</li> <li>如果另一名囚犯选择告密、合作、告密这样的策略，则这名囚犯会选择相反的行为。</li> </ul> <p>在这样的策略下另一名囚犯的效用取决于博弈终止的概率\(\gamma\)。当他选择一直合作或是一直告密，则效用可以表示为：</p> \[U(\text{always cooperate}) = -\frac{1}{1 - \gamma}\] \[U(\text{always snitch}) = -\frac{6 \gamma}{1 - \gamma}\] <p>上式说明当\(\gamma\)接近于0时应该选择告密，而当\(\gamma\)接近于1时应该选择合作。实际上此时这名囚犯的效用可以建模为下图表示的MDP：</p> <div align="center"> <img src="https://i.imgur.com/3cluhov.png" width="40%"> </div> <p>因此我们可以通过求解这个MDP来获得最优策略。</p> <h3 id="folk-theorem">Folk Theorem</h3> <p>不难发现当两名囚犯都选择了相互告密或是tit-for-tat策略时就达到了Nash均衡，更重要的是tit-for-tat策略会使双方达成相互合作的局面。换句话说当存在对等报复的情况时合作是可以实现的(<strong>in repeated games, the possibility of retailiation opens the door for cooperation</strong>)。</p> <p>要严格的表述这种情形我们需要引入一些相关的概念。首先是<strong>feasible payoff</strong>，它是极端情况下payoff构成的凸包。然后是<strong>minmax profile</strong>，它是每名玩家对抗恶意攻击(malicious adversary)时所能得到的一对payoff。因此我们可以把整个博弈过程转换为一个零和博弈。</p> <p>博弈论的<strong>folk theorem</strong>指出：</p> <blockquote> <p>Any feasible payoff profile that strictly dominated the minmax profile can be realized as a Nash equilibrium payoff profile, with a sufficiently large discount factor.</p> </blockquote> <h3 id="pavlovs-strategy">Pavlov’s Strategy</h3> <p>接下来我们考虑另一种策略：在一开始选择合作，如果另一名囚犯选择告密的话就将行为改为告密。然后对他进行报复，每次选择和另一名囚犯相反的行为直到自身的状态回到合作。这种策略称为<strong>Pavlov’s strategy</strong>，可以用下图所示的MDP来表示：</p> <div align="center"> <img src="https://i.imgur.com/7yHcsua.png" width="40%"> </div> <p>Pavlov’s strategy同样达成了Nash均衡。它的另一个特点是如果两名囚犯都采取Pavlov’s strategy，那么无论他们的初始状态如何，最终都会选择相互合作。</p> <p>最后我们介绍一下<strong>computational folk theorem</strong>：</p> <blockquote> <p>You can build a Pavlov-like machine for any game and construct a subgame perfect Nash equilibrium in polynomial time.</p> </blockquote> <h2 id="stochastic-games-and-multiagent-rl">Stochastic Games and Multiagent RL</h2> <h3 id="generalization">Generalization</h3> <p>接下来我们把强化学习的相关概念拓展到多智能体上。假设我们有两个智能体\(a\)和\(b\)，整个系统包括：</p> <ul> <li>状态\(s\)，同时包括两个智能体的状态；</li> <li>行为\(A_i\)，每个智能体都有各自的行为；</li> <li>状态转移\(T(s, (a, b), s')\)由系统状态以及两个智能体的行为共同决定；</li> <li>奖励函数\(R_1(s, (a, b))\)和\(R_2(s, (a, b))\)，每个智能体都有各自的奖励函数；</li> <li>折扣系数\(\gamma\)由整个系统共享。</li> </ul> <p>这样定义的系统称为<strong>generalization of MDPs</strong>。</p> <h3 id="solving-stochastic-games">Solving Stochastic Games</h3> <p>对于多智能体的情况我们同样可以建立Bellman方程：</p> \[Q_i^* (s, (a, b)) = R_i (s, (a, b)) + \gamma \sum_{s'} \bigg[ T(s, (a, b), s') \cdot \max_{a', b'} Q_i^* (s', (a', b')) \bigg]\] <p>如果是零和博弈则可以理解利用\(\text{minimax}\)来代替\(\max\)：</p> \[Q_i^* (s, (a, b)) = R_i (s, (a, b)) + \gamma \sum_{s'} \bigg[ T(s, (a, b), s') \cdot \underset{a', b'}{\text{minimax}} \ Q_i^* (s', (a', b')) \bigg]\] <p>我们同样可以利用Q-learning的方式来进行更新：</p> \[Q_i (s, (a, b)) = (1 - \alpha) \cdot Q_i (s, (a, b)) + \alpha \bigg[ r_i + \gamma \cdot \underset{a', b'}{\text{minimax}} \ Q_i (s', (a', b')) \bigg]\] <p>上式称为<strong>minimax-Q</strong>。</p> <p>对于更一般的非零和博弈的情况我们需要使用Nash均衡来取代\(\text{minimax}\)，对应的Bellman方程和Q-learning算法为：</p> \[Q_i^* (s, (a, b)) = R_i (s, (a, b)) + \gamma \sum_{s'} \bigg[ T(s, (a, b), s') \cdot \underset{a', b'}{\text{Nash}} \ Q_i^* (s', (a', b')) \bigg]\] \[Q_i (s, (a, b)) = (1 - \alpha) \cdot Q_i (s, (a, b)) + \alpha \bigg[ r_i + \gamma \cdot \underset{a', b'}{\text{Nash}} \ Q_i (s', (a', b')) \bigg]\] <p>这个算法称为Nash-Q。需要注意的是由于Nash均衡的存在，Nash-Q可能不会收敛(存在多个Nash均衡)而且每个智能体的策略是相互依赖的，这些问题导致直接求解Nash-Q是非常困难的。</p> <h2 id="reference">Reference</h2> <ul> <li><a href="https://en.wikipedia.org/wiki/Minimax" rel="external nofollow noopener" target="_blank">Wikipedia: Minimax</a></li> <li><a href="https://en.wikipedia.org/wiki/Minimax_theorem" rel="external nofollow noopener" target="_blank">Wikipedia: Minimax theorem</a></li> <li><a href="https://en.wikipedia.org/wiki/Prisoner%27s_dilemma" rel="external nofollow noopener" target="_blank">Wikipedia: Prisoner’s dilemma</a></li> <li><a href="https://en.wikipedia.org/wiki/Nash_equilibrium" rel="external nofollow noopener" target="_blank">Wikipedia: Nash equilibrium</a></li> <li><a href="https://en.wikipedia.org/wiki/Folk_theorem_(game_theory)" rel="external nofollow noopener" target="_blank">Wikipedia: Folk theorem (game theory)</a></li> </ul> </div> </article> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Bo Peng. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script defer src="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.js" integrity="sha256-4rppopQE9POKfukn2kEvhJ9Um25Cf6+IDVkARD0xh78=" crossorigin="anonymous"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-post",title:"Post",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-projects",title:"Projects",description:"A growing collection of my projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-cv",title:"CV",description:"\u4e2a\u4eba\u7b80\u5386",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"dropdown-formatting-guide",title:"Formatting Guide",description:"",section:"Dropdown",handler:()=>{window.location.href="/blog/"}},{id:"dropdown-leetcode",title:"LeetCode",description:"",section:"Dropdown",handler:()=>{window.location.href="/blog/"}},{id:"post-games001\u8bfe\u7a0b\u7b14\u8bb014-\u6df1\u5ea6\u5b66\u4e60",title:"GAMES001\u8bfe\u7a0b\u7b14\u8bb014-\u6df1\u5ea6\u5b66\u4e60",description:"\u751f\u6210\u5f0f\u6a21\u578b\u80cc\u540e\u7684\u6570\u5b66\u77e5\u8bc6",section:"Posts",handler:()=>{window.location.href="/blog/2024/GAMES001-NOTES-14/"}},{id:"post-games001\u8bfe\u7a0b\u7b14\u8bb013-\u4f18\u5316\u57fa\u7840",title:"GAMES001\u8bfe\u7a0b\u7b14\u8bb013-\u4f18\u5316\u57fa\u7840",description:"\u56fe\u5f62\u5b66\u4e2d\u5e38\u7528\u7684\u4f18\u5316\u65b9\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2024/GAMES001-NOTES-13/"}},{id:"post-games001\u8bfe\u7a0b\u7b14\u8bb012-\u7ebf\u6027\u7cfb\u7edf",title:"GAMES001\u8bfe\u7a0b\u7b14\u8bb012-\u7ebf\u6027\u7cfb\u7edf",description:"\u6c42\u89e3\u7ebf\u6027\u7cfb\u7edf\u7684\u76f8\u5173\u6280\u672f",section:"Posts",handler:()=>{window.location.href="/blog/2024/GAMES001-NOTES-12/"}},{id:"post-\u5fae\u5206\u51e0\u4f55\u7b14\u8bb007-\u6d3b\u52a8\u6807\u67b6\u548c\u5916\u5fae\u5206\u6cd5",title:"\u5fae\u5206\u51e0\u4f55\u7b14\u8bb007-\u6d3b\u52a8\u6807\u67b6\u548c\u5916\u5fae\u5206\u6cd5",description:"\u5fae\u5206\u51e0\u4f55\u4e2d\u7684\u5916\u5fae\u5206\u65b9\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2024/DifferentialGeometry-NOTES-07/"}},{id:"post-games001\u8bfe\u7a0b\u7b14\u8bb011-\u5fae\u5206\u65b9\u7a0b",title:"GAMES001\u8bfe\u7a0b\u7b14\u8bb011-\u5fae\u5206\u65b9\u7a0b",description:"\u5fae\u5206\u65b9\u7a0b\u7684\u6c42\u89e3\u65b9\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2024/GAMES001-NOTES-11/"}},{id:"post-games001\u8bfe\u7a0b\u7b14\u8bb010-\u53e4\u5178\u5fae\u5206\u51e0\u4f55",title:"GAMES001\u8bfe\u7a0b\u7b14\u8bb010-\u53e4\u5178\u5fae\u5206\u51e0\u4f55",description:"\u53e4\u5178\u5fae\u5206\u51e0\u4f55\u7684\u57fa\u672c\u77e5\u8bc6",section:"Posts",handler:()=>{window.location.href="/blog/2024/GAMES001-NOTES-10/"}},{id:"post-games001\u8bfe\u7a0b\u7b14\u8bb009-\u573a\u8bba\u521d\u6b65",title:"GAMES001\u8bfe\u7a0b\u7b14\u8bb009-\u573a\u8bba\u521d\u6b65",description:"\u573a\u8bba\u7684\u57fa\u672c\u77e5\u8bc6",section:"Posts",handler:()=>{window.location.href="/blog/2024/GAMES001-NOTES-09/"}},{id:"post-games001\u8bfe\u7a0b\u7b14\u8bb008-\u6982\u7387\u8bbaii",title:"GAMES001\u8bfe\u7a0b\u7b14\u8bb008-\u6982\u7387\u8bbaII",description:"\u6982\u7387\u8bba\u5728\u56fe\u5f62\u5b66\u4e2d\u7684\u5e94\u7528",section:"Posts",handler:()=>{window.location.href="/blog/2024/GAMES001-NOTES-08/"}},{id:"post-\u5fae\u5206\u51e0\u4f55\u7b14\u8bb006-\u6d4b\u5730\u66f2\u7387\u548c\u6d4b\u5730\u7ebf",title:"\u5fae\u5206\u51e0\u4f55\u7b14\u8bb006-\u6d4b\u5730\u66f2\u7387\u548c\u6d4b\u5730\u7ebf",description:"\u66f2\u9762\u7684\u5185\u8574\u51e0\u4f55",section:"Posts",handler:()=>{window.location.href="/blog/2024/DifferentialGeometry-NOTES-06/"}},{id:"post-a-post-with-tabs",title:"a post with tabs",description:"this is what included tabs in a post could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/tabs/"}},{id:"post-games001\u8bfe\u7a0b\u7b14\u8bb007-\u6982\u7387\u8bbai",title:"GAMES001\u8bfe\u7a0b\u7b14\u8bb007-\u6982\u7387\u8bbaI",description:"\u6982\u7387\u8bba\u57fa\u7840\u77e5\u8bc6",section:"Posts",handler:()=>{window.location.href="/blog/2024/GAMES001-NOTES-07/"}},{id:"post-a-post-with-typograms",title:"a post with typograms",description:"this is what included typograms code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/typograms/"}},{id:"post-a-post-that-can-be-cited",title:"a post that can be cited",description:"this is what a post that can be cited looks like",section:"Posts",handler:()=>{window.location.href="/blog/2024/post-citation/"}},{id:"post-games001\u8bfe\u7a0b\u7b14\u8bb006-\u5085\u91cc\u53f6\u53d8\u6362\u4e0e\u7403\u8c10\u51fd\u6570",title:"GAMES001\u8bfe\u7a0b\u7b14\u8bb006-\u5085\u91cc\u53f6\u53d8\u6362\u4e0e\u7403\u8c10\u51fd\u6570",description:"\u8c31\u53d8\u6362\u4e0e\u7403\u8c10\u51fd\u6570\u76f8\u5173\u77e5\u8bc6",section:"Posts",handler:()=>{window.location.href="/blog/2024/GAMES001-NOTES-06/"}},{id:"post-a-post-with-pseudo-code",title:"a post with pseudo code",description:"this is what included pseudo code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/pseudocode/"}},{id:"post-games001\u8bfe\u7a0b\u7b14\u8bb005-\u63d2\u503c-amp-\u62df\u5408",title:"GAMES001\u8bfe\u7a0b\u7b14\u8bb005-\u63d2\u503c&\u62df\u5408",description:"\u51fd\u6570\u63d2\u503c\u4e0e\u62df\u5408\u6280\u672f",section:"Posts",handler:()=>{window.location.href="/blog/2024/GAMES001-NOTES-05/"}},{id:"post-games001\u8bfe\u7a0b\u7b14\u8bb004-\u5947\u5f02\u503c\u5206\u89e3\u4e0e\u4e3b\u6210\u5206\u5206\u6790",title:"GAMES001\u8bfe\u7a0b\u7b14\u8bb004-\u5947\u5f02\u503c\u5206\u89e3\u4e0e\u4e3b\u6210\u5206\u5206\u6790",description:"SVD\u4e0ePCA\u80cc\u540e\u7684\u6570\u5b66",section:"Posts",handler:()=>{window.location.href="/blog/2024/GAMES001-NOTES-04/"}},{id:"post-games001\u8bfe\u7a0b\u7b14\u8bb003-\u65cb\u8f6c\u53d8\u6362",title:"GAMES001\u8bfe\u7a0b\u7b14\u8bb003-\u65cb\u8f6c\u53d8\u6362",description:"\u4e09\u7ef4\u65cb\u8f6c\u80cc\u540e\u7684\u6570\u5b66\u77e5\u8bc6",section:"Posts",handler:()=>{window.location.href="/blog/2024/GAMES001-NOTES-03/"}},{id:"post-games001\u8bfe\u7a0b\u7b14\u8bb002-\u8ba1\u7b97\u51e0\u4f55",title:"GAMES001\u8bfe\u7a0b\u7b14\u8bb002-\u8ba1\u7b97\u51e0\u4f55",description:"\u8ba1\u7b97\u51e0\u4f55\u76f8\u5173\u5185\u5bb9",section:"Posts",handler:()=>{window.location.href="/blog/2024/GAMES001-NOTES-02/"}},{id:"post-games001\u8bfe\u7a0b\u7b14\u8bb001-\u7ebf\u6027\u4ee3\u6570\u57fa\u7840",title:"GAMES001\u8bfe\u7a0b\u7b14\u8bb001-\u7ebf\u6027\u4ee3\u6570\u57fa\u7840",description:"\u7ebf\u6027\u4ee3\u6570\u57fa\u7840\u77e5\u8bc6",section:"Posts",handler:()=>{window.location.href="/blog/2024/GAMES001-NOTES-01/"}},{id:"post-a-post-with-code-diff",title:"a post with code diff",description:"this is how you can display code diffs",section:"Posts",handler:()=>{window.location.href="/blog/2024/code-diff/"}},{id:"post-a-post-with-advanced-image-components",title:"a post with advanced image components",description:"this is what advanced image components could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/advanced-images/"}},{id:"post-a-post-with-vega-lite",title:"a post with vega lite",description:"this is what included vega lite code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/vega-lite/"}},{id:"post-a-post-with-geojson",title:"a post with geojson",description:"this is what included geojson code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/geojson-map/"}},{id:"post-a-post-with-echarts",title:"a post with echarts",description:"this is what included echarts code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/echarts/"}},{id:"post-a-post-with-chart-js",title:"a post with chart.js",description:"this is what included chart.js code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/chartjs/"}},{id:"post-\u5fae\u5206\u51e0\u4f55\u7b14\u8bb005-\u66f2\u9762\u8bba\u57fa\u672c\u5b9a\u7406",title:"\u5fae\u5206\u51e0\u4f55\u7b14\u8bb005-\u66f2\u9762\u8bba\u57fa\u672c\u5b9a\u7406",description:"\u66f2\u9762\u8bba\u57fa\u672c\u5b9a\u7406",section:"Posts",handler:()=>{window.location.href="/blog/2023/DifferentialGeometry-NOTES-05/"}},{id:"post-a-post-with-tikzjax",title:"a post with TikZJax",description:"this is what included TikZ code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/tikzjax/"}},{id:"post-c-stl\u7b14\u8bb005-std-list\u53cc\u5411\u94fe\u8868",title:"C++ STL\u7b14\u8bb005-std::list\u53cc\u5411\u94fe\u8868",description:"\u52a8\u624b\u5b9e\u73b0std::list",section:"Posts",handler:()=>{window.location.href="/blog/2023/STL-NOTES-05/"}},{id:"post-c-stl\u7b14\u8bb004-std-vector\u52a8\u6001\u6570\u7ec4",title:"C++ STL\u7b14\u8bb004-std::vector\u52a8\u6001\u6570\u7ec4",description:"\u52a8\u624b\u5b9e\u73b0std::vector",section:"Posts",handler:()=>{window.location.href="/blog/2023/STL-NOTES-04/"}},{id:"post-\u5fae\u5206\u51e0\u4f55\u7b14\u8bb004-\u66f2\u9762\u7684\u7b2c\u4e8c\u57fa\u672c\u5f62\u5f0f",title:"\u5fae\u5206\u51e0\u4f55\u7b14\u8bb004-\u66f2\u9762\u7684\u7b2c\u4e8c\u57fa\u672c\u5f62\u5f0f",description:"\u66f2\u9762\u7684\u7b2c\u4e8c\u57fa\u672c\u5f62\u5f0f",section:"Posts",handler:()=>{window.location.href="/blog/2023/DifferentialGeometry-NOTES-04/"}},{id:"post-c-stl\u7b14\u8bb003-std-array\u6570\u7ec4",title:"C++ STL\u7b14\u8bb003-std::array\u6570\u7ec4",description:"\u52a8\u624b\u5b9e\u73b0std::array",section:"Posts",handler:()=>{window.location.href="/blog/2023/STL-NOTES-03/"}},{id:"post-\u5fae\u5206\u51e0\u4f55\u7b14\u8bb003-\u66f2\u9762\u7684\u7b2c\u4e00\u57fa\u672c\u5f62\u5f0f",title:"\u5fae\u5206\u51e0\u4f55\u7b14\u8bb003-\u66f2\u9762\u7684\u7b2c\u4e00\u57fa\u672c\u5f62\u5f0f",description:"\u66f2\u9762\u7684\u7b2c\u4e00\u57fa\u672c\u5f62\u5f0f",section:"Posts",handler:()=>{window.location.href="/blog/2023/DifferentialGeometry-NOTES-03/"}},{id:"post-c-stl\u7b14\u8bb002-std-unique-ptr\u72ec\u5360\u578b\u667a\u80fd\u6307\u9488",title:"C++ STL\u7b14\u8bb002-std::unique_ptr\u72ec\u5360\u578b\u667a\u80fd\u6307\u9488",description:"\u52a8\u624b\u5b9e\u73b0std::unique_ptr",section:"Posts",handler:()=>{window.location.href="/blog/2023/STL-NOTES-02/"}},{id:"post-c-stl\u7b14\u8bb001-std-function\u5bb9\u5668",title:"C++ STL\u7b14\u8bb001-std::function\u5bb9\u5668",description:"\u52a8\u624b\u5b9e\u73b0std::function",section:"Posts",handler:()=>{window.location.href="/blog/2023/STL-NOTES-01/"}},{id:"post-\u5fae\u5206\u51e0\u4f55\u7b14\u8bb002-\u66f2\u7ebf\u8bba",title:"\u5fae\u5206\u51e0\u4f55\u7b14\u8bb002-\u66f2\u7ebf\u8bba",description:"\u66f2\u7ebf\u8bba\u76f8\u5173\u77e5\u8bc6",section:"Posts",handler:()=>{window.location.href="/blog/2023/DifferentialGeometry-NOTES-02/"}},{id:"post-\u5fae\u5206\u51e0\u4f55\u7b14\u8bb001-\u9884\u5907\u77e5\u8bc6",title:"\u5fae\u5206\u51e0\u4f55\u7b14\u8bb001-\u9884\u5907\u77e5\u8bc6",description:"\u5fae\u5206\u51e0\u4f55\u9884\u5907\u77e5\u8bc6\u4e0e\u5e38\u7528\u7ed3\u8bba",section:"Posts",handler:()=>{window.location.href="/blog/2023/DifferentialGeometry-NOTES-01/"}},{id:"post-a-post-with-bibliography",title:"a post with bibliography",description:"an example of a blog post with bibliography",section:"Posts",handler:()=>{window.location.href="/blog/2023/post-bibliography/"}},{id:"post-a-post-with-jupyter-notebook",title:"a post with jupyter notebook",description:"an example of a blog post with jupyter notebook",section:"Posts",handler:()=>{window.location.href="/blog/2023/jupyter-notebook/"}},{id:"post-a-post-with-custom-blockquotes",title:"a post with custom blockquotes",description:"an example of a blog post with custom blockquotes",section:"Posts",handler:()=>{window.location.href="/blog/2023/custom-blockquotes/"}},{id:"post-a-post-with-table-of-contents-on-a-sidebar",title:"a post with table of contents on a sidebar",description:"an example of a blog post with table of contents on a sidebar",section:"Posts",handler:()=>{window.location.href="/blog/2023/sidebar-table-of-contents/"}},{id:"post-a-post-with-audios",title:"a post with audios",description:"this is what included audios could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/audios/"}},{id:"post-a-post-with-videos",title:"a post with videos",description:"this is what included videos could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/videos/"}},{id:"post-\u5e76\u67e5\u96c6",title:"\u5e76\u67e5\u96c6",description:"LeetCode\u5e76\u67e5\u96c6\u4e60\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/UnionFindSet/"}},{id:"post-\u56fe\u8bba",title:"\u56fe\u8bba",description:"LeetCode\u56fe\u8bba\u4e60\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/Graph/"}},{id:"post-\u5355\u8c03\u6808",title:"\u5355\u8c03\u6808",description:"LeetCode\u5355\u8c03\u6808\u4e60\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/MonotoneStack/"}},{id:"post-displaying-beautiful-tables-with-bootstrap-tables",title:"displaying beautiful tables with Bootstrap Tables",description:"an example of how to use Bootstrap Tables",section:"Posts",handler:()=>{window.location.href="/blog/2023/tables/"}},{id:"post-a-post-with-table-of-contents",title:"a post with table of contents",description:"an example of a blog post with table of contents",section:"Posts",handler:()=>{window.location.href="/blog/2023/table-of-contents/"}},{id:"post-\u52a8\u6001\u89c4\u5212",title:"\u52a8\u6001\u89c4\u5212",description:"LeetCode\u52a8\u6001\u89c4\u5212\u4e60\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/DynamicProgramming/"}},{id:"post-\u8d2a\u5fc3",title:"\u8d2a\u5fc3",description:"LeetCode\u8d2a\u5fc3\u4e60\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/Greedy/"}},{id:"post-\u56de\u6eaf",title:"\u56de\u6eaf",description:"LeetCode\u56de\u6eaf\u4e60\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/Backtracking/"}},{id:"post-\u4e8c\u53c9\u6811",title:"\u4e8c\u53c9\u6811",description:"LeetCode\u4e8c\u53c9\u6811\u4e60\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/BinaryTree/"}},{id:"post-\u6808\u4e0e\u961f\u5217",title:"\u6808\u4e0e\u961f\u5217",description:"LeetCode\u6808\u4e0e\u961f\u5217\u4e60\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/StackQueue/"}},{id:"post-\u53cc\u6307\u9488",title:"\u53cc\u6307\u9488",description:"LeetCode\u53cc\u6307\u9488\u4e60\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/TwoPointers/"}},{id:"post-\u5b57\u7b26\u4e32",title:"\u5b57\u7b26\u4e32",description:"LeetCode\u5b57\u7b26\u4e32\u4e60\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/String/"}},{id:"post-\u54c8\u5e0c\u8868",title:"\u54c8\u5e0c\u8868",description:"LeetCode\u54c8\u5e0c\u8868\u4e60\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/HashTable/"}},{id:"post-\u94fe\u8868",title:"\u94fe\u8868",description:"LeetCode\u94fe\u8868\u4e60\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/LinkedList/"}},{id:"post-\u6570\u7ec4",title:"\u6570\u7ec4",description:"LeetCode\u6570\u7ec4\u4e60\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/Array/"}},{id:"post-a-post-with-giscus-comments",title:"a post with giscus comments",description:"an example of a blog post with giscus comments",section:"Posts",handler:()=>{window.location.href="/blog/2022/giscus-comments/"}},{id:"post-omscs-ga\u8bfe\u7a0b\u7b14\u8bb007-linear-programming",title:"OMSCS-GA\u8bfe\u7a0b\u7b14\u8bb007-Linear Programming",description:"\u7ebf\u6027\u89c4\u5212",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-GA-NOTES-07/"}},{id:"post-omscs-ga\u8bfe\u7a0b\u7b14\u8bb006-np-completeness",title:"OMSCS-GA\u8bfe\u7a0b\u7b14\u8bb006-NP Completeness",description:"NP\u5b8c\u5907\u7406\u8bba",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-GA-NOTES-06/"}},{id:"post-omscs-ga\u8bfe\u7a0b\u7b14\u8bb005-randomized-algorithms",title:"OMSCS-GA\u8bfe\u7a0b\u7b14\u8bb005-Randomized Algorithms",description:"\u5bc6\u7801\u5b66\u4e0e\u968f\u673a\u7b97\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-GA-NOTES-05/"}},{id:"post-omscs-ga\u8bfe\u7a0b\u7b14\u8bb004-max-flow",title:"OMSCS-GA\u8bfe\u7a0b\u7b14\u8bb004-Max Flow",description:"\u6700\u5927\u6d41",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-GA-NOTES-04/"}},{id:"post-omscs-ga\u8bfe\u7a0b\u7b14\u8bb003-graph-algorithms",title:"OMSCS-GA\u8bfe\u7a0b\u7b14\u8bb003-Graph Algorithms",description:"\u56fe\u7b97\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-GA-NOTES-03/"}},{id:"post-omscs-ga\u8bfe\u7a0b\u7b14\u8bb002-divide-and-conquer",title:"OMSCS-GA\u8bfe\u7a0b\u7b14\u8bb002-Divide and Conquer",description:"\u5206\u6cbb\u7b97\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-GA-NOTES-02/"}},{id:"post-omscs-ga\u8bfe\u7a0b\u7b14\u8bb001-dynamic-programming",title:"OMSCS-GA\u8bfe\u7a0b\u7b14\u8bb001-Dynamic Programming",description:"\u52a8\u6001\u89c4\u5212",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-GA-NOTES-01/"}},{id:"post-a-post-with-redirect",title:"a post with redirect",description:"you can also redirect to assets like pdf",section:"Posts",handler:()=>{window.location.href="/assets/pdf/example_pdf.pdf"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb015-game-theory",title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb015-Game Theory",description:"\u535a\u5f08\u8bba",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-15/"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb014-reinforcement-learning",title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb014-Reinforcement Learning",description:"\u5f3a\u5316\u5b66\u4e60",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-14/"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb013-markov-decision-processes",title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb013-Markov Decision Processes",description:"Markov\u51b3\u7b56\u8fc7\u7a0b",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-13/"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb012-feature-selection-and-transform",title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb012-Feature Selection and Transform",description:"\u7279\u5f81\u9009\u62e9",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-12/"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb011-clustering",title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb011-Clustering",description:"\u805a\u7c7b\u7b97\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-11/"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb010-randomized-optimization",title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb010-Randomized Optimization",description:"\u968f\u673a\u4f18\u5316",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-10/"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb009-information-theory",title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb009-Information Theory",description:"\u4fe1\u606f\u8bba",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-09/"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb008-bayesian-learning-and-inference",title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb008-Bayesian Learning and Inference",description:"\u8d1d\u53f6\u65af\u5b66\u4e60",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-08/"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb007-computational-learning-theory",title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb007-Computational Learning Theory",description:"\u8ba1\u7b97\u5b66\u4e60\u7406\u8bba",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-07/"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb006-svm-and-kernel-methods",title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb006-SVM and Kernel Methods",description:"\u652f\u6301\u5411\u91cf\u673a",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-06/"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb005-ensemble-learning",title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb005-Ensemble Learning",description:"\u96c6\u6210\u5b66\u4e60",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-05/"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb004-instance-based-learning",title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb004-Instance Based Learning",description:"\u5b9e\u4f8b\u5b66\u4e60",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-04/"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb003-neural-networks",title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb003-Neural Networks",description:"\u795e\u7ecf\u7f51\u7edc",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-03/"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb002-regression",title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb002-Regression",description:"\u56de\u5f52\u95ee\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-02/"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb001-decision-trees",title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb001-Decision Trees",description:"\u51b3\u7b56\u6811",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-01/"}},{id:"post-ddg\u8bfe\u7a0b\u7b14\u8bb05-\u6d4b\u5730\u7ebf",title:"DDG\u8bfe\u7a0b\u7b14\u8bb05-\u6d4b\u5730\u7ebf",description:"\u6d4b\u5730\u7ebf\u4e0e\u6d4b\u5730\u8ddd\u79bb",section:"Posts",handler:()=>{window.location.href="/blog/2021/DDG-NOTES-5/"}},{id:"post-ddg\u8bfe\u7a0b\u7b14\u8bb04-\u66f2\u9762\u53c2\u6570\u5316",title:"DDG\u8bfe\u7a0b\u7b14\u8bb04-\u66f2\u9762\u53c2\u6570\u5316",description:"\u66f2\u9762\u53c2\u6570\u5316",section:"Posts",handler:()=>{window.location.href="/blog/2021/DDG-NOTES-4/"}},{id:"post-ddg\u8bfe\u7a0b\u7b14\u8bb03-laplace\u7b97\u5b50",title:"DDG\u8bfe\u7a0b\u7b14\u8bb03-Laplace\u7b97\u5b50",description:"\u66f2\u9762\u4e0a\u7684Laplace\u7b97\u5b50",section:"Posts",handler:()=>{window.location.href="/blog/2021/DDG-NOTES-3/"}},{id:"post-ddg\u8bfe\u7a0b\u7b14\u8bb02-\u66f2\u9762\u4e0e\u66f2\u7387",title:"DDG\u8bfe\u7a0b\u7b14\u8bb02-\u66f2\u9762\u4e0e\u66f2\u7387",description:"\u66f2\u9762\u4e0a\u7684\u66f2\u7387",section:"Posts",handler:()=>{window.location.href="/blog/2021/DDG-NOTES-2/"}},{id:"post-ddg\u8bfe\u7a0b\u7b14\u8bb01-\u5916\u4ee3\u6570\u4e0e\u5916\u5fae\u5206",title:"DDG\u8bfe\u7a0b\u7b14\u8bb01-\u5916\u4ee3\u6570\u4e0e\u5916\u5fae\u5206",description:"\u5916\u4ee3\u6570\u4e0e\u5916\u5fae\u5206\u57fa\u7840",section:"Posts",handler:()=>{window.location.href="/blog/2021/DDG-NOTES-1/"}},{id:"post-a-post-with-diagrams",title:"a post with diagrams",description:"an example of a blog post with diagrams",section:"Posts",handler:()=>{window.location.href="/blog/2021/diagrams/"}},{id:"post-a-distill-style-blog-post",title:"a distill-style blog post",description:"an example of a distill-style blog post and main elements",section:"Posts",handler:()=>{window.location.href="/blog/2021/distill/"}},{id:"post-a-post-with-github-metadata",title:"a post with github metadata",description:"a quick run down on accessing github metadata.",section:"Posts",handler:()=>{window.location.href="/blog/2020/github-metadata/"}},{id:"post-a-post-with-twitter",title:"a post with twitter",description:"an example of a blog post with twitter",section:"Posts",handler:()=>{window.location.href="/blog/2020/twitter/"}},{id:"post-a-post-with-disqus-comments",title:"a post with disqus comments",description:"an example of a blog post with disqus comments",section:"Posts",handler:()=>{window.location.href="/blog/2015/disqus-comments/"}},{id:"post-a-post-with-math",title:"a post with math",description:"an example of a blog post with some math",section:"Posts",handler:()=>{window.location.href="/blog/2015/math/"}},{id:"post-a-post-with-code",title:"a post with code",description:"an example of a blog post with some code",section:"Posts",handler:()=>{window.location.href="/blog/2015/code/"}},{id:"post-a-post-with-images",title:"a post with images",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2015/images/"}},{id:"post-a-post-with-formatting-and-links",title:"a post with formatting and links",description:"march & april, looking forward to summer",section:"Posts",handler:()=>{window.location.href="/blog/2015/formatting-and-links/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-games103-labs",title:"GAMES103 Labs",description:"Homeworks in GAMES 103: Intro to Physics Based Animation.",section:"Projects",handler:()=>{window.location.href="/projects/GAMES103/"}},{id:"projects-nerf-project",title:"NeRF Project",description:"Course project in CS 7643: Deep Learning. We implemented NeRF from scratch.",section:"Projects",handler:()=>{window.location.href="/projects/NeRF_Project/"}},{id:"projects-shape-analysis-homeworks",title:"Shape Analysis Homeworks",description:"Homeworks in MIT 6.838: Shape Analysis.",section:"Projects",handler:()=>{window.location.href="/projects/ShapeAnalysis/"}},{id:"projects-ai4r-projects",title:"AI4R Projects",description:"Course project in CS 7638: Artificial Intelligence for Robotics.",section:"Projects",handler:()=>{window.location.href="/projects/CS7638/"}},{id:"projects-games301-homeworks",title:"GAMES301 Homeworks",description:"Homeworks in GAMES 301: Surface Parameterization.",section:"Projects",handler:()=>{window.location.href="/projects/GAMES301/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%62%70%31%36%35%37@%6E%79%75.%65%64%75","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/peng00bo00","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/bo-peng-9600a4175","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>