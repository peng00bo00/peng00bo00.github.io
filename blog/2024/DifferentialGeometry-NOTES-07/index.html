<!DOCTYPE html> <html lang="cn"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> 微分几何笔记07-活动标架和外微分法 | Bo Peng </title> <meta name="author" content="Bo Peng"> <meta name="description" content="微分几何中的外微分方法"> <meta name="keywords" content="Computer Graphics, Geometry Processing"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.css" integrity="sha256-uRX+PiRTR4ysKFRCykT8HLuRCub26LgXJZym3Yeom1c=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@400..900&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="/assets/img/favicon.png?cc76d8e6f4495e4cf26b99e34f8aefe4"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://peng00bo00.github.io/blog/2024/DifferentialGeometry-NOTES-07/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Bo</span> Peng </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Post </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Quick Link </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/blog/tag/formatting">Formatting Guide</a> <a class="dropdown-item " href="/blog/category/leetcode">LeetCode</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">微分几何笔记07-活动标架和外微分法</h1> <p class="post-meta"> Created in June 08, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/cg"> <i class="fa-solid fa-hashtag fa-sm"></i> CG</a>   <a href="/blog/tag/math"> <i class="fa-solid fa-hashtag fa-sm"></i> Math</a>   ·   <a href="/blog/category/differential-geometry"> <i class="fa-solid fa-tag fa-sm"></i> Differential-Geometry</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <blockquote class="block-preface"> <p>这个系列是北京大学陈维桓教授《微分几何(第二版)》的学习笔记，主要涉及古典微分几何中曲线曲面理论的相关知识。系统学习微分几何对于理解计算机图形学中的各种几何处理算法是十分有益的。本节介绍活动标架和外微分法的相关理论。</p> </blockquote> <h2 id="外形式">外形式</h2> <p>本节要在代数上做一些准备，介绍外形式和外代数的概念。</p> <h3 id="对偶空间">对偶空间</h3> <p>设\(V\)是\(n\)维向量空间，\(\{ \boldsymbol{e}_1, ..., \boldsymbol{e}_n \}\)是它的一个基底，则空间\(V\)中的任意一个元素\(\boldsymbol{x}\)都能够唯一地表示为基底向量\(\boldsymbol{e}_1, ..., \boldsymbol{e}_n\)的线性组合，设为</p> \[\boldsymbol{x} = x^1 \boldsymbol{e}_1 + \cdots + x^n \boldsymbol{e}_n \equiv x^i \boldsymbol{e}_i\] <p>在最右端我们采用了<a href="/blog/2023/DifferentialGeometry-NOTES-05/#einstein%E6%B1%82%E5%92%8C%E7%BA%A6%E5%AE%9A">Einstein的和式约定</a>。在本节，我们规定所有的指标\(i\)，\(j\)，\(k\)，\(l\)的取值范围是从1到\(n\)的整数。实数\(x^1, ..., x^n\)称为向量\(\boldsymbol{x}\)在基底\(\{ \boldsymbol{e}_1, ..., \boldsymbol{e}_n \}\)下的分量。</p> <p>设\(f: V \rightarrow \mathbb{R}\)是向量空间\(V\)上的函数。如果对于任意的\(\boldsymbol{x}, \boldsymbol{y} \in V\)及\(\alpha \in \mathbb{R}\)总有</p> \[f(\boldsymbol{x} + \boldsymbol{y}) = f(\boldsymbol{x}) + f(\boldsymbol{y}), \ \ \ f(\alpha \cdot \boldsymbol{x}) = \alpha \cdot f(\boldsymbol{x})\] <p>则称\(f\)是向量空间\(V\)上的线性函数。在固定的基底\(\{ \boldsymbol{e}_i \}\)下，取向量\(\boldsymbol{x}\in V\)在该基底下的第\(j\)的分量，显然它是在向量空间\(V\)的一个线性函数，记为\(e^j\)，即</p> \[e^j (\boldsymbol{x}) = x^j\] <p>特别地，函数\(e^j\)在基底向量\(\boldsymbol{e}_i\)上的值是</p> \[e^j (\boldsymbol{e}_i) = \begin{cases} 1, &amp; i = j \\ 0, &amp; i \neq j \end{cases}\] <p>为方便起见，常常把上式右端记为\(\delta_i^j\)，称作Kronecker \(\delta\)记号，即</p> \[\delta_i^j = \begin{cases} 1, &amp; i = j \\ 0, &amp; i \neq j \end{cases}\] <p>这里的\(\delta_i^j\)是专用记号，与基底\(\{ \boldsymbol{e}_i \}\)所用的字母的记号没有关系。</p> <p>很明显，向量空间\(V\)上的任意两个线性函数的和是\(V\)上的线性函数，\(V\)上的一个线性函数与实数\(\alpha\)的乘积仍然是\(V\)上的线性函数。这就是说，\(V\)上全体线性函数的集合关于加法和数乘法是封闭的。因此该集合是一个新的向量空间，记为\(V^*\), 称为原向量空间\(V\)的<strong>对偶空间</strong>。容易证明，前面在\(V\)的固定基底\(\{ \boldsymbol{e}_i \}\)下定义的\(n\)个线性函数\(e^1, ..., e^n\)恰好构成空间\(V^*\)的基底，称为与原向量空间\(V\)的基底\(\{ \boldsymbol{e}_1, ..., \boldsymbol{e}_n \}\)对偶的基底。实际上，对于任意的线性函数\(f \in V^*\)和任意的向量\(\boldsymbol{x} = x^i \boldsymbol{e}_i \in V\)，我们有</p> \[f(\boldsymbol{x}) = f(x^i \boldsymbol{e}_i) = x^i f(\boldsymbol{e}_i)\] <p>命</p> \[f_i = f(\boldsymbol{e}_i)\] <p>则可以得到</p> \[f(\boldsymbol{x}) = f_i x^i = f_i e^i (\boldsymbol{x}) = (f_i e^i) (\boldsymbol{x}), \ \ \ \forall \boldsymbol{x} \in V\] <p>因此</p> \[f = f_i e^i\] <p>这说明向量空间\(V\)上的任意一个线性函数\(f\)能够表示成线性函数\(e^1, ..., e^n\)的线性组合，组合系数\(f_i\)正好是线性函数\(f\)在基底向量\(\boldsymbol{e}_i\)上的值。下面要证明这\(n\)个线性函数\(e^1, ..., e^n\)是线性无关的。假定有\(n\)个实数\(\alpha_1, ..., \alpha_n\)使得线性组合\(\alpha_1 e^1 + \cdots + \alpha_n e^n\)为零，即</p> \[\alpha_1 e^1 + \cdots + \alpha_n e^n = 0\] <p>将这个零函数在基底\(\boldsymbol{e}_k\)上求值得到</p> \[0 = \alpha_i e^i (\boldsymbol{e}_k) = \alpha_i \delta_k^i = \alpha_k, \ \ \ \forall k\] <p>这意味着所有的实数\(\alpha_1, ..., \alpha_n\)必须为零，因此线性函数\(e^1, ..., e^n\)是线性无关的，故它们构成对偶向量空间\(V^*\)的基底，特别是\(\dim{V^*} = n\)。\(V\)上的线性函数也称为一次形式，或者1-形式。</p> <h3 id="多重线性函数">多重线性函数</h3> <p>类似地，我们可以考虑线性空间\(V\)上的多重线性函数。设</p> \[f: \underbrace{V \times \cdots \times V}_{r个} \rightarrow \mathbb{R}\] <p>是\(V\)上的\(r\)元函数。如果它对于每一个自变量来说都是线性函数，则称它是\(r\)重线性函数。线性空间\(V\)上全体\(r\)重线性函数的集合关于加法和数乘法自然是封闭的，因此它本身是一个向量空间，记为\(\bigotimes^r V^*\)，或者\(V_r\)。</p> <p>另外，任意两个多重线性函数能够作张量积，得到一个新的多重线性函数。例如，设\(f\)是一个\(r\)重线性函数，\(g\)是一个\(s\)重线性函数，\(f\)和\(g\)的张量积\(f \otimes g\)定义为</p> \[f \otimes g (x_1, ..., x_{r+s}) = f(x_1, ..., x_r) \cdot g(x_{r+1}, ..., x_{r+s})\] <p>其中\(x_1, ..., x_{r+s} \in V\)。很明显，\(f \otimes g\)是一个\(r+s\)重线性函数。容易验证，张量积具有分配律和结合律，即</p> <p>分配率：\((f+g) \otimes h = f \otimes h + g \otimes h\)，\(h \otimes (f + g) = h \otimes f + h \otimes g\)</p> <p>结合律：\((f \otimes g) \otimes h = f \otimes (g \otimes h) = f \otimes g \otimes h\)</p> <p>因此，\(r\)个线性函数的张量积便成为一个\(r\)重线性函数。特别地，设\(\{ e^1, ..., e^n \}\)是对偶向量空间\(V^*\)的基底，任意固定\(r\)个指标\(i_1, ..., i_r\)，则我们得到一个\(r\)重线性函数\(e^{i_1} \otimes \cdots \otimes e^{i_r}\)，它在向量\(\boldsymbol{x}_1, ..., \boldsymbol{x}_r \in V\)上的值是</p> \[e^{i_1} \otimes \cdots \otimes e^{i_r} (\boldsymbol{x}_1, ..., \boldsymbol{x}_r) = e^{i_1} (\boldsymbol{x}_1) \cdots e^{i_r} (\boldsymbol{x}_r) = x_1^{i_1} \cdots x_r^{i_r}\] <p>指标\(i_1, ..., i_r\)的选法共有\(n^r\)种，因此我们得到\(n^r\)个\(r\)重线性函数</p> \[e^{i_1} \otimes \cdots \otimes e^{i_r}, \ \ \ 1 \leq i_1, ..., i_r \leq n\] <p>它们构成向量空间\(\bigotimes^r V^*\)的基底，由此可见\(\dim{\bigotimes^r V^*} = n^r\)。实际上，若设\(f \in \bigotimes^r V^*\)，\(\boldsymbol{x}_1, ..., \boldsymbol{x}_r \in V\)，则</p> \[\begin{aligned} f(\boldsymbol{x}_1, ..., \boldsymbol{x}_r) &amp;= f(x_1^{i_1} \boldsymbol{e}_{i_1}, ..., x_r^{i_r} \boldsymbol{e}_{i_r}) \\ &amp;= x_1^{i_1} \cdots x_r^{i_r} \cdot f(\boldsymbol{e}_{i_1}, ..., \boldsymbol{e}_{i_r}) \\ &amp;= f_{i_1 \cdots i_r} e^{i_1} \otimes \cdots \otimes e^{i_r} (\boldsymbol{x}_1, ..., \boldsymbol{x}_r) \end{aligned}\] <p>其中</p> \[f_{i_1 \cdots i_r} = f(\boldsymbol{e}_{i_1}, ..., \boldsymbol{e}_{i_r})\] <p>因此</p> \[f = f_{i_1 \cdots i_r} e^{i_1} \otimes \cdots \otimes e^{i_r}\] <p>类似地，可以证明\(n^r\)个\(r\)重线性函数是线性无关的。</p> <h3 id="外形式-1">外形式</h3> <p>设\(f \in \bigotimes^r V^*\)。如果在函数\(f\)的任意两个自变量交换位置时\(f\)的值只改变它的符号，即对于任意的\(\boldsymbol{x}_1, ..., \boldsymbol{x}_r \in V\)以及任意的\(1 \leq s \lt t \leq r\)总有</p> \[\begin{aligned} f(\boldsymbol{x}_1, ..., \boldsymbol{x}_{s-1}, \boldsymbol{x}_s, \boldsymbol{x}_{s+1}, ..., \boldsymbol{x}_{t-1}, \boldsymbol{x}_t, \boldsymbol{x}_{t+1}, ...) = \\ -f(\boldsymbol{x}_1, ..., \boldsymbol{x}_{s-1}, \boldsymbol{x}_t, \boldsymbol{x}_{s+1}, ..., \boldsymbol{x}_{t-1}, \boldsymbol{x}_s, \boldsymbol{x}_{t+1}, ..) \end{aligned}\] <p>则称\(f\)是一个反对称的\(r\)重线性函数，或称\(f\)是一个\(r\)次<strong>外形式</strong>，简称为\(r\)-形式。此时，如果\(\sigma\)是\(\{ 1, ..., r \}\)的任意一个置换，则有</p> \[f(\boldsymbol{x}_{\sigma(1)}, ..., \boldsymbol{x}_{\sigma(r)}) = \text{sign} (\sigma) \cdot f(\boldsymbol{x}_1, ..., \boldsymbol{x}_r)\] <p>其中\(\text{sign}(\sigma)\)是置换\(\sigma\)的符号，即</p> \[\text{sign} (\sigma) = \begin{cases} 1, &amp;\text{若 $\sigma$是偶置换} \\ -1, &amp;\text{若 $\sigma$是奇置换} \\ \end{cases}\] <p>实际上，\(r\)次外形式的最简单的例子就是由行列式给出的。</p> <p>设\(\boldsymbol{x}_1, ..., \boldsymbol{x}_r\)是向量空间\(V\)中的\(r\)个元素，在基底\(\{ \boldsymbol{e}_1, ..., \boldsymbol{e}_n \}\)下它们可以表示为</p> \[\boldsymbol{x}_i = x_i^1 \boldsymbol{e}_1 + \cdots + x_i^n \boldsymbol{e}_n\] <p>任意取定一组指标\(1 \leq j_1 \lt \cdots \lt j_r \leq n\)，命</p> \[D^{j_1 ... j_r} (\boldsymbol{x}_1, ..., \boldsymbol{x}_r) = \begin{vmatrix} x_1^{j_1} &amp; \cdots &amp; x_1^{j_r} \\ \vdots &amp; &amp; \vdots \\ x_r^{j_1} &amp; \cdots &amp; x_r^{j_r} \\ \end{vmatrix}\] <p>根据行列式的形式，函数\(D^{j_1 ... j_r} (\boldsymbol{x}_1, ..., \boldsymbol{x}_r)\)是\(\boldsymbol{x}_1, ..., \boldsymbol{x}_r\)的反对称的\(r\)重线性函数，即\(D^{j_1 ... j_r}\)是一个\(r\)次外形式。</p> <h3 id="外积">外积</h3> <p>以后我们要证明任意一个\(r\)次外形式无非是这样的一些行列式的线性组合。为此我们先介绍反对称化运算和外积运算这两个概念。</p> <p>所谓的反对称化运算是将一个\(r\)重线性函数变成一个\(r\)重反对称线性函数的手段。实际上，\(r\)重线性函数\(f\)的反对称化(记为\([f]\))就是将它的自变量做所有的置换，然后取它们的值的交替平均值。例如，设\(f\)是\(V\)上的一个2重线性函数，则</p> \[[f] (\boldsymbol{x}, \boldsymbol{y}) = \frac{1}{2} \big( f (\boldsymbol{x}, \boldsymbol{y}) - f (\boldsymbol{y}, \boldsymbol{x}) \big), \ \ \ \forall \boldsymbol{x}, \boldsymbol{y} \in V\] <p>如果\(f\)是\(V\)上的一个3重线性函数，则</p> \[\begin{aligned}[] [f] (\boldsymbol{x}, \boldsymbol{y}, \boldsymbol{z}) = \frac{1}{6} \big( &amp;f (\boldsymbol{x}, \boldsymbol{y}, \boldsymbol{z}) - f (\boldsymbol{y}, \boldsymbol{x}, \boldsymbol{z}) + f (\boldsymbol{y}, \boldsymbol{z}, \boldsymbol{x}) \\ - &amp;f (\boldsymbol{z}, \boldsymbol{y}, \boldsymbol{x}) + f (\boldsymbol{z}, \boldsymbol{x}, \boldsymbol{y}) - f (\boldsymbol{x}, \boldsymbol{z}, \boldsymbol{y}) \big) \end{aligned}\] <p>其中\(\forall \boldsymbol{x}, \boldsymbol{y}, \boldsymbol{z} \in V\)。一般地，设\(f\)是\(V\)上的一个\(r\)重线性函数，则</p> \[[f] (\boldsymbol{x}_1, ..., \boldsymbol{x}_r) = \frac{1}{r!} \sum_{\sigma \in \mathfrak{G}_r} \text{sign} (\sigma) \cdot f (\boldsymbol{x}_{\sigma(1)}, ..., \boldsymbol{x}_{\sigma(r)})\] <p>其中\(\mathfrak{G}_r\)是\(r\)个整数\(\{ 1, ..., r \}\)的置换群。很明显，\([f]\)是一个\(r\)次外形式。如果\(f\)本身是\(r\)次外形式，则\([f] = f\)。</p> <p>向量空间\(V\)上的全体\(r\)次外形式集合记为\(\bigwedge^r V^*\)，因为加法和数乘法在集合\(\bigwedge^r V^*\)中是封闭的，因此它自然是一个向量空间。更要紧的一个事实是在外形式之间还能够定义外积运算， 它在实质上是张量积和反对称化运算的复合。</p> <blockquote class="block-definition"> <h5 id="定义71">定义7.1</h5> <p>设\(f \in \bigwedge^r V^*\)，\(g \in \bigwedge^s V^*\)，则\(f\)和\(g\)的<strong>外积</strong>\(f \wedge g\)是一个\((r+s)\)次外形式，定义为\(f \wedge g = \frac{(r+s)!}{r! s!} [f \otimes g]\)。</p> </blockquote> <p>根据<strong>定义7.1</strong>，设\(f\)、\(g\)是向量空间\(V\)上的两个一次形式，则它们的外积为</p> \[\begin{aligned} f \wedge g (\boldsymbol{x}, \boldsymbol{y}) &amp;= 2 [f \otimes g] (\boldsymbol{x}, \boldsymbol{y}) = f \otimes g (\boldsymbol{x}, \boldsymbol{y}) - f \otimes g (\boldsymbol{y}, \boldsymbol{x}) \\ &amp;= f(\boldsymbol{x}) g(\boldsymbol{y}) - f(\boldsymbol{y}) g(\boldsymbol{x}) \\ &amp;= \begin{vmatrix} f(\boldsymbol{x}) &amp; f(\boldsymbol{y}) \\ g(\boldsymbol{x}) &amp; g(\boldsymbol{y}) \\ \end{vmatrix} \end{aligned}\] <p>其中\(\boldsymbol{x}, \boldsymbol{y} \in V\)。类似地，设\(f\)、\(g\)、\(h\)是向量空间\(V\)上的三个一次形式，它们的外积为</p> \[f \wedge (g \wedge h) (\boldsymbol{x}, \boldsymbol{y}, \boldsymbol{z}) = \begin{vmatrix} f(\boldsymbol{x}) &amp; f(\boldsymbol{y}) &amp; f(\boldsymbol{z}) \\ g(\boldsymbol{x}) &amp; g(\boldsymbol{y}) &amp; g(\boldsymbol{z}) \\ h(\boldsymbol{x}) &amp; h(\boldsymbol{y}) &amp; h(\boldsymbol{z}) \\ \end{vmatrix}\] <blockquote class="block-theorem"> <h5 id="定理71">定理7.1</h5> <p>外积运算遵循下列运算法则：<br> (1) 分配率：\((f_1 + f_2) \wedge g = f_1 \wedge g + f_2 \wedge g\)<br> (2) 反交换律：设\(f \in \bigwedge^r V^*\)，\(g \in \bigwedge^s V^*\)，则\(f \wedge g = (-1)^{rs} g \wedge f\)<br> (3) 结合律：\(f \wedge (g \wedge h) = (f \wedge g) \wedge h\)</p> </blockquote> <p>根据结合律，任意多个外形式的外积是有意义的。例如：3个外形式\(f\)、\(g\)、\(h\)的外积\(f \wedge g \wedge h\)可以写成\(f \wedge (g \wedge h)\)，也可以写成\((f \wedge g) \wedge h\)。</p> <p>由反交换律得知，如果\(f\)、\(g\)是\(V\)上的一次形式，则</p> \[f \wedge g = - g \wedge f\] <p>特别地，</p> \[f \wedge f = - f \wedge f = 0\] <p>另外，如果在\(f\)、\(g\)中至少有一个是偶次外形式，则下面的交换律成立：</p> \[f \wedge g = g \wedge f\] <p>现在设\(f^1, ..., f^r\)是\(V\)上的\(r\)个一次形式，则有</p> \[f^1 \wedge \cdots \wedge f^r = r! [f^1 \otimes \cdots \otimes f^r]\] <p>任意取\(\boldsymbol{x}_1, ..., \boldsymbol{x}_r \in V\)，则</p> \[\begin{aligned} f^1 \wedge \cdots \wedge f^r (\boldsymbol{x}_1, ..., \boldsymbol{x}_r) &amp;= r! [f^1 \otimes \cdots \otimes f^r] (\boldsymbol{x}_1, ..., \boldsymbol{x}_r) \\ &amp;= \begin{vmatrix} f^1 (\boldsymbol{x}_1) &amp; \cdots &amp; f^1 (\boldsymbol{x}_r) \\ \vdots &amp; &amp; \vdots \\ f^r (\boldsymbol{x}_1) &amp; \cdots &amp; f^r (\boldsymbol{x}_r) \\ \end{vmatrix} \end{aligned}\] <p>特别地，在\(V^*\)的基底\(\{ e^i \}\)中任意取定\(r\)个成员\(e^{j_1}, ..., e^{j_r}\)，则由上式得到</p> \[\begin{aligned} e^{j_1} \wedge \cdots \wedge e^{j_r} (\boldsymbol{x}_1, ..., \boldsymbol{x}_r) &amp;= \begin{vmatrix} e^{j_1} (\boldsymbol{x}_1) &amp; \cdots &amp; e^{j_1} (\boldsymbol{x}_r) \\ \vdots &amp; &amp; \vdots \\ e^{j_r} (\boldsymbol{x}_1) &amp; \cdots &amp; e^{j_r} (\boldsymbol{x}_r) \\ \end{vmatrix} \\ &amp;= \begin{vmatrix} x_1^{j_1} &amp; \cdots &amp; x_r^{j_1} \\ \vdots &amp; &amp; \vdots \\ x_1^{j_r} &amp; \cdots &amp; x_r^{j_r} \\ \end{vmatrix} \end{aligned}\] <p>和前面相对照不难知道</p> \[D^{j_1 \cdots j_r} = e^{j_1} \wedge \cdots \wedge e^{j_r}\] <p>若在\(V\)的基底\(\{ \boldsymbol{e}_i \}\)中任意取定\(r\)个成员\(e_{i_1}, ..., e_{i_r}\)，则由上面的式子得到</p> \[e^{j_1} \wedge \cdots \wedge e^{j_r} (\boldsymbol{e}_{i_1}, ..., \boldsymbol{e}_{i_r}) = \begin{vmatrix} \delta_{i_1}^{j_1} &amp; \cdots &amp; \delta_{i_r}^{j_1} \\ \vdots &amp; &amp; \vdots \\ \delta_{i_1}^{j_r} &amp; \cdots &amp; \delta_{i_r}^{j_r} \\ \end{vmatrix} \equiv \delta_{i_1 \cdots i_r}^{j_1 \cdots j_r}\] <p>我们把\(\delta_{i_1 \cdots i_r}^{j_1 \cdots j_r}\)称为广义的Kronecker \(\delta\)记号。由它的定义式即知</p> \[\delta_{i_1 \cdots i_r}^{j_1 \cdots j_r} = \begin{cases} 1, &amp;\text{若$i_1, ..., i_r$互不相同，且$j_1, ..., j_r$是$i_1, ..., i_r$的偶排列} \\ -1, &amp;\text{若$i_1, ..., i_r$互不相同，且$j_1, ..., j_r$是$i_1, ..., i_r$的奇排列} \\ 0, &amp;\text{其它情形} \end{cases}\] <p>根据反交换律，对于一次形式\(f^1, ..., f^r\)的外积\(f^1 \wedge \cdots \wedge f^r\)，交换其中的任意两个因子，则该外积必反号。所以，对任意的\(\sigma \in \mathfrak{G}_r\)有</p> \[\begin{aligned} f^{\sigma (1)} \wedge \cdots \wedge f^{\sigma (r)} &amp;= \text{sign} (\sigma) \cdot f^1 \wedge \cdots \wedge f^r \\ &amp;= \delta_{1 \cdots r}^{\sigma (1) \cdots \sigma (r)} f^1 \wedge \cdots \wedge f^r \end{aligned}\] <h3 id="外代数">外代数</h3> <blockquote class="block-theorem"> <h5 id="定理72">定理7.2</h5> <p>设\(\{ e^1, ..., e^n \}\)是对偶向量空间\(V^*\)的一个基底，则\(\{ e^{j_1} \wedge \cdots \wedge e^{j_r}, 1\leq j_1 \lt \cdots \lt j_r \leq n \}\)是\(r\)次外形式空间\(\bigwedge^r V^*\)的基底。特别是，空间\(\bigwedge^r V^*\)的维数是\(\dim \bigwedge^r V^* = C_n^r\)。当\(r \gt n\)时，\(\bigwedge^r V^* = \{ 0 \}\)。</p> </blockquote> <p><strong>证明</strong> 设\(f \in \bigwedge^r V^*\)，则\(f\)作为<a href="/blog/2024/DifferentialGeometry-NOTES-07/#%E5%A4%9A%E9%87%8D%E7%BA%BF%E6%80%A7%E5%87%BD%E6%95%B0">\(r\)重线性函数</a>可以表示为 \(f = f_{j_1 \cdots j_r} e^{j_1} \otimes \cdots \otimes e^{j_r}\)</p> <p>其中</p> \[f_{j_1 \cdots j_r} = f(\boldsymbol{e}_{j_1}, ..., \boldsymbol{e}_{j_r})\] <p>这里\(\{ \boldsymbol{e}_i \}\)是向量空间\(V\)中对偶的基底。因为\(f\)的反对称性，所以系数\(f_{j_1 \cdots j_r}\)关于下指标是反对称的，即</p> \[f_{j_{\sigma(1)} \cdots j_{\sigma(r)}} = \text{sign} (\sigma) f_{j_1 \cdots j_r}, \ \ \ \forall \sigma \in \mathfrak{G}_r\] <p>因此</p> \[\begin{aligned} f &amp;= [f] = f_{j_1 \cdots j_r} [e^{j_1} \otimes \cdots \otimes e^{j_r}] = \frac{1}{r!} f_{j_1 \cdots j_r} e^{j_1} \wedge \cdots \wedge e^{j_r} \\ &amp;= \sum_{1 \leq j_1 \lt \cdots \lt j_r \leq n} f_{j_1 \cdots j_r} e^{j_1} \wedge \cdots \wedge e^{j_r} \end{aligned}\] <p>这说明任意一个\(r\)次外形式\(f\)都能够表示成\(e^{j_1} \wedge \cdots \wedge e^{j_r}\)，\(1 \leq j_1 \lt \cdots \lt j_r \leq n\)的线性组合。</p> <p>为了证明这\(C_n^r\)个\(r\)次形式\(e^{j_1} \wedge \cdots \wedge e^{j_r}\)，\(1 \leq j_1 \lt \cdots \lt j_r \leq n\)是线性无关的，假定有一组实数\(_{j_1 \cdots j_r}\)，\(1 \leq j_1 \lt \cdots \lt j_r \leq n\)，使得线性组合</p> \[\sum_{1 \leq j_1 \lt \cdots \lt j_r \leq n} f_{j_1 \cdots j_r} e^{j_1} \wedge \cdots \wedge e^{j_r} = 0\] <p>将这个零函数在向量\(\boldsymbol{e}_{i_1}, ..., \boldsymbol{e}_{i_r}\)，\(1 \leq i_1 \lt \cdots \lt i_r \leq n\)上求值，得到</p> \[\begin{aligned} 0 &amp;= \sum_{1 \leq j_1 \lt \cdots \lt j_r \leq n} f_{j_1 \cdots j_r} e^{j_1} \wedge \cdots \wedge e^{j_r} (\boldsymbol{e}_{i_1}, ..., \boldsymbol{e}_{i_r}) \\ &amp;= \sum_{1 \leq j_1 \lt \cdots \lt j_r \leq n} f_{j_1 \cdots j_r} \delta_{i_1 \cdots i_r}^{j_1 \cdots j_r} = f_{i_1 \cdots i_r} \end{aligned}\] <p>由此可见，这组实数\(f_{j_1 \cdots j_r}\)，\(1 \leq j_1 \lt \cdots \lt j_r \leq n\)必须全部为零。证毕∎</p> <p>上面的构造可以从代数上进行抽象。假定\(W\)是任意一个\(n\)维向量空间，它的一个基底是\(\{ \boldsymbol{w}_1, ..., \boldsymbol{w}_n \}\)。把\(\boldsymbol{w}_1, ..., \boldsymbol{w}_n\)看作\(n\)个字母，构造实系数多项式，只是要求字母之间的乘法不是普通的交换乘法，而是反交换乘法。也就是在交换任意两个字母的位置时该乘积变号：</p> \[\boldsymbol{w}_i \wedge \boldsymbol{w}_j = - \boldsymbol{w}_j \wedge \boldsymbol{w}_i, \ \ \ \forall 1 \leq i, j \leq n\] <p>把这种乘法称为外积，假定多个字母的外积遵循结合律，同时假定分配律也成立。如此得到的多项式称为外多项式。由于</p> \[\boldsymbol{w}_i \wedge \boldsymbol{w}_i = - \boldsymbol{w}_i \wedge \boldsymbol{w}_i\] <p>故</p> \[\boldsymbol{w}_i \wedge \boldsymbol{w}_i = 0, \ \ \ \forall i\] <p>因此在外多项式的每一项中同一个字母不能出现两次，于是高于\(n\)次的齐次外多项式必定是零。这样，一次外多项式是字母\(\boldsymbol{w}_1, ..., \boldsymbol{w}_n\)的线性组合，它们构成向量空间\(W\)本身。二次外多项式是\(\boldsymbol{w}_i \wedge \boldsymbol{w}_j\)，\(1 \leq i \lt j \leq n\)的线性组合，它们构成的空间记成\(\bigwedge^2 W\)。一般地，\(k\)次外多项式是</p> \[\boldsymbol{w}_{i_1} \wedge \cdots \wedge \boldsymbol{w}_{i_k}, \ \ \ 1 \leq i_i \lt \cdots \lt i_k \leq n\] <p>的线性组合，它们构成的空间记成\(\bigwedge^k W\)。零次外多项式定义为实数本身。全体外多项式的集合记为</p> \[\bigwedge (W) = \sum_{k=0}^n \bigwedge^k W\] <p>其元素是各次外多项式的形式和。在集合\(\bigwedge (W)\)中有加法和外积运算，并且外积运算适合分配律、结合律和反交换律，所以从代数上讲，\(\bigwedge (W)\)是一个结合代数，称为向量空间\(W\)上的<strong>外代数</strong>。</p> <p>由此可见向量空间\(V\)上的外形式就是其对偶空间\(V^*\)的基底向量\(e^1, ..., e^n\)的外多项式。但是，我们在本节具体地、构造性地定义了外形式的外积，而不只是一种抽象的规定。这就是说，本节叙述的外形式的理论具体地构造出一个外代数。</p> <p>外多项式的形式化定义的好处在于消除外形式和外积的神秘感。从普通的多项式出发，只要规定字母之间的乘法是反交换的，则所得到的便是外多项式。</p> <p>具有反交换乘法的代数结构的例子还有：设\(\mathbb{R}^3\)是三维向量空间，「×」是该空间上的向量积(叉积)。容易验证，空间\(\mathbb{R}^3\)关于向量积是一个代数。不过，向量积不具有结合律，而满足所谓的<a href="https://en.wikipedia.org/wiki/Jacobi_identity" rel="external nofollow noopener" target="_blank">Jacobi恒等式</a>，因此\(\mathbb{R}^3\)关于向量积不是外代数，而是所谓的<a href="https://en.wikipedia.org/wiki/Lie_algebra" rel="external nofollow noopener" target="_blank">李代数</a>。</p> <p>最后，我们叙述一个重要的定理，它在微分几何中是十分有用的。</p> <p><a id="cartan-lemma"></a></p> <blockquote class="block-theorem"> <h5 id="定理73-cartan引理">定理7.3 (Cartan引理)</h5> <p>设\(\omega^1, ..., \omega^r\)，\(\theta_1, ..., \theta_r\)是\(n\)维向量空间\(V\)的\(2r\)个一次形式，其中\(\omega^1, ..., \omega^r\)是线性无关的。如果恒等式\(\sum_{\alpha = 1}^r \omega^\alpha \wedge \theta_\alpha = 0\)成立，则每一个\(\theta_\alpha\)必定是\(\omega^1, ..., \omega^r\)的线性组合，即\(\theta_\alpha = \sum_{\beta = 1}^r a_{\alpha \beta} \omega^\beta\)，并且组合系数\(a_{\alpha \beta}\)是对称的，即\(a_{\alpha \beta} = a_{\beta \alpha}\)。</p> </blockquote> <p><strong>证明</strong> 因为\(\omega^1, ..., \omega^r\)是线性无关的，所以可以把它们扩充成为对偶空间\(V^*\)的一个基底\(\omega^1, ..., \omega^r, \omega^{r+1}, ..., \omega^n\)，因此每一个一次形式\(\theta_\alpha\)可以由该基底表示，命</p> \[\theta_\alpha = \sum_{i=1}^n a_{\alpha i} \omega^i\] <p>已知空间\(\bigwedge^2 V^*\)的基底是\(\{ \omega^i \wedge \omega^j, 1 \leq i \lt j \leq n \}\)，将上式代入已知条件\(\sum_{\alpha = 1}^r \omega^\alpha \wedge \theta_\alpha = 0\)得到</p> \[\begin{aligned} 0 &amp; = \sum_{\alpha = 1}^r \omega^\alpha \wedge \theta_\alpha = \sum_{\alpha = 1}^r \sum_{i = 1}^n a_{\alpha i} \omega^\alpha \wedge \omega^i \\ &amp;= \sum_{\alpha = 1}^r \sum_{\beta = 1}^r a_{\alpha \beta} \omega^\alpha \wedge \omega^\beta + \sum_{\alpha = 1}^r \sum_{\xi = r+1}^n a_{\alpha \xi} \omega^\alpha \wedge \omega^\xi \\ &amp;= \sum_{1 \leq \alpha \lt \beta \leq r} (a_{\alpha \beta} - a_{\beta \alpha}) \omega^\alpha \wedge \omega^\beta + \sum_{\alpha = 1}^r \sum_{\xi = r+1}^n a_{\alpha \xi} \omega^\alpha \wedge \omega^\xi \end{aligned}\] <p>于是所有的组合系数必须为零，即</p> \[a_{\alpha \beta} - a_{\beta \alpha} = 0, \ \ \ \forall 1 \leq \alpha \lt \beta \leq r\] \[a _{\alpha \xi} = 0, \ \ \ \forall 1 \leq \alpha \leq r \lt \xi \leq n\] <p>这样\(\theta_\alpha\)成为</p> \[\theta_\alpha = \sum_{\beta = 1}^r a_{\alpha \beta} \omega^\beta\] <p>证毕∎</p> <h2 id="外微分式和外微分">外微分式和外微分</h2> <p>本节的主要内容是介绍外微分式的概念及其外微分运算。为此，我们首先复习曲纹坐标系的概念。</p> <h3 id="曲纹坐标系">曲纹坐标系</h3> <p>设欧式空间\(\mathbb{E}^3\)中的正则曲面\(S\)的参数方程是\(\boldsymbol{r} (u^1, u^2)\)，其中\((u^1, u^2) \in D \subset \mathbb{E}^2\)，则</p> \[\mathrm{d} \boldsymbol{r} = \boldsymbol{r}_\alpha \mathrm{d} u^\alpha\] <p>在<a href="/blog/2023/DifferentialGeometry-NOTES-03/#%E6%AD%A3%E5%88%99%E5%8F%82%E6%95%B0%E6%9B%B2%E9%9D%A2">前面的章节</a>，我们已经强调\((u^1, u^2)\)可以作为曲面\(S\)上的点\(p\)的坐标，称为曲面\(S\)上的点\(p\)的曲纹坐标。另外，从上式得知曲面\(S\)在点\(p\)的切空间的基底是\(\{ \boldsymbol{r}_1, \boldsymbol{r}_2 \}\)，而\((\mathrm{d} u^1, \mathrm{d} u^2)\)是在点\(p\)的任意一个切向量的分量，因此\(\mathrm{d} u^1\)、\(\mathrm{d} u^2\)分别是曲面\(S\)在点\(p\)的切空间\(T_p S\)上的线性函数，它们构成曲面\(S\)在点\(p\)的切空间的对偶空间上与自然基底\(\{ \boldsymbol{r}_1, \boldsymbol{r}_2 \}\)对偶的基底，记为\(\{ \mathrm{d} u^1, \mathrm{d} u^2 \}\)。我们把曲面\(S\)在点\(p\)的切空间\(T_p S\)的对偶空间称为曲面\(S\)在点\(p\)的<strong>余切空间</strong>，记为\(T_p^* S\)。余切空间\(T_p^* S\)中的元素称为曲面\(S\)在点\(p\)的<strong>余切向量</strong>，也就是曲面\(S\)在点\(p\)的切空间上的线性函数。</p> <p>上面的说法可以搬到欧氏空间\(\mathbb{E}^2\)的一个区域\(D\)上去，得到平面区域\(D\)上的曲纹坐标的概念。设\((x^1, x^2)\)是平面区域\(D\)上的笛卡尔直角坐标系，\((u^1, u^2)\)是另一个平面区域\(U\)上的笛卡儿直角坐标系。如果在平面区域\(U\)和\(D\)之间存在一个一一对应，它可以表示为从\(U\)到\(D\)的映射\(f: U \rightarrow D\), 即</p> \[x^1 = f^1 (u^1, u^2), \ \ \ x^2 = f^2 (u^1, u^2)\] <p>以及从\(D\)到\(U\)的逆映射\(g: D \rightarrow U\)，即</p> \[u^1 = g^1 (x^1, x^2), \ \ \ u^2 = g^2 (x^1, x^2)\] <p>并且假定函数\(f^\alpha (u^1, u^2)\)、\(g^\alpha (x^1, x^2)\)都是连续可微的，则称\((u^1, u^2)\)是平面区域\(D\)上的<strong>曲纹坐标系</strong>。如果让\(u^2\)的值固定，而让\(u^1\)变化，则我们再平面区域\(D\)上得到一条曲线，称为平面区域\(D\)上的一条\(u^1\)-曲线。同理，我们有平面区域\(D\)上的一条\(u^2\)-曲线。由于平面区域\(U\)和\(D\)的点之间是一一对应的，因此经过区域\(D\)上的每一点\(p\)只有一条\(u^1\)-曲线，也只有一条\(u^2\)-曲线。我们把\(u^1\)-曲线的切向量记为\(\frac{\partial}{\partial u^1}\)，把\(u^2\)-曲线的切向量记为\(\frac{\partial}{\partial u^2}\)，于是它们构成区域\(D\)在点\(p\)的切空间的基底，记为\(\{ \frac{\partial}{\partial u^1}, \frac{\partial}{\partial u^2} \}\)，同时区域\(D\)在点\(p\)的余切空间的基底是\(\{ \mathrm{d} u^1, \mathrm{d} u^2 \}\)。在点\(p\)的任意一个余切向量是\(\mathrm{d} u^1\)、\(\mathrm{d} u^2\)的线性组合。</p> <p>由于映射\(f: U \rightarrow D\)和\(g: D \rightarrow U\)互为逆映射，因此有恒等式</p> \[x^\alpha = f^\alpha \big( g^1 (x^1, x^2), g^2 (x^1, x^2) \big), \ \ \ \alpha = 1,2\] <p>和恒等式</p> \[u^\alpha = g^\alpha \big( f^1 (u^1, u^2), f^2 (u^1, u^2) \big), \ \ \ \alpha = 1,2\] <p>因为\(f^\alpha (u^1, u^2)\)，\(g^\alpha (x^1, x^2)\)都是连续可微函数，将\(u^\alpha\)对\(u^\beta\)求导得到</p> \[\frac{\partial g^\alpha}{\partial x^\gamma} \frac{\partial f^\gamma}{\partial u^\beta} = \delta_\beta^\alpha\] <p>所以Jacobi行列式</p> \[\frac{\partial (f^1, f^2)}{\partial (u^1, u^2)} \neq 0\] <p>反过来，根据反函数定理，如果有两个连续可微函数</p> \[x^1 = f^1 (u^1, u^2), \ \ \ x^2 = f^2 (u^1, u^2)\] <p>只要它们的Jacobi行列式\(\frac{\partial (f^1, f^2)}{\partial (u^1, u^2)}\)处处不为零，则在任意一点\((x_0^1, x_0^2)\)的一个邻域内存在反函数</p> \[u^1 = g^1 (x^1, x^2), \ \ \ u^2 = g^2 (x^1, x^2)\] <p>使得恒等式成立，因此\((u^1, u^2)\)可作为区域\(D\)在点\((x_0^1, x_0^2)\)的邻域内的曲纹坐标。由此可见，平面区域上的曲纹坐标系要比笛卡儿直角坐标系随意得多。克服笛卡儿直角坐标系的局限性是数学发展过程中的重要一步，同时曲纹坐标系的概念又导致微分流形概念的产生。</p> <p>一般地，设\((x^1, ..., x^n)\)是\(n\)维欧氏空间\(\mathbb{E}^n\)中的区域\(D\)上的笛卡儿直角坐标系，\((u^1, ..., u^n)\)是\(n\)维欧氏空间\(\mathbb{E}^n\)中的另一个区域\(U\)上笛卡儿直角坐标系。如果在区域\(U\)和\(D\)之间存在一个一一对应，它可以表示为从\(U\)到\(D\)的映射\(f: U \rightarrow D\)，即</p> \[x^1 = f^1 (u^1, ..., u^n), \cdots , x^n = f^n (u^1, ..., u^n)\] <p>以及从\(D\)到\(U\)的逆映射\(g: D \rightarrow U\)，即</p> \[u^1 = g^1 (x^1, ..., x^n), \cdots , u^n = g^n (x^1, ..., x^n)\] <p>并且假定函数\(f^\alpha (u^1, ..., u^n)\)，\(g^\alpha (x^1, ..., x^n)\)都是连续可微的，则称\((u^1, ..., u^n)\)是区域\(D\)上的曲纹坐标系。区域\(D\)在点\(p\)的切空间的自然基底是\(\{ \frac{\partial}{\partial u^1}, ..., \frac{\partial}{\partial u^n} \}\)，同时区域\(D\)在点\(p\)的余切空间的基底是\(\{ \mathrm{d} u^1, ..., \mathrm{d} u^n \}\)。在点\(p\)的任意一个余切向量是\(\mathrm{d} u^1, ..., \mathrm{d} u^n\)的线性组合。</p> <p>反过来，根据反函数定理，如果有\(n\)个连续可微函数</p> \[x^1 = f^1 (u^1, ..., u^n), \cdots , x^n = f^n (u^1, ..., u^n)\] <p>只要它们满足条件</p> \[\frac{\partial (f^1, ..., f^n)}{\partial (u^1, ..., u^n)} \neq 0\] <p>则在任意一点\((x_0^1, ..., x_0^n)\)的一个邻域内存在反函数</p> \[u^1 = g^1 (x^1, ..., x^n), \cdots , u^n = g^n (x^1, ..., x^n)\] <p>使得恒等式</p> \[x^\alpha = f^\alpha (g^1 (x^1, ..., x^n), ..., g^n (x^1, ..., x^n)), \ \ \ 1 \leq \alpha \leq n\] <p>和恒等式</p> \[u^\alpha = g^\alpha (f^1 (u^1, ..., u^n), ..., f^n (u^1, ..., u^n)), \ \ \ 1 \leq \alpha \leq n\] <p>成立，因此\((u^1, ..., u^n)\)可以作为区域\(D\)在点\((x_0^1, ..., x_0^n)\)的邻域内的曲纹坐标。由此可见，\(\frac{\partial (f^1, ..., f^n)}{\partial (u^1, ..., u^n)} \neq 0\)是函数组\(f^1, ..., f^n\)能够在点\((x_0^1, ..., x_0^n)\)的邻域内引进曲纹坐标系\((u^1, ..., u^n)\)的充分必要条件。</p> <p>在20世纪中叶，所谓的大范围微分几何和大范围分析的课题成为数学研究的热门课题，所考虑的空间不再限于具有笛卡儿直角坐标系的欧氏空间，而只要求这种空间在局部上具有曲纹坐标系，并且容许曲纹坐标系作一定的变换，这种空间就是现在所称的<strong>微分流形</strong>。稍微确切一点说，所谓的\(n\)维微分流形是指由\(n\)维欧氏空间中的一些小块区域一片、一片连续可微地拼接起来得到的空间。这里，「连续可微地拼接起来」的意思是在有些小块区域的某部分可以通过其上面的曲纹坐标的正则的连续可微的函数关系等同起来。当\(n=2\)时，这就是<a href="/blog/2024/DifferentialGeometry-NOTES-06/#%E6%8A%BD%E8%B1%A1%E6%9B%B2%E9%9D%A2%E4%B8%8A%E7%9A%84%E5%87%A0%E4%BD%95%E5%AD%A6">前面</a>所叙述的二维光滑流形。以后为方便起见，总是假定连续可微函数指它有连续的任意阶的各种偏导数，有时也称这种函数是光滑函数。在\(n\)维微分流形的每一点有切向量、切空间、余切向量、余切空间的概念，特别地在曲纹坐标系\((u^1, ..., u^n)\)下\(\{ \mathrm{d} u^1, ..., \mathrm{d} u^n \}\)是\(n\)维微分流形在一点的余切空间的基底。</p> <h3 id="外微分式">外微分式</h3> <p>现在，我们要给出外微分式的定义。</p> <blockquote class="block-definition"> <h5 id="定义72">定义7.2</h5> <p>设\(D\)是\(n\)为欧式空间\(\mathbb{E}^n\)中的一个区域，\((u^1, ..., u^n)\)是区域\(D\)上的曲纹坐标系。如果以连续可微的方式在每一点\(p = (u^1, ..., u^n) \in D\)给定了一个\(r\)次外形式</p> <center> $$ \begin{aligned} \varphi (p) &amp;= \frac{1}{r!} \varphi_{i_1 \cdots i_r} (u^1, ..., u^n) \mathrm{d} u^{i_1} \wedge \cdots \wedge \mathrm{d} u^{i_r} \\ &amp;= \sum_{1 \leq i_1 \lt \cdots \lt i_r \leq n} \varphi_{i_1 \cdots i_r} (u^1, ..., u^n) \mathrm{d} u^{i_1} \wedge \cdots \wedge \mathrm{d} u^{i_r} \end{aligned} $$ </center> <p>其中假定系数函数\(\varphi_{i_1 \cdots i_r} (u^1, ..., u^n)\)对于下指标是反对称的，则称\(\varphi\)是定义在\(D\)上的<strong>\(r\)次外微分式</strong>。</p> </blockquote> <p>在这里，所谓的「以连续可微的方式」是指系数\(\varphi_{i_1 \cdots i_r} (u^1, ..., u^n)\)，\(1 \leq i_1 \lt \cdots \lt i_r \leq n\)是\(u^1, ..., u^n\)的连续可微函数，即\(\varphi_{i_1 \cdots i_r} (u^1, ..., u^n)\)是\(u^1, ..., u^n\)的光滑函数。</p> <p>设\(f: D \rightarrow \mathbb{R}\)是定义在\(D\)上的连续可微函数，则它的微分</p> \[\mathrm{d} f = \frac{\partial f}{\partial u^i} \mathrm{d} u^i\] <p>即为区域\(D\)上的1次微分式，因而也是\(D\)上的一个1次外微分式。</p> <p>设\(S\)是三维欧式空间\(\mathbb{E}^3\)中的一块正则参数曲面，参数方程是</p> \[\boldsymbol{r} = \boldsymbol{r} (u^1, u^2)\] <p>并且它的第一基本形式是</p> \[\mathrm{I} = g_{\alpha \beta} \mathrm{d} u^\alpha \mathrm{d} u^\beta\] <p>命</p> \[\mathrm{d} \sigma = \sqrt{g_{11} g_{22} - (g_{12})^2} \mathrm{d} u^1 \wedge \mathrm{d} u^2\] <p>则\(\mathrm{d} \sigma\)是曲面\(S\)上的一个2次微分式。</p> <p>容易证明：2次微分式\(\mathrm{d} \sigma\)在曲面\(S\)的保持定向的容许参数变换下是不变的。实际上，如果\((\tilde{u}^1, \tilde{u}^2)\)是曲面\(S\)的另一个保持定向的参数系，于是\(\tilde{u}^\alpha = \tilde{u}^\alpha (u^1, u^2)\)的至少3次以上连续可微的函数，并且</p> \[\frac{\partial (\tilde{u}^1, \tilde{u}^2)}{\partial (u^1, u^2)} \gt 0\] <p>假定曲面\(S\)的第一基本形式用新参数\((\tilde{u}^1, \tilde{u}^2)\)的表达式是</p> \[\mathrm{I} = \tilde{g}_{\alpha \beta} \mathrm{d} \tilde{u}^\alpha \mathrm{d} \tilde{u}^\beta\] <p>则根据<a href="/blog/2023/DifferentialGeometry-NOTES-03/#%E7%AC%AC%E4%B8%80%E5%9F%BA%E6%9C%AC%E5%BD%A2%E5%BC%8F%E7%9A%84%E4%B8%8D%E5%8F%98%E6%80%A7">第一基本形式的不变性</a>，在第一类基本量\(\tilde{g}_{\alpha \beta}\)和\(g_{\alpha \beta}\)之间有关系式</p> \[\begin{pmatrix} g_{11} &amp; g_{12} \\ g_{21} &amp; g_{22} \end{pmatrix} = J \cdot \begin{pmatrix} \tilde{g}_{11} &amp; \tilde{g}_{12} \\ \tilde{g}_{21} &amp; \tilde{g}_{22} \end{pmatrix} \cdot J^T\] <p>其中</p> \[J = \begin{pmatrix} \frac{\partial \tilde{u}^1}{\partial u^1} &amp; \frac{\partial \tilde{u}^2}{\partial u^1} \\ \frac{\partial \tilde{u}^1}{\partial u^2} &amp; \frac{\partial \tilde{u}^2}{\partial u^2} \\ \end{pmatrix}\] <p>对等式两边取行列式得到</p> \[g_{11} g_{22} - (g_{12})^2 = (\det{J})^2 (\tilde{g}_{11} \tilde{g}_{22} - (\tilde{g}_{12})^2)\] <p>因此</p> \[\sqrt{g_{11} g_{22} - (g_{12})^2} = \vert \det{J} \vert \cdot \sqrt{\tilde{g}_{11} \tilde{g}_{22} - (\tilde{g}_{12})^2}\] <p>但是根据已知条件，Jacobi行列式大于0</p> \[\det{J} = \begin{vmatrix} \frac{\partial \tilde{u}^1}{\partial u^1} &amp; \frac{\partial \tilde{u}^2}{\partial u^1} \\ \frac{\partial \tilde{u}^1}{\partial u^2} &amp; \frac{\partial \tilde{u}^2}{\partial u^2} \\ \end{vmatrix} = \frac{\partial (\tilde{u}^1, \tilde{u}^2)}{\partial (u^1, u^2)} \gt 0\] <p>所以关于第一基本形式的等式成为</p> \[\sqrt{g_{11} g_{22} - (g_{12})^2} = \det{J} \cdot \sqrt{\tilde{g}_{11} \tilde{g}_{22} - (\tilde{g}_{12})^2}\] <p>在另一方面，对函数\(\tilde{u}^\alpha (u^1, u^2)\)求微分得到</p> \[\mathrm{d} \tilde{u}^\alpha = \frac{\partial \tilde{u}^\alpha}{\partial u^1} \mathrm{d} u^1 + \frac{\partial \tilde{u}^\alpha}{\partial u^2} \mathrm{d} u^2, \ \ \ \alpha = 1, 2\] <p>因此</p> \[\begin{aligned} \mathrm{d} \tilde{u}^1 \wedge \mathrm{d} \tilde{u}^2 &amp;= \bigg( \frac{\partial \tilde{u}^1}{\partial u^1} \mathrm{d} u^1 + \frac{\partial \tilde{u}^1}{\partial u^2} \mathrm{d} u^2 \bigg) \wedge \bigg( \frac{\partial \tilde{u}^2}{\partial u^1} \mathrm{d} u^1 + \frac{\partial \tilde{u}^2}{\partial u^2} \mathrm{d} u^2 \bigg) \\ &amp;= \frac{\partial (\tilde{u}^1, \tilde{u}^2)}{\partial (u^1, u^2)} \mathrm{d} u^1 \wedge \mathrm{d} u^2 \end{aligned}\] <p>综合前面的推导可以得到</p> \[\begin{aligned} \sqrt{\tilde{g}_{11} \tilde{g}_{22} - (\tilde{g}_{12})^2} \mathrm{d} \tilde{u}^1 \wedge \mathrm{d} \tilde{u}^2 &amp;= \sqrt{\tilde{g}_{11} \tilde{g}_{22} - (\tilde{g}_{12})^2} \frac{\partial (\tilde{u}^1, \tilde{u}^2)}{\partial (u^1, u^2)} \mathrm{d} u^1 \wedge \mathrm{d} u^2 \\ &amp;= \sqrt{g_{11} g_{22} - (g_{12})^2} \mathrm{d} u^1 \wedge \mathrm{d} u^2 \end{aligned}\] <p>这就证明了2次微分式\(\mathrm{d} \sigma\)在曲面\(S\)的保持定向的容许参数变换下是不变的。</p> <p>这个事实蕴涵着一个十分重要的结果。我们在前已经定义过<a href="/blog/2023/DifferentialGeometry-NOTES-03/#%E6%AD%A3%E5%88%99%E6%9B%B2%E9%9D%A2">正则曲面</a>的概念(<strong>定义3.1</strong>)，它是一片、一片正则参数曲面粘合的结果，在重叠部分会有多个曲纹坐标系，但是在不同的曲纹坐标系之间的变换都是容许的参数变换。上面的断言表明，虽然2次微分式\(\mathrm{d} \sigma\)在曲面\(S\)的每一个参数表示是\(\mathrm{d} \sigma = \sqrt{g_{11} g_{22} - (g_{12})^2} \mathrm{d} u^1 \wedge \mathrm{d} u^2\)，但是它在实际上是定义在整个有向正则曲面\(S\)上的2次外微分式。同样，有向抽象曲面(二维黎曼流形)上也有定义在整个曲面上的2次微分式\(\mathrm{d} \sigma\)。在这里，我们具体地描述了构造定义在整个有向曲面\(S\)上的量的一种方式，即这个量可以用局部坐标来表示、但是与局部坐标系的选择无关。这种方式有普遍意义。</p> <p>2次外微分式\(\mathrm{d} \sigma\)称为在曲面\(S\)上的<strong>面积元素</strong>，其理由如下：假设在曲纹坐标系\((u^1, u^2)\)下，在点\(p\)给定两个切向量</p> \[\boldsymbol{a} = a^1 \boldsymbol{r}_1 + a^2 \boldsymbol{r}_2, \ \ \ \boldsymbol{b} = b^1 \boldsymbol{r}_1 + b^2 \boldsymbol{r}_2\] <p>那么</p> \[\begin{aligned} \mathrm{d} \sigma (\boldsymbol{a}, \boldsymbol{b}) &amp;= \sqrt{g_{11} g_{22} - (g_{12})^2} \mathrm{d} u^1 \wedge \mathrm{d} u^2 (\boldsymbol{a}, \boldsymbol{b}) \\ &amp;= \sqrt{g_{11} g_{22} - (g_{12})^2} \big( \mathrm{d} u^1 (\boldsymbol{a}) \mathrm{d} u^2 (\boldsymbol{b}) - \mathrm{d} u^1 (\boldsymbol{b}) \mathrm{d} u^2 (\boldsymbol{a}) \big) \\ &amp;= \sqrt{g_{11} g_{22} - (g_{12})^2} (a^1 b^2 - b^1 a^2) \end{aligned}\] <p>作切向量\(\boldsymbol{a}\)、\(\boldsymbol{b}\)的向量积得到</p> \[\begin{aligned} \boldsymbol{a} \times \boldsymbol{b} &amp;= (a^1 b^2 - b^1 a^2) \boldsymbol{r}_1 \times \boldsymbol{r}_2 \\ &amp;= (a^1 b^2 - b^1 a^2) \vert \boldsymbol{r}_1 \times \boldsymbol{r}_2 \vert \cdot \boldsymbol{n} \\ &amp;= (a^1 b^2 - b^1 a^2) ( \vert \boldsymbol{r}_1 \vert \cdot \vert \boldsymbol{r}_2 \vert \sin{\angle (\boldsymbol{a} , \boldsymbol{b})} ) \cdot \boldsymbol{n} \\ &amp;= (a^1 b^2 - b^1 a^2) \vert \boldsymbol{r}_1 \vert \cdot \vert \boldsymbol{r}_2 \vert \sqrt{1 - \cos^2{\angle (\boldsymbol{a} , \boldsymbol{b})} } \cdot \boldsymbol{n} \\ &amp;= (a^1 b^2 - b^1 a^2) \sqrt{g_{11} g_{22} - (g_{12})^2} \cdot \boldsymbol{n} \end{aligned}\] <p>因此</p> \[\mathrm{d} \sigma (\boldsymbol{a}, \boldsymbol{b}) = \pm \vert \boldsymbol{a} \times \boldsymbol{b} \vert\] <p>换言之，\(\mathrm{d} \sigma (\boldsymbol{a}, \boldsymbol{b})\)恰好是切向量\(\boldsymbol{a} \times \boldsymbol{b}\)所张的平行四边形的有向面积。</p> <h3 id="外微分">外微分</h3> <p>区域\(D\)上的任意两个同次的外微分式能够以逐点计算的方式作加法和外积运算。对于外微分式来说，更重要的一种运算是外微分，它把\(r\)次外微分式变为一个\(r+1\)次外微分式。</p> <blockquote class="block-definition"> <h5 id="定义73">定义7.3</h5> <p>设 \(\varphi = \frac{1}{r!} \varphi_{i_1 \cdots i_r} \mathrm{d} u^{i_1} \wedge \cdots \wedge \mathrm{d} u^{i_r}\) 是定义在区域\(D\)上的一个\(r\)次外微分式。用如下的方式定义\(r+1\)次外微分式：</p> <center> $$ \begin{aligned} \mathrm{d} \varphi &amp;= \frac{1}{r!} \mathrm{d} \varphi_{i_1 \cdots i_r} \mathrm{d} u^{i_1} \wedge \cdots \wedge \mathrm{d} u^{i_r} \\ &amp;= \frac{1}{r!} \frac{\partial \varphi_{i_1 \cdots i_r}}{\partial u^j} \mathrm{d} u^j \wedge \mathrm{d} u^{i_1} \wedge \cdots \wedge \mathrm{d} u^{i_r} \end{aligned} $$ </center> <p>称为\(\varphi\)的<strong>外微分</strong>。如果\(\varphi: D \rightarrow \mathbb{R}\)是定义在\(D\)上的连续可微函数(即零次外微分式)，则它的外微分\(\mathrm{d} \varphi\)就是它的普通微分。</p> </blockquote> <blockquote class="block-theorem"> <h5 id="定理74">定理7.4</h5> <p>外微分运算\(\mathrm{d}\)遵循下面的运算法则：<br> (1) \(\mathrm{d}\)是线性算子，即对于任意的外微分式\(\varphi^1\)、\(\varphi^2\)有 \(\mathrm{d} (\varphi^1 + \varphi^2) = \mathrm{d} \varphi^1 + \mathrm{d} \varphi^2\) ， \(\mathrm{d} (c \cdot \varphi^1) = c \cdot \mathrm{d} \varphi^1, \ \ \ \forall c \in \mathbb{R}\)<br> (2) \(\mathrm{d} \circ \mathrm{d} = 0\)，即对于任意一个外微分式\(\varphi\)，有 \(\mathrm{d} (\mathrm{d} \varphi) = 0\) (3) 若\(\varphi\)是\(r\)次外微分式，则对于任意一个外微分式\(\psi\)，有 \(\mathrm{d} (\varphi \wedge \psi) = \mathrm{d} \varphi \wedge \psi + (-1)^r \varphi \wedge \mathrm{d} \psi\)</p> </blockquote> <p>关于运算法则(3)有两个特殊情形需要特别强调一些。若\(f\)是定义在区域\(D\)上的零次外微分式，即\(f\)是定义在区域\(D\)上的连续可微函数，则由(3)得到</p> \[\mathrm{d} (f \psi) = \mathrm{d} f \wedge \psi + f \mathrm{d} \psi\] <p>若\(\varphi\)是定义在区域\(D\)上的一次外微分式，则</p> \[\mathrm{d} (\varphi \wedge \psi) = \mathrm{d} \varphi \wedge \psi - \varphi \wedge \mathrm{d} \psi\] <p>外微分运算还有一个更重要的性质，也就是外微分\(\mathrm{d}\)与外微分式的参数表示的方式无关，这称为「外微分\(\mathrm{d}\)的形式不变性」，是微积分学中「一次微分的形式不变性」的推广。确切地说我们有下面的定理。</p> <blockquote class="block-theorem"> <h5 id="定理75">定理7.5</h5> <p>设\(\varphi\)是定义在\(n\)维区域\(D\)上的一个\(r\)次外微分式，它在曲纹坐标系\((u^1, ..., u^n)\)下的表示是</p> <center> $$ \varphi = \frac{1}{r!} \varphi_{i_1 \cdots i_r} (u^1, ..., u^n) \mathrm{d} u^{i_1} \wedge \cdots \wedge \mathrm{d} u^{i_r} $$ </center> <p>在另一个曲纹坐标系\((\tilde{u}^1, ..., \tilde{u}^n)\)下的表示是</p> <center> $$ \varphi = \frac{1}{r!} \tilde{\varphi}_{i_1 \cdots i_r} (\tilde{u}^1, ..., \tilde{u}^n) \mathrm{d} \tilde{u}^{i_1} \wedge \cdots \wedge \mathrm{d} \tilde{u}^{i_r} $$ </center> <p>其中假定\(\varphi_{i_1 \cdots i_r}\)和\(\tilde{\varphi}_{i_1 \cdots i_r}\)对下指标都是反对称的，则有</p> <center> $$ \mathrm{d} \varphi_{i_1 \cdots i_r} \wedge \mathrm{d} u^{i_1} \wedge \cdots \wedge \mathrm{d} u^{i_r} = \mathrm{d} \tilde{\varphi}_{i_1 \cdots i_r} \wedge \mathrm{d} \tilde{u}^{i_1} \wedge \cdots \wedge \mathrm{d} \tilde{u}^{i_r} $$ </center> </blockquote> <p><strong>证明</strong> 由于不同的曲纹坐标系之间有容许的坐标变换，设为</p> \[\tilde{u}^i = \tilde{u}^i (u^1, ..., u^n), \ \ \ 1 \leq i \leq n\] <p>故</p> \[\mathrm{d} \tilde{u}^i = \frac{\partial \tilde{u}^i}{\partial u^j} \cdot \mathrm{d} u^j\] <p>因此</p> \[\begin{aligned} \varphi_{i_1 \cdots i_r} &amp;(u^1, ..., u^n) \mathrm{d} u^{i_1} \wedge \cdots \wedge \mathrm{d} u^{i_r} \\ &amp;= \tilde{\varphi}_{j_1 \cdots j_r} (\tilde{u}^1, ..., \tilde{u}^n) \mathrm{d} \tilde{u}^{j_1} \wedge \cdots \wedge \mathrm{d} \tilde{u}^{j_r} \\ &amp;= \tilde{\varphi}_{j_1 \cdots j_r} (\tilde{u}^1, ..., \tilde{u}^n) \frac{\partial \tilde{u}^{j_1}}{\partial u^{i_1}} \cdots \frac{\partial \tilde{u}^{j_r}}{\partial u^{i_r}} \mathrm{d} u^{i_1} \wedge \cdots \wedge \mathrm{d} u^{i_r} \end{aligned}\] <p>很明显，\(\tilde{\varphi}_{j_1 \cdots j_r} \frac{\partial \tilde{u}^{j_1}}{\partial \tilde{u}^{i_1}} \cdots \frac{\partial \tilde{u}^{j_r}}{\partial \tilde{u}^{i_r}}\)对于下指标\(i_1, ..., i_r\)仍然是反对称的，因此比较上式的前后两端的系数得到</p> \[\varphi_{i_1 \cdots i_r} = \tilde{\varphi}_{j_1 \cdots j_r} \frac{\partial \tilde{u}^{j_1}}{\partial u^{i_1}} \cdots \frac{\partial \tilde{u}^{j_r}}{\partial u^{i_r}}\] <p>对上式求微分得到</p> \[\begin{aligned} \mathrm{d} \varphi_{i_1 \cdots i_r} &amp;= \frac{\partial}{\partial u^k} \bigg( \tilde{\varphi}_{j_1 \cdots j_r} \frac{\partial \tilde{u}^{j_1}}{\partial \tilde{u}^{i_1}} \cdots \frac{\partial \tilde{u}^{j_r}}{\partial \tilde{u}^{i_r}} \bigg) \mathrm{d} u^k \\ &amp;= \bigg( \frac{\partial \tilde{\varphi}_{j_1 \cdots j_r}}{\partial \tilde{u}^l} \frac{\partial \tilde{u}^l}{\partial u^k} \frac{\partial \tilde{u}^{j_1}}{\partial u^{i_1}} \cdots \frac{\partial \tilde{u}^{j_r}}{\partial u^{i_r}} + \tilde{\varphi}_{j_1 \cdots j_r} \frac{\partial^2 \tilde{u}^{j_1}}{\partial u^k \partial u^{i_1}} \cdots \frac{\partial \tilde{u}^{j_r}}{\partial u^{i_r}} \\ &amp;+ \cdots + \tilde{\varphi}_{j_1 \cdots j_r} \frac{\partial \tilde{u}^{j_1}}{\partial u^{i_1}} \cdots \frac{\partial^2 \tilde{u}^{j_r}}{\partial u^k \partial u^{i_r}} \bigg) \mathrm{d} u^k \end{aligned}\] <p>所以</p> \[\begin{aligned} \mathrm{d} \varphi_{i_1 \cdots i_r} &amp;\wedge \mathrm{d} u^{i_1} \wedge \cdots \wedge \mathrm{d} u^{i_r} \\ &amp;= \bigg( \frac{\partial \tilde{\varphi}_{j_1 \cdots j_r}}{\partial \tilde{u}^l} \frac{\partial \tilde{u}^l}{\partial u^k} \frac{\partial \tilde{u}^{j_1}}{\partial u^{i_1}} \cdots \frac{\partial \tilde{u}^{j_r}}{\partial u^{i_r}} + \tilde{\varphi}_{j_1 \cdots j_r} \frac{\partial^2 \tilde{u}^{j_1}}{\partial u^k \partial u^{i_1}} \cdots \frac{\partial \tilde{u}^{j_r}}{\partial u^{i_r}} \\ &amp;+ \cdots + \tilde{\varphi}_{j_1 \cdots j_r} \frac{\partial \tilde{u}^{j_1}}{\partial u^{i_1}} \cdots \frac{\partial^2 \tilde{u}^{j_r}}{\partial u^k \partial u^{i_r}} \bigg) \mathrm{d} u^k \wedge \mathrm{d} u^{i_1} \wedge \cdots \wedge \mathrm{d} u^{i_r} \\ &amp;= \frac{\partial \tilde{\varphi}_{j_1 \cdots j_r}}{\partial \tilde{u}^l} \frac{\partial \tilde{u}^l}{\partial u^k} \frac{\partial \tilde{u}^{j_1}}{\partial u^{i_1}} \cdots \frac{\partial \tilde{u}^{j_r}}{\partial u^{i_r}} \mathrm{d} u^k \wedge \mathrm{d} u^{i_1} \wedge \cdots \wedge \mathrm{d} u^{i_r} \\ &amp;= \frac{\partial \tilde{\varphi}_{j_1 \cdots j_r}}{\partial \tilde{u}^l} \mathrm{d} \tilde{u}^l \wedge \mathrm{d} \tilde{u}^{j_1} \wedge \cdots \wedge \mathrm{d} \tilde{u}^{j_r} \\ &amp;= \mathrm{d} \tilde{\varphi}_{j_1 \cdots j_r} \wedge \mathrm{d} \tilde{u}^{j_1} \wedge \cdots \wedge \mathrm{d} \tilde{u}^{j_r} \end{aligned}\] <p>在这里，第二个等号成立的理由是除了第1项以外，其余各项全部为零，例如</p> \[\begin{aligned} \frac{\partial^2 \tilde{u}^{j_1}}{\partial u^k \partial u^{i_1}} &amp;\cdots \frac{\partial \tilde{u}^{j_r}}{\partial u^{i_r}} \mathrm{d} u^k \wedge \mathrm{d} u^{i_1} \wedge \cdots \wedge \mathrm{d} u^{i_r} \\ &amp;= \frac{1}{2} \bigg( \frac{\partial^2 \tilde{u}^{j_1}}{\partial u^k \partial u^{i_1}} - \frac{\partial^2 \tilde{u}^{j_1}}{\partial u^{i_1} \partial u^k} \bigg) \cdots \frac{\partial \tilde{u}^{j_r}}{\partial u^{i_r}} \mathrm{d} u^k \wedge \mathrm{d} u^{i_1} \wedge \cdots \wedge \mathrm{d} u^{i_r} \\ &amp;= 0 \end{aligned}\] <p>证毕∎</p> <p>根据<strong>定理7.5</strong>，外微分实际上是定义在整个正则曲面\(S\)上的算子，或者更一般地，外微分是定义在光滑流形上的算子。因为在这种空间每一点的邻域内有局部坐标系，而在不同的局部坐标系之间有容许的坐标变换，但是外微分算子与局部坐标系的选取无关，所以它是在整个空间上定义好的算子。这就是说，给定一个定义在光滑流形\(M\)上的一个\(r\)次外微分式，尽管在不同的局部坐标系下，外微分式有不同的表达式，但是它们的外微分仍旧是同一个外微分式在相应的局部坐标系下的表达式。因此，外微分运算把定义在整个流形\(M\)上的一个\(r\)次外微分式变成定义在整个流形\(M\)上的一个确定的\(r+l\)次外微分式。</p> <p><strong>定理7.5</strong>还可以作一些推广，这在以后十分有用。设有另一个\(m\)维区域\(\tilde{D}\)，曲纹坐标系是\((\tilde{u}^1, ..., \tilde{u}^m)\)，并且\(\sigma: D \rightarrow \tilde{D}\)是一个连续可微映射，表示为</p> \[\tilde{u}^\alpha = \tilde{u}^\alpha (u^1, ..., u^n), \ \ \ \alpha = 1, ..., m\] <p>映射\(\sigma\)诱导出一个映射\(\sigma^*\)，它把定义在区域\(\tilde{D}\)上的\(r\)次外微分式变为区域\(D\)上的\(r\)次外微分式。例如，设</p> \[\tilde{\varphi} = \frac{1}{r!} \sum_{1 \leq \alpha_1, ..., \alpha_r \leq m} \tilde{\varphi}_{\alpha_1 ... \varphi_r} (\tilde{u}^1, ..., \tilde{u}^m) \mathrm{d} \tilde{u}^{\alpha_1} \wedge \cdots \wedge \mathrm{d} \tilde{u}^{\alpha_r}\] <p>则\(\sigma^* \tilde{\varphi}\)是区域\(D\)上的\(r\)次外微分形式，它是把\(\tilde{u}^\alpha\)代入\(\tilde{\varphi}\)式所得到的结果，即</p> \[\begin{aligned} \sigma^* \tilde{\varphi} &amp;= \frac{1}{r!} \tilde{\varphi}_{\alpha_1 ... \varphi_r} (\tilde{u}^1 (u^1, ..., u^n), ..., \tilde{u}^m (u^1, ..., u^n)) \\ &amp;\cdot \frac{\partial \tilde{u}^{\alpha_1}}{\partial u^{i_1}} \cdots \frac{\partial \tilde{u}^{\alpha_r}}{\partial u^{i_r}} \mathrm{d} u^{\alpha_1} \wedge \cdots \wedge \mathrm{d} u^{\alpha_r} \end{aligned}\] <p>其中指标\(\alpha_1, ..., \alpha_r\)的取值范围从1到\(m\)，指标\(i_1, ..., i_r\)的取值范围从1到\(n\)，并且上式使用了Einstein和式约定。通常，我们把\(\sigma^* \tilde{\varphi}\)称为区域\(\tilde{D}\)上的\(r\)次外微分式\(\tilde{\varphi}\)通过映射\(\sigma\)在区域\(D\)上的<strong>拉回</strong>。</p> <p><a id="theorem7.6"></a></p> <blockquote class="block-theorem"> <h5 id="定理76">定理7.6</h5> <p>设\(\sigma: \tilde{D} \rightarrow D\)是连续可微映射，则对区域\(\tilde{D}\)上的任意外微分式\(\tilde{\varphi}\)、\(\tilde{\psi}\)有下面的等式：<br> (1) \(\sigma^* (\varphi + \psi) = \sigma^* \varphi + \sigma^* \psi\)<br> (2) \(\sigma^* (\varphi \wedge \psi) = \sigma^* \varphi \wedge \sigma^* \psi\)<br> (3) \(\sigma^* (\mathrm{d} \varphi) = \mathrm{d} (\sigma^* \varphi)\)</p> </blockquote> <p>把微积分学中的重积分的被积表达式写成外微分式是更加自然的，因为此时积分的变扯替换公式可以通过直接计算得到。例如，考虑二维区域上的重积分\(\iint_D f(x, y) \ \mathrm{d} x \mathrm{d} y\)，其中的\(\mathrm{d} x \mathrm{d} y\)应该换成\(\mathrm{d} x \wedge \mathrm{d} y\)。如果有变量替换</p> \[x = x(u, v), \ \ \ y = y(u, v), \ \ \ (u, v) \in \tilde{D}\] <p>则</p> \[\mathrm{d} x \wedge \mathrm{d} y = \begin{vmatrix} \frac{\partial x}{\partial u} &amp; \frac{\partial x}{\partial v} \\ \frac{\partial y}{\partial u} &amp; \frac{\partial y}{\partial v} \\ \end{vmatrix} \mathrm{d} u \wedge \mathrm{d} v = \frac{\partial (x, y)}{\partial (u, v)} \mathrm{d} u \wedge \mathrm{d} v\] <p>所以</p> \[\iint_D f(x, y) \ \mathrm{d} x \wedge \mathrm{d} y = \iint_{\tilde{D}} f(x(u, v), y(u, v)) \cdot \frac{\partial (x, y)}{\partial (u, v)} \mathrm{d} u \wedge \mathrm{d} v\] <p>这正好是二重积分的变量替换公式。三重积分的情况是一样的。</p> <h3 id="stokes公式">Stokes公式</h3> <p>采用外微分的语言，积分的Green公式、Stokes公式和Gauss 公式可以统一地表述如下：设\(G\)是\(n\)维欧式空间\(\mathbb{E}^n\)中的一个\(r\)维有向曲面上的一个区域，\(\partial G\)是\(G\)的边界，具有从\(G\)诱导的定向，\(\omega\)是定义在\(G\)上的\(r-1\)次外微分式，则有</p> \[\int_{\partial G} \omega = \int_G \mathrm{d} \omega\] <p>上式统称为<strong>Stokes公式</strong>。</p> <h2 id="e中的标架族">E³中的标架族</h2> <h3 id="活动标架的运动公式">活动标架的运动公式</h3> <p>在<a href="/blog/2023/DifferentialGeometry-NOTES-01/#%E6%AD%A3%E4%BA%A4%E6%A0%87%E6%9E%B6">第一章</a>中， 我们已经讨论过由\(\mathbb{E}^3\)中的标架的全体所组成的12维空间。具体一点说，就是在\(\mathbb{E}^3\)中取定一个右手单位正交标架\(\{ O; \boldsymbol{i}, \boldsymbol{j}, \boldsymbol{k} \}\)，那么在\(\mathbb{E}^3\)中的任意一个右手标架\(\{ p; \boldsymbol{e}_1, \boldsymbol{e}_2, \boldsymbol{e}_3 \}\)都可以表示成</p> <p><a id="frame-definition"></a></p> \[\begin{pmatrix} \overrightarrow{Op} \\ \boldsymbol{e}_1 \\ \boldsymbol{e}_2 \\ \boldsymbol{e}_3 \end{pmatrix} = \begin{pmatrix} a_1 &amp; a_2 &amp; a_3 \\ a_{11} &amp; a_{12} &amp; a_{13} \\ a_{21} &amp; a_{22} &amp; a_{23} \\ a_{31} &amp; a_{32} &amp; a_{33} \\ \end{pmatrix} \cdot \begin{pmatrix} \boldsymbol{i} \\ \boldsymbol{j} \\ \boldsymbol{k} \end{pmatrix}\] <p>并且条件</p> \[\begin{vmatrix} a_{11} &amp; a_{12} &amp; a_{13} \\ a_{21} &amp; a_{22} &amp; a_{23} \\ a_{31} &amp; a_{32} &amp; a_{33} \\ \end{vmatrix} \gt 0\] <p>成立。因此，\(\mathbb{E}^3\)中全体右手标架的集合\(\mathfrak{F}\)是\(\mathbb{R}^{12}\)中满足行列式大于0条件的区域\(D\)，位于区域中的点的坐标就是</p> \[(a_1, a_2, a_3, a_{11}, a_{12}, \cdots, a_{33})\] <p>如果\(\{ p; \boldsymbol{e}_1, \boldsymbol{e}_2, \boldsymbol{e}_3 \}\)是右手单位正交标架，则除了满足行列式大于0条件外，它还要满足方程</p> \[\boldsymbol{e}_i \cdot \boldsymbol{e}_j = \delta_{ij}, \ \ \ 1 \leq i, j \leq 3\] <p>即</p> \[\begin{pmatrix} a_{11} &amp; a_{12} &amp; a_{13} \\ a_{21} &amp; a_{22} &amp; a_{23} \\ a_{31} &amp; a_{32} &amp; a_{33} \\ \end{pmatrix} \cdot \begin{pmatrix} a_{11} &amp; a_{12} &amp; a_{33} \\ a_{12} &amp; a_{22} &amp; a_{32} \\ a_{13} &amp; a_{22} &amp; a_{33} \\ \end{pmatrix} = \begin{pmatrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 \\ \end{pmatrix}\] <p>因此\(\mathbb{E}^3\)中全体右手标架的集合\(\mathfrak{F}\)是\(\mathbb{R}^{12}\)中满足上述条件的一张6维(代数)曲面。</p> <p>现在我们来考察标架\(\{ p; \boldsymbol{e}_1, \boldsymbol{e}_2, \boldsymbol{e}_3 \}\)的无穷小位移，也就是标架原点\(p\)和标架向量\(\boldsymbol{e}_1, \boldsymbol{e}_2, \boldsymbol{e}_3\)的微分，则有</p> \[\begin{pmatrix} \mathrm{d}(\overrightarrow{Op}) \\ \mathrm{d} \boldsymbol{e}_1 \\ \mathrm{d} \boldsymbol{e}_2 \\ \mathrm{d} \boldsymbol{e}_3 \end{pmatrix} = \begin{pmatrix} \mathrm{d} a_1 &amp; \mathrm{d} a_2 &amp; \mathrm{d} a_3 \\ \mathrm{d} a_{11} &amp; \mathrm{d} a_{12} &amp; \mathrm{d} a_{13} \\ \mathrm{d} a_{21} &amp; \mathrm{d} a_{22} &amp; \mathrm{d} a_{23} \\ \mathrm{d} a_{31} &amp; \mathrm{d} a_{32} &amp; \mathrm{d} a_{33} \\ \end{pmatrix} \cdot \begin{pmatrix} \boldsymbol{i} \\ \boldsymbol{j} \\ \boldsymbol{k} \end{pmatrix}\] <p>但是\(\{ \boldsymbol{e}_1, \boldsymbol{e}_2, \boldsymbol{e}_3 \}\)是线性无关的，因此基底\(\{ \boldsymbol{i}, \boldsymbol{j}, \boldsymbol{k} \}\)反过来可以用\(\{ \boldsymbol{e}_1, \boldsymbol{e}_2, \boldsymbol{e}_3 \}\)来表示，即</p> \[\begin{pmatrix} \boldsymbol{i} \\ \boldsymbol{j} \\ \boldsymbol{k} \end{pmatrix} = \begin{pmatrix} b_{11} &amp; b_{12} &amp; b_{13} \\ b_{21} &amp; b_{22} &amp; b_{23} \\ b_{31} &amp; b_{32} &amp; b_{33} \\ \end{pmatrix} \cdot \begin{pmatrix} \boldsymbol{e}_1 \\ \boldsymbol{e}_2 \\ \boldsymbol{e}_3 \end{pmatrix}\] <p>其中系数矩阵</p> \[\begin{pmatrix} b_{11} &amp; b_{12} &amp; b_{13} \\ b_{21} &amp; b_{22} &amp; b_{23} \\ b_{31} &amp; b_{32} &amp; b_{33} \\ \end{pmatrix} = \begin{pmatrix} a_{11} &amp; a_{12} &amp; a_{13} \\ a_{21} &amp; a_{22} &amp; a_{23} \\ a_{31} &amp; a_{32} &amp; a_{33} \\ \end{pmatrix}^{-1}\] <p>将上式代入标架向量的微分得到</p> \[\begin{pmatrix} \mathrm{d}(\overrightarrow{Op}) \\ \mathrm{d} \boldsymbol{e}_1 \\ \mathrm{d} \boldsymbol{e}_2 \\ \mathrm{d} \boldsymbol{e}_3 \end{pmatrix} = \begin{pmatrix} \mathrm{d} a_1 &amp; \mathrm{d} a_2 &amp; \mathrm{d} a_3 \\ \mathrm{d} a_{11} &amp; \mathrm{d} a_{12} &amp; \mathrm{d} a_{13} \\ \mathrm{d} a_{21} &amp; \mathrm{d} a_{22} &amp; \mathrm{d} a_{23} \\ \mathrm{d} a_{31} &amp; \mathrm{d} a_{32} &amp; \mathrm{d} a_{33} \\ \end{pmatrix} \cdot \begin{pmatrix} b_{11} &amp; b_{12} &amp; b_{13} \\ b_{21} &amp; b_{22} &amp; b_{23} \\ b_{31} &amp; b_{32} &amp; b_{33} \\ \end{pmatrix} \cdot \begin{pmatrix} \boldsymbol{e}_1 \\ \boldsymbol{e}_2 \\ \boldsymbol{e}_3 \end{pmatrix}\] <p>展开以后得到</p> <p><a id="equation-of-moving-frame"></a></p> \[\begin{aligned} \mathrm{d} (\overrightarrow{Op}) &amp;= \Omega^1 \boldsymbol{e}_1 + \Omega^2 \boldsymbol{e}_2 + \Omega^3 \boldsymbol{e}_3 \\ \mathrm{d} \boldsymbol{e}_i &amp;= \Omega_i^1 \boldsymbol{e}_1 + \Omega_i^2 \boldsymbol{e}_2 + \Omega_i^3 \boldsymbol{e}_3 \end{aligned}\] <p>其中</p> \[\Omega^j = \sum_{k=1}^3 \mathrm{d} a_k \cdot b_{kj}, \ \ \ \Omega_i^j = \sum_{k=1}^3 \mathrm{d} a_{ik} \cdot b_{kj}, \ \ \ 1 \leq i, j \leq 3\] <p>向这里的\(\Omega^j\)，\(\Omega_i^j\)是区域\(D\)上的12个一次微分式，称为欧式空间\(\mathbb{E}^3\)上的活动标架的<strong>相对分量</strong>。<a href="#equation-of-moving-frame">方程</a>称为<strong>活动标架的运动公式</strong>。</p> <p>上面的讨论对于欧氏空间\(\mathbb{E}^3\)上的单位正交活动标架也是适用的，只是现在要求矩阵\((a_{ij})\)是正交矩阵，即</p> \[\begin{pmatrix} b_{11} &amp; b_{12} &amp; b_{13} \\ b_{21} &amp; b_{22} &amp; b_{23} \\ b_{31} &amp; b_{32} &amp; b_{33} \\ \end{pmatrix} = \begin{pmatrix} a_{11} &amp; a_{21} &amp; a_{31} \\ a_{12} &amp; a_{22} &amp; a_{32} \\ a_{13} &amp; a_{23} &amp; a_{33} \\ \end{pmatrix}\] <p>因此欧式空间\(\mathbb{E}^3\)上的单位正交活动标架的相对分量是</p> \[\Omega^j = \sum_{k=1}^3 a_{jk} \cdot \mathrm{d} a_k, \ \ \ \Omega_i^j = \sum_{k=1}^3 a_{jk} \cdot \mathrm{d} a_{ik}, \ \ \ 1 \leq i, j \leq 3\] <p>另外，容易得知</p> \[\Omega_i^j = - \Omega_j^i, \ \ \ 1 \leq i, j \leq 3\] <p>因此欧式空间\(\mathbb{E}^3\)上的单位正交活动标架的相对分量在实质上只有6个，它们是</p> \[\Omega^1, \ \ \ \Omega^2, \ \ \ \Omega^3, \ \ \ \Omega_1^2 = -\Omega_2^1, \ \ \ \Omega_1^3 = -\Omega_3^1, \ \ \ \Omega_2^3 = -\Omega_3^2\] <p>这些一次微分式定义在\(\mathbb{R}^{12}\)中的6维曲面\(\tilde{\mathfrak{F}}\)上。</p> <h3 id="标架空间的结构方程">标架空间的结构方程</h3> <blockquote class="block-theorem"> <h5 id="定理77">定理7.7</h5> <p>欧式空间\(\mathbb{E}^3\)上的活动标架的相对分量\(\Omega^j\)，\(\Omega_i^j\)满足下列方程式:</p> <center> $$\mathrm{d} \Omega^j = \sum_{k=1}^3 \Omega^k \wedge \Omega_k^j, \ \ \ \mathrm{d} \Omega_i^j = \sum_{k=1}^3 \Omega_i^k \wedge \Omega_k^j$$ </center> <p>这组方程称为欧氏空间\(\mathbb{E}^3\)上的标架空间\(\mathfrak{F}\)的<strong>结构方程</strong>。</p> </blockquote> <p><strong>证明</strong> 标架族的位置向量\(\mathrm{d}(\overrightarrow{Op})\)相当于函数\(a_1\)，\(a_2\)，\(a_3\)，而每一个标架向量\(\boldsymbol{e}_i\)相当于函数\(a_{i1}\)，\(a_{i2}\)，\(a_{i3}\)，所以\(\mathrm{d}(\overrightarrow{Op})\)和\(\boldsymbol{e}_i\)实际上是标架空间\(\mathfrak{F}\)中的12个坐标函数。根据外微分的性质得到</p> \[\mathrm{d} (\mathrm{d} (\overrightarrow{Op}) ) = \boldsymbol{0}, \ \ \ \mathrm{d} (\mathrm{d} \boldsymbol{e}_i ) = \boldsymbol{0}\] <p>代入<a href="#equation-of-moving-frame">活动标架的运动方程</a>得到</p> \[\begin{aligned} \boldsymbol{0} &amp;= \mathrm{d} (\mathrm{d} (\overrightarrow{Op}) ) = \sum_{j=1}^3 \mathrm{d} (\Omega^j \boldsymbol{e}_j) = \sum_{j=1}^3 ( \mathrm{d} \Omega^j \boldsymbol{e}_j - \Omega^j \wedge \mathrm{d} \boldsymbol{e}_j ) \\ &amp;= \sum_{j=1}^3 \bigg( \mathrm{d} \Omega^j - \sum_{k=1}^3 \Omega^k \wedge \Omega_k^j \bigg) \boldsymbol{e}_j \end{aligned}\] \[\begin{aligned} \boldsymbol{0} &amp;= \mathrm{d} (\mathrm{d} \boldsymbol{e}_i) = \sum_{j=1}^3 \mathrm{d} ( \Omega_i^j \boldsymbol{e}_j ) = \sum_{j=1}^3 (\mathrm{d} \Omega_i^j \boldsymbol{e}_j - \Omega_i^j \wedge \mathrm{d} \boldsymbol{e}_j) \\ &amp;= \sum_{j=1}^3 \bigg( \mathrm{d} \Omega_i^j - \sum_{k=1}^3 \Omega_i^k \wedge \Omega_k^j \bigg) \boldsymbol{e}_j \end{aligned}\] <p>因为\(\boldsymbol{e}_1\)，\(\boldsymbol{e}_2\)，\(\boldsymbol{e}_3\)是线性无关的，因此上式终端的系数必须为零。证毕∎</p> <p>欧式空间\(\mathbb{E}^3\)上的单位正交标架空间\(\tilde{\mathfrak{F}}\)有相同的结构方程，但是由于外微分式\(\Omega_i^j\)关于指标有反对称性，故结构方程成为</p> <p><a id="equation-of-moving-frame-E3"></a></p> \[\begin{aligned} \mathrm{d} \Omega^j &amp;= \sum_{k=1}^3 \Omega^k \wedge \Omega_k^j \\ \mathrm{d} \Omega_1^2 &amp;= \Omega_1^3 \wedge \Omega_3^2 = -\Omega_1^3 \wedge \Omega_2^3 \\ \mathrm{d} \Omega_1^3 &amp;= \Omega_1^2 \wedge \Omega_2^3 \\ \mathrm{d} \Omega_2^3 &amp;= \Omega_2^1 \wedge \Omega_1^3 = \Omega_1^3 \wedge \Omega_1^2 \\ \end{aligned}\] <p>下面我们考虑欧氏空间\(\mathbb{E}^3\)中依赖\(r\)个参数的标架族。设变量\((u^1, \cdots, u^r)\)的定义域是空间\(\mathbb{R}^r\)中的一个区域\(\tilde{D}\)，那么所谓的\(\mathbb{E}^3\)中依赖\(r\)个参数的标架族是指从\(r\)维区域\(\tilde{D}\)到标架空间\(\mathfrak{F}\)中的一个连续可微映射\(\sigma: \tilde{D} \rightarrow \mathfrak{F}\)，即有12个连续可微函数</p> \[a_i = a_i (u^1, \cdots, u^r), \ \ \ a_{ij} = a_{ij} (u^1, \cdots, u^r)\] <p>其中\(\det{(a_{ij}(u^\alpha))} \gt 0\)。把\(u^1, \cdots, u^r\)看作自变量，将上式代入<a href="#frame-definition">标架的定义方程</a>并求微分，故有</p> <p><a id="标架族的运动公式"></a></p> \[\mathrm{d} (\overrightarrow{Op}) = \sum_{i=1}^3 \omega^k \boldsymbol{e}_k, \ \ \ \mathrm{d} \boldsymbol{e}_i = \sum_{i=1}^3 \omega_i^k \boldsymbol{e}_k\] <p>很明显</p> \[\omega^k = \sigma^* \Omega^k, \ \ \ \omega_i^k = \sigma^* \Omega_i^k\] <p>它们是\(r\)维区域\(\tilde{D}\)上的一次微分式，称为\(\mathbb{E}^3\)中依赖\(r\)个参数\(u^1, \cdots, u^r\)的标架族的相对分量。<a href="%E6%A0%87%E6%9E%B6%E6%97%8F%E7%9A%84%E8%BF%90%E5%8A%A8%E5%85%AC%E5%BC%8F">上式</a>称为\(\mathbb{E}^3\)中依赖\(r\)个参数\(u^1, \cdots, u^r\)的标架族的运动公式。</p> <p>如果考虑欧式空间\(\mathbb{E}^3\)中依赖\(r\)个参数的单位正交标架族，则它是从\(r\)维区域\(\tilde{D}\)到标架空间\(\tilde{\mathfrak{F}}\)中的一个连续可微映射\(\sigma: \tilde{D} \rightarrow \tilde{\mathfrak{F}}\)，换言之，这12个函数\(a_i = a_i (u^1, \cdots, u^r)\)，\(a_{ij} = a_{ij} (u^1, \cdots, u^r)\)还要满足条件</p> \[\sum_{k=1}^3 a_{ik} (u^1, \cdots, u^r) a_{jk} (u^1, \cdots, u^r) = \delta_{ij}\] <p>相应地，相对分量\(\omega^j\)，\(\omega_i^j\)满足关系式</p> \[\omega_i^j + \omega_j^i = 0\] <blockquote class="block-theorem"> <h5 id="定理78">定理7.8</h5> <p>欧式空间\(\mathbb{E}^3\)中依赖\(r\)个参数\(u^1, \cdots, u^r\)的任意一个标架族\(\{ p(u^\alpha); \boldsymbol{e}_1(u^\alpha), \boldsymbol{e}_2(u^\alpha), \boldsymbol{e}_3(u^\alpha) \}\)的相对分量\(\omega^j\)，\(\omega_i^j\)必定满足结构方程</p> <center> $$\mathrm{d} \omega^j = \sum_{k=1}^3 \omega^k \wedge \omega_k^j, \ \ \ \mathrm{d} \omega_i^j = \sum_{k=1}^3 \omega_i^k \wedge \omega_k^j$$ </center> </blockquote> <p><strong>证明</strong> 根据<a href="#theorem7.6">定理7.6</a>可以得到</p> \[\begin{aligned} \mathrm{d} \omega^j &amp;= \mathrm{d} (\sigma^* \Omega^j) = \sigma^* \mathrm{d} \Omega^j = \sigma^* \bigg( \sum_{k=1}^3 \Omega^k \wedge \Omega_k^j \bigg) \\ &amp;= \sum_{k=1}^3 \sigma^* \Omega^k \wedge \sigma^* \Omega_k^j = \sum_{k=1}^3 \omega^k \wedge \omega_k^j \end{aligned}\] \[\begin{aligned} \mathrm{d} \omega_i^j &amp;= \mathrm{d} (\sigma^* \Omega_i^j) = \sigma^* \mathrm{d} \Omega_i^j = \sigma^* \bigg( \sum_{k=1}^3 \Omega_i^k \wedge \Omega_k^j \bigg) \\ &amp;= \sum_{k=1}^3 \sigma^* \Omega_i^k \wedge \sigma^* \Omega_k^j = \sum_{k=1}^3 \omega_i^k \wedge \omega_k^j \end{aligned}\] <p>证毕∎</p> <p>结构方程的重要性在于上述定理的逆定理成立，即结构方程成立是使标架族存在、且以给定的一组一次微分式\(\omega^j\)，\(\omega_i^j\)，\(1 \leq i, j \leq 3\)为其相对分量的充分条件。具体地说，我们有下面的定理：</p> <blockquote class="block-theorem"> <h5 id="定理79">定理7.9</h5> <p>任意给定12个依赖自变量\((u^1, \cdots, u^r) \in \tilde{D} \subset \mathbb{R}^r\)的一次微分式\(\omega^j\)，\(\omega_i^j\)，\(1 \leq i, j \leq 3\)，如果它们满足结构方程</p> <center> $$\mathrm{d} \omega^j = \sum_{k=1}^3 \omega^k \wedge \omega_k^j, \ \ \ \mathrm{d} \omega_i^j = \sum_{k=1}^3 \omega_i^k \wedge \omega_k^j$$ </center> <p>则在欧式空间\(\mathbb{E}^3\)中有依赖\(r\)个参数\(u^1, \cdots, u^r\)的右手标架族\(\{ p(u^\alpha); \boldsymbol{e}_1(u^\alpha), \boldsymbol{e}_2(u^\alpha), \boldsymbol{e}_3(u^\alpha) \}\)以\(\omega^j\)，\(\omega_i^j\)为它的相对分量。</p> </blockquote> <blockquote class="block-theorem"> <h5 id="定理79-1">定理7.9′</h5> <p>任意给定6个依赖自变量\((u^1, \cdots, u^r) \in \tilde{D} \subset \mathbb{R}^r\)的一次微分式</p> <center> $$\omega^1, \omega^2, \omega^3, \omega_1^2 = - \omega_2^1, \omega_1^3 = - \omega_3^1, \omega_2^3 = - \omega_3^2$$ </center> <p>如果它们满足结构方程</p> <center> $$\mathrm{d} \omega^j = \sum_{k=1}^3 \omega^k \wedge \omega_k^j, \ \ \ \mathrm{d} \omega_i^j = \sum_{k=1}^3 \omega_i^k \wedge \omega_k^j$$ </center> <p>则在欧式空间\(\mathbb{E}^3\)中有依赖\(r\)个参数\(u^1, \cdots, u^r\)的右手单位正交标架族\(\{ p(u^\alpha); \boldsymbol{e}_1(u^\alpha), \boldsymbol{e}_2(u^\alpha), \boldsymbol{e}_3(u^\alpha) \}\)以\(\omega^j\)，\(\omega_i^j\)为它的相对分量，并且任意两个这样的右手单位正交标架族可以通过空间\(\mathbb{E}^3\)的一个刚体运动彼此重合。</p> </blockquote> <p>定理7.9和定理7.9′的证明，实际上要化为在证明曲面存在定理时用到的一阶线性齐次偏微分方程组的求解问题，而结构方程相当于这组偏微分方程组的完全可积条件。</p> <h2 id="曲面上的正交标架场">曲面上的正交标架场</h2> <p>本节的目的是把\(\mathbb{E}^3\)中的标架族的理论用于曲面论的研究。首先我们求曲面上自然标架场的相对分量，然后把曲面论的Gauss-Codazzi方程和自然标架场的结构方程等同起来。我们所着眼的重点还是如何在曲面上取单位正交标架场，并且把曲面的有关几何量用曲面上的一阶标架场的相对分量表示出来，为在曲面上用活动标架法创造条件。</p> <h3 id="自然标架场">自然标架场</h3> <p>设欧式空间\(\mathbb{E}^3\)中曲面\(S\)的参数方程是\(\boldsymbol{r} = \boldsymbol{r}(u^1, u^2)\)，相应的自然标架场是\(\{ \boldsymbol{r}; \boldsymbol{r}_1, \boldsymbol{r}_2, \boldsymbol{n} \}\)，其中</p> \[\boldsymbol{r}_\alpha = \frac{\partial \boldsymbol{r}}{\partial u^\alpha}, \ \ \ \alpha = 1,2; \ \ \ \boldsymbol{n} = \frac{\boldsymbol{r}_1 \times \boldsymbol{r}_2}{\vert \boldsymbol{r}_1 \times \boldsymbol{r}_2 \vert}\] <p>因此，自然标架场\(\{ \boldsymbol{r}; \boldsymbol{r}_1, \boldsymbol{r}_2, \boldsymbol{n} \}\)是空间\(\mathbb{E}^3\)中依赖参数\(u^1\)，\(u^2\)的标架族。</p> <p>现在求这个标架族的相对分量\(\omega^j\)，\(\omega_i^j\)。假定曲面\(S\)的两个基本形式分别是</p> \[\mathrm{I} = g_{\alpha \beta} \mathrm{d} u^\alpha \mathrm{d} u^\beta, \ \ \ \mathrm{II} = b_{\alpha \beta} \mathrm{d} u^\alpha \mathrm{d} u^\beta\] <p>由于</p> \[\mathrm{d} \boldsymbol{r} = \boldsymbol{r}_1 \mathrm{d} u^1 + \boldsymbol{r}_2 \mathrm{d} u^2\] <p>与<a href="%E6%A0%87%E6%9E%B6%E6%97%8F%E7%9A%84%E8%BF%90%E5%8A%A8%E5%85%AC%E5%BC%8F">活动标架的运动公式</a>对照得到</p> \[\omega^1 = \mathrm{d} u^1, \ \ \ \omega^2 = \mathrm{d} u^2, \ \ \ \omega^3 = 0\] <p>由曲面论的<a href="/blog/2023/DifferentialGeometry-NOTES-05/#%E8%87%AA%E7%84%B6%E6%A0%87%E6%9E%B6%E5%9C%BA%E7%9A%84%E8%BF%90%E5%8A%A8%E5%85%AC%E5%BC%8F">Gauss-Weingarten公式</a>得到</p> \[\mathrm{d} \boldsymbol{r}_\alpha = \frac{\partial \boldsymbol{r}_\alpha}{\partial u^\beta} \mathrm{d} u^\beta = \Gamma_{\alpha \beta}^\gamma \mathrm{d} u^\beta \boldsymbol{r}_\gamma + b_{\alpha \beta} \mathrm{d} u^\beta \boldsymbol{n}\] \[\mathrm{d} \boldsymbol{n} = \frac{\partial \boldsymbol{n}}{\partial u^\beta} \mathrm{d} u^\beta = -b_\beta^\gamma \mathrm{d} u^\beta \boldsymbol{r}_\gamma\] <p>其中\(\Gamma_{\alpha \beta}^\gamma\)是度量矩阵\((g_{\alpha \beta})\)的Christoffel记号。与<a href="%E6%A0%87%E6%9E%B6%E6%97%8F%E7%9A%84%E8%BF%90%E5%8A%A8%E5%85%AC%E5%BC%8F">活动标架的运动公式</a>对照得到</p> \[\omega_\alpha^\gamma = \Gamma_{\alpha \beta}^\gamma \mathrm{d} u^\beta, \ \ \ \omega_\alpha^3 = b_{\alpha \beta} \mathrm{d} u^\beta, \ \ \ \omega_3^\gamma =-b_\beta^\gamma \mathrm{d} u^\beta, \ \ \ \omega_3^3 = 0, \ \ \ \alpha, \gamma = 1, 2\] <p>下面考察该标架族的结构方程。根据\(\omega^1 = \mathrm{d} u^1\)，\(\omega^2 = \mathrm{d} u^2\)，\(\omega^3 = 0\)得知\(\mathrm{d} \omega^j = 0\)。而在另一方面，由于\(\Gamma_{\alpha \beta}^\gamma\)和\(b_{\alpha \beta}\)关于下指标的对称性我们有</p> \[\sum_{k=1}^3 \omega^k \wedge \omega_k^\gamma = \sum_{\alpha, \beta=1}^2 \mathrm{d} u^\alpha \wedge \Gamma_{\alpha \beta}^\gamma \mathrm{d} u^\beta = (\Gamma_{12}^\gamma - \Gamma_{21}^\gamma) \mathrm{d} u^1 \wedge \mathrm{d} u^2 = 0\] \[\sum_{k=1}^3 \omega^k \wedge \omega_k^3 = \sum_{\alpha, \beta=1}^2 \mathrm{d} u^\alpha \wedge b_{\alpha \beta} \mathrm{d} u^\beta = (b_{12}^\gamma - b_{21}^\gamma) \mathrm{d} u^1 \wedge \mathrm{d} u^2 = 0\] <p>因此第一组结构方程</p> \[\mathrm{d} \omega^j = \sum_{k=1}^3 \omega^k \wedge \omega_k^j, \ \ \ 1 \leq j \leq 3\] <p>是自动成立的。第二组结构方程可以写成</p> \[\mathrm{d} \omega_\alpha^\gamma = \omega_\alpha^\beta \wedge \omega_\beta^\gamma + \omega_\alpha^3 \wedge \omega_3^\gamma, \ \ \ \mathrm{d} \omega_\alpha^3 = \omega_\alpha^\beta \wedge \omega_\beta^3,\] \[\mathrm{d} \omega_3^\gamma = \omega_3^\beta \wedge \omega_\beta^\gamma, \ \ \ \mathrm{d} \omega_3^3 = \omega_3^\beta \wedge \omega_\beta^3\] <p>可以验证，上面的前两个式子分别是<a href="/blog/2023/DifferentialGeometry-NOTES-05/#gauss-codazzi%E6%96%B9%E7%A8%8B">Gauss方程和Codazzi方程</a>。</p> <p>总起来说，在曲面\(S\)上取自然标架场\(\{ \boldsymbol{r}; \boldsymbol{r}_1, \boldsymbol{r}_2, \boldsymbol{n} \}\)，则它的相对分量为</p> \[\omega^1 = \mathrm{d} u^1, \ \ \ \omega^2 = \mathrm{d} u^2, \ \ \ \omega^3 = 0\] \[\omega_\alpha^\gamma = \Gamma_{\alpha \beta}^\gamma \mathrm{d} u^\beta, \ \ \ \omega_\alpha^3 = b_{\alpha \beta} \mathrm{d} u^\beta, \ \ \ \omega_3^\gamma =-b_\beta^\gamma \mathrm{d} u^\beta, \ \ \ \omega_3^3 = 0, \ \ \ \alpha, \gamma = 1, 2\] <p>它们所满足的结构方程恰好是曲面\(S\)所满足的Gauss-Codazzi方程。由此可见，如果已知两个二次微分形式</p> \[\varphi = g_{\alpha \beta} \mathrm{d} u^\alpha \mathrm{d} u^\beta, \ \ \ \psi = b_{\alpha \beta} \mathrm{d} u^\alpha \mathrm{d} u^\beta\] <p>其中\(\varphi\)是正定的，要验证它们是否满足Gauss-Codazzi方程，只要构造一次微分式\(\omega^j\)，\(\omega_i^j\)，然后验证它们是否满足结构方程就行了。由于结构方程比Gauss-Codazzi方程容易记忆，所以验证结构方程显然是比较方便的。</p> <h3 id="正交标架场">正交标架场</h3> <p>下面我们来讨论曲面\(S\)上的单位正交标架场。首先我们要指出，从曲面\(S\)的自然标架场得到单位正交标架场的最简单的方法是所谓的Schmidt正交化步骤。假定曲面\(S\)的第一基本形式是(采用Gauss记号)</p> \[\mathrm{I} = E (\mathrm{d} u)^2 + 2 F \mathrm{d} u \mathrm{d} v + G (\mathrm{d} v)^2\] <p>则从\(\{ \boldsymbol{r}_u, \boldsymbol{r}_v \}\)经过Schmidt正交化得到</p> \[\boldsymbol{e}_1 = \frac{\boldsymbol{r}_u}{\sqrt{E}}, \ \ \ \boldsymbol{e}_2 = \frac{1}{\sqrt{EG - F^2}} \bigg( -\frac{F}{\sqrt{E}} \boldsymbol{r}_u + \sqrt{E} \boldsymbol{r}_v \bigg)\] <p>命\(g = EG - F^2\)，则上式可以用矩阵表示为</p> \[\begin{pmatrix} \boldsymbol{e}_1 \\ \boldsymbol{e}_2 \end{pmatrix} = \begin{pmatrix} \frac{1}{\sqrt{E}} &amp; 0 \\ -\frac{F}{\sqrt{Eg}} &amp; \frac{\sqrt{E}}{\sqrt{g}} \end{pmatrix} \cdot \begin{pmatrix} \boldsymbol{r}_u \\ \boldsymbol{r}_v \end{pmatrix}\] <p>命</p> \[\boldsymbol{e}_3 = \boldsymbol{e}_1 \times \boldsymbol{e}_2 = \boldsymbol{n}\] <p>现在，\(\{ \boldsymbol{r}; \boldsymbol{e}_1, \boldsymbol{e}_2, \boldsymbol{e}_3 \}\)是定义在曲面\(S\)上的单位正交标架场，其中\(\boldsymbol{e}_1\)和\(\boldsymbol{e}_2\)是曲面\(S\)的切向量。这时欧式空间\(\mathbb{E}^3\)中依赖参数\(u\)，\(v\)的正交标架族。为求该标架族的相对分量\(\omega^i\)，注意到\(\mathrm{d} \boldsymbol{r}\)是曲面\(S\)的切向量，所以</p> \[\omega^3 = \mathrm{d} \boldsymbol{r} \cdot \boldsymbol{e}_3 = \boldsymbol{r} \cdot \boldsymbol{n} = 0\] <p>另外，根据相对分量\(\omega^i\)的定义得到</p> \[\begin{aligned} \mathrm{d} \boldsymbol{r} &amp;= \omega^1 \boldsymbol{e}_1 + \omega^2 \boldsymbol{e}_2 = \begin{pmatrix} \omega^1 &amp; \omega^2 \end{pmatrix} \cdot \begin{pmatrix} \boldsymbol{e}_1 \\ \boldsymbol{e}_2 \end{pmatrix} \\ &amp;= \begin{pmatrix} \omega^1 &amp; \omega^2 \end{pmatrix} \cdot \begin{pmatrix} \frac{1}{\sqrt{E}} &amp; 0 \\ -\frac{F}{\sqrt{Eg}} &amp; \frac{\sqrt{E}}{\sqrt{g}} \end{pmatrix} \cdot \begin{pmatrix} \boldsymbol{r}_u \\ \boldsymbol{r}_v \end{pmatrix} \\ &amp;= \begin{pmatrix} \mathrm{d} u &amp; \mathrm{d} v \end{pmatrix} \cdot \begin{pmatrix} \boldsymbol{r}_u \\ \boldsymbol{r}_v \end{pmatrix} \end{aligned}\] <p>所以</p> \[\begin{pmatrix} \mathrm{d} u &amp; \mathrm{d} v \end{pmatrix} = \begin{pmatrix} \omega^1 &amp; \omega^2 \end{pmatrix} \cdot \begin{pmatrix} \frac{1}{\sqrt{E}} &amp; 0 \\ -\frac{F}{\sqrt{Eg}} &amp; \frac{\sqrt{E}}{\sqrt{g}} \end{pmatrix}\] <p>或者</p> \[\begin{pmatrix} \omega^1 &amp; \omega^2 \end{pmatrix} = \begin{pmatrix} \mathrm{d} u &amp; \mathrm{d} v \end{pmatrix} \cdot \begin{pmatrix} \sqrt{E} &amp; 0 \\ \frac{F}{\sqrt{E}} &amp; \frac{\sqrt{g}}{\sqrt{E}} \end{pmatrix}\] <p>即</p> \[\omega^1 = \sqrt{E} \mathrm{d} u + \frac{F}{\sqrt{E}} \mathrm{d} v, \ \ \ \omega^2 = \frac{\sqrt{g}}{\sqrt{E}} \mathrm{d} v\] <p>上面求曲面\(S\)上的单位正交标架场\(\{ \boldsymbol{r}; \boldsymbol{e}_1, \boldsymbol{e}_2, \boldsymbol{e}_3 \}\)的相对分量\(\omega^1\)，\(\omega^2\)的过程，可以简单地归结为曲面\(S\)的第一基本形式配平方的过程。实际上，将第一基本形式配平方得到</p> \[\begin{aligned} \mathrm{I} &amp;= E (\mathrm{d} u)^2 + 2 F \mathrm{d} u \mathrm{d} v + G (\mathrm{d} v)^2 \\ &amp;= \bigg( \sqrt{E} \mathrm{d} u + \frac{F}{\sqrt{E}} \mathrm{d} v \bigg)^2 + \bigg( \frac{\sqrt{EG - F^2}}{\sqrt{E}} \mathrm{d} v \bigg)^2 \end{aligned}\] <p>把等式终端的第一个括号内的式子记为\(\omega^1\)，第二个括号内的式子记为\(\omega^2\)即可。</p> <h3 id="一阶标架场">一阶标架场</h3> <p>一般地，如果曲面\(S\)上的单位正交标架场\(\{ \boldsymbol{r}; \boldsymbol{e}_1, \boldsymbol{e}_2, \boldsymbol{e}_3 \}\)中的成员\(\boldsymbol{e}_1\)，\(\boldsymbol{e}_2\)是曲面\(S\)的切向量，则称这样的标架场为曲面\(S\)的<strong>一阶标架场</strong>。对于曲面\(S\)的任意一个一阶标架场\(\{ \boldsymbol{r}; \boldsymbol{e}_1, \boldsymbol{e}_2, \boldsymbol{e}_3 \}\)必定有</p> \[\mathrm{d} \boldsymbol{r} = \omega^1 \boldsymbol{e}_1 + \omega^2 \boldsymbol{e}_2\] <p>因此\(\omega^3 = 0\)并且</p> \[\mathrm{I} = \mathrm{d} \boldsymbol{r} \cdot \mathrm{d} \boldsymbol{r} = (\omega^1 \boldsymbol{e}_1 + \omega^2 \boldsymbol{e}_2)^2 = (\omega^1)^2 + (\omega^2)^2\] <p>反过来，只要将曲面\(S\)的第一基本形式作任意的配平方，把它写成两个一次微分式的平方和，并且把这两个一次微分式分别记为\(\omega^1\)和\(\omega^2\)，而让\(\omega^3 = 0\)，则我们便得到曲面\(S\)的某个一阶标架场的相对分量，并且由此可以得到曲面\(S\)的一阶标架场关于自然标架场的表达式。这个看法为在曲面\(S\)上选用一阶标架场带来方便，在实践中是十分有用的。</p> <p>下面我们来求曲面\(S\)的一阶标架场相对分量的其他成员。假定我们有曲面\(S\)的一阶标架场\(\{ \boldsymbol{r}; \boldsymbol{e}_1, \boldsymbol{e}_2, \boldsymbol{e}_3 \}\)，换言之，我们有一次微分式\(\omega^1\)，\(\omega^2\)，\(\omega^3=0\)，使得</p> \[\mathrm{I} = (\omega^1)^2 + (\omega^2)^2\] <p>因为\(\mathrm{I}\)是正定的，容易证明\(\omega^1\)和\(\omega^2\)是处处线性无关的。首先我们断言：一次微分式\(\omega_1^2 = -\omega_2^1\)是由\(\omega^1\)，\(\omega^2\)根据结构方程唯一确定的。确切地说，我们有下面的定理。</p> <p><a id="theorem7.10"></a></p> <blockquote class="block-theorem"> <h5 id="定理710">定理7.10</h5> <p>假定\(\omega^1\)，\(\omega^2\)是依赖自变量\(u\)，\(v\)的两个处处线性无关的一次微分式，则存在唯一的一个一次微分式\(\omega_1^2 = -\omega_2^1\)满足条件</p> <center> $$\mathrm{d} \omega^1 = \omega^2 \wedge \omega_2^1, \ \ \ \mathrm{d} \omega^2 = \omega^1 \wedge \omega_1^2$$ </center> </blockquote> <p><strong>证明</strong> 因为曲面\(S\)的一阶标架场是空间\(\mathbb{E}^3\)中依赖参数\(u\)，\(v\)的单位正交标架族，它的相对分量必定是自变量\(u\)，\(v\)的一次微分式，但是\(\omega^1\)，\(\omega^2\)是\(u\)，\(v\)的处处线性无关的一次微分式，故可设</p> \[\omega_1^2 = - \omega_2^1 = p \omega^1 + q \omega^2\] <p>将上式代入结构方程得到</p> \[\mathrm{d} \omega^1 = p \omega^1 \wedge \omega^2, \ \ \ \mathrm{d} \omega^2 = q \omega^1 \wedge \omega^2\] <p>因为\(\mathrm{d} \omega^1\)，\(\mathrm{d} \omega^2\)是自变量\(u\)，\(v\)的二次微分式，所以它们必定是\(\mathrm{d} u \wedge \mathrm{d} v\)的倍数，其系数是\(u\)，\(v\)的函数。同时因为\(\omega^1\)，\(\omega^2\)是\(u\)，\(v\)的处处线性无关的一次微分式，故二次微分式\(\omega^1 \wedge \omega^2\)是\(\mathrm{d} u \wedge \mathrm{d} v\)的非零函数倍，这样，\(\mathrm{d} \omega^1\)，\(\mathrm{d} \omega^2\)必定是\(\omega^1 \wedge \omega^2\)的倍数，其系数恰好是我们要确定的\(p\)，\(q\)，即</p> \[p = \frac{\mathrm{d} \omega^1}{\omega^1 \wedge \omega^2}, \ \ \ q = \frac{\mathrm{d} \omega^2}{\omega^1 \wedge \omega^2}\] <p>由此可见，一次微分式\(\omega_1^2 = -\omega_2^1\)是由\(\omega^1\)和\(\omega^2\)借助于结构方程唯一确定的。证毕∎</p> <p>关于曲面\(S\)的一阶标架场的相对分量，还需要求出\(\omega_1^3 = -\omega_3^1\)和\(\omega_2^3 = -\omega_3^2\)，它们与曲面\(S\)的第二基本形式有关。根据结构方程</p> \[0 = \mathrm{d} \omega^3 = \omega^1 \wedge \omega_1^3 + \omega^2 \wedge \omega_2^3\] <p><a id="相对分量的线性表示"></a></p> <p>以及\(\omega^1\)和\(\omega^2\)的线性无关性，由<a href="#cartan-lemma">Cartan引理</a>得知</p> \[\begin{pmatrix} \omega_1^3 &amp; \omega_2^3 \end{pmatrix} = \begin{pmatrix} \omega^1 &amp; \omega^2 \end{pmatrix} \cdot \begin{pmatrix} a &amp; b \\ b &amp; c \end{pmatrix}\] <p>根据曲面\(S\)的第二基本形式的定义</p> \[\begin{aligned} \mathrm{II} &amp;= -\mathrm{d} \boldsymbol{r} \cdot \mathrm{d} \boldsymbol{e}_3 = - (\omega^1 \boldsymbol{e}_1 + \omega^2 \boldsymbol{e}_2) \cdot (\omega_3^1 \boldsymbol{e}_1 + \omega_3^2 \boldsymbol{e}_2) \\ &amp;= - (\omega^1 \omega_3^1 + \omega^2 \omega_3^2) = \omega^1 \omega_1^3 + \omega^2 \omega_2^3 \\ &amp;= a (\omega^1)^2 + 2b \omega^1 \omega^2 + c (\omega^2)^2 \end{aligned}\] <p>如果已知曲面\(S\)的第二基本形式是</p> \[\mathrm{II} = L (\mathrm{d} u)^2 + 2 M \mathrm{d} u \mathrm{d} v + N (\mathrm{d} v)^2\] <p>则将\(\mathrm{d} u\)，\(\mathrm{d} v\)关于\(\omega^1\)，\(\omega^2\)的表达式代入上式就能够得到待定系数\(a\)，\(b\)，\(c\)。</p> <p>将上面的讨论综合起来，我们有下面的结论：如果给定曲面\(S\)的第一基本形式\(\mathrm{I}\)和第一基本形式\(\mathrm{II}\)，将\(\mathrm{I}\)作任意一个配平方，写成两个一次微分式\(\omega^1\)，\(\omega^2\)的平方和，那么\(\omega^1\)，\(\omega^2\)，\(\omega^3=0\)一定是曲面\(S\)的某个一阶标架场的相对分量。根据<a href="#theorem7.10">定理7.10</a>，相对分量\(\omega_1^2 = -\omega_2^1\)由\(\omega^1\)，\(\omega^2\)借助于结构方程\(\mathrm{d} \omega^1 = \omega^2 \wedge \omega_2^1, \ \ \ \mathrm{d} \omega^2 = \omega^1 \wedge \omega_1^2\)唯一地确定，\(\omega_1^3 = -\omega_3^1\)和\(\omega_2^3 = -\omega_3^2\)由曲面\(S\)的第二基本形式\(\mathrm{II}\)借助于结构方程\(0 = \mathrm{d} \omega^3 = \omega^1 \wedge \omega_1^3 + \omega^2 \wedge \omega_2^3\)唯一地确定。至此，尚未涉及曲面\(S\)的另一组结构方程\(\mathrm{d} \omega_i^j = \omega_i^k \wedge \omega_k^i\)，它们恰好是曲面\(S\)的Gauss-Codazzi方程。</p> <p><a href="#theorem7.10">定理7.10</a>说明，对于曲面\(S\)的一阶标架场来说，相对分量\(\omega_1^2 = -\omega_2^2\)是由\(\omega^1\)，\(\omega^2\)借助于结构方程唯一确定的。这个事实可以用来证实\(S\)上切向量场的协变微分和沿曲线的平行移动是属于曲面\(S\)的内蕴几何的概念。设\(\{ \boldsymbol{r}; \boldsymbol{e}_1, \boldsymbol{e}_2, \boldsymbol{e}_3 \}\)是曲面\(S\)的一阶标架场，则</p> \[\mathrm{d} \boldsymbol{e}_1 = \omega_1^2 \boldsymbol{e}_2 + \omega_1^3 \boldsymbol{e}_3, \ \ \ \mathrm{d} \boldsymbol{e}_2 = \omega_2^1 \boldsymbol{e}_1 + \omega_2^3 \boldsymbol{e}_3\] <p>根据曲面\(S\)上切向量场<a href="/blog/2024/DifferentialGeometry-NOTES-06/#%E5%8D%8F%E5%8F%98%E5%BE%AE%E5%88%86">协变微分</a>的定义，我们有</p> \[\mathrm{D} \boldsymbol{e}_1 = (\mathrm{d} \boldsymbol{e}_1)^{\perp} = \omega_1^2 \boldsymbol{e}_2, \ \ \ \mathrm{D} \boldsymbol{e}_2 = (\mathrm{d} \boldsymbol{e}_2)^{\perp} = \omega_2^1 \boldsymbol{e}_1\] <p>假定</p> \[\boldsymbol{X} = x^1 \boldsymbol{e}_1 + x^2 \boldsymbol{e}_2\] <p>是曲面\(S\)上的一个连续可微切向量场，则它的协变微分是</p> \[\begin{aligned} \mathrm{D} \boldsymbol{X} &amp;= \mathrm{d} x^1 \boldsymbol{e}_1 + x^1 \mathrm{D} \boldsymbol{e}_1 + \mathrm{d} x^2 \boldsymbol{e}_2 + x^2 \mathrm{D} \boldsymbol{e}_2 \\ &amp;= (\mathrm{d} x^1 + x^2 \omega_2^1) \boldsymbol{e}_1 + (\mathrm{d} x^2 + x^1 \omega_1^2) \boldsymbol{e}_2 \end{aligned}\] <p>命</p> \[\mathrm{D} x^1 = \mathrm{d} x^1 + x^2 \omega_2^1, \ \ \ \mathrm{D} x^2 = \mathrm{d} x^2 + x^1 \omega_1^2\] <p>分别称为切向量场\(\boldsymbol{X}\)的分量\(x^1\)，\(x^2\)的协变微分。注意到协变微分\(\mathrm{D} \boldsymbol{e}_1\)，\(\mathrm{D} \boldsymbol{e}_2\)中只用到相对分量\(\omega_1^2 = - \omega_2^1\)，而它们是由\(\omega^1\)，\(\omega^2\)确定的，与曲面\(S\)的第二基本形式无关，所以协变微分是曲面\(S\)的内蕴几何的概念，在曲面\(S\)作保长变换时它是保持不变的。在曲面的内蕴微分几何学中，一次微分形式</p> \[\omega_1^2 = - \omega_2^1\] <p>通常称为<strong>联络形式</strong>。</p> <p>曲面的一阶标架场是与曲面有密切关系的标架场，曲面的一些几何量应该能够用一阶标架场的相对分量来表示。但是曲面的一阶标架场的选取又有相当大的随意性，因为让曲面\(S\)的一阶标架场\(\{ \boldsymbol{r}; \boldsymbol{e}_1, \boldsymbol{e}_2, \boldsymbol{e}_3 \}\)在每一点绕法向量\(\boldsymbol{e}_3\)转过一个角度\(\theta\)得到的仍然是曲面\(S\)的一阶标架场。换言之，曲面\(S\)的一阶标架场容许作如下的变换：</p> \[\begin{aligned} \tilde{\boldsymbol{e}}_1 &amp;= \cos{\theta} \boldsymbol{e}_1 + \sin{\theta} \boldsymbol{e}_2 \\ \tilde{\boldsymbol{e}}_2 &amp;=-\sin{\theta} \boldsymbol{e}_1 + \cos{\theta} \boldsymbol{e}_2 \end{aligned}\] <p>其中\(\theta\)是曲面\(S\)上的连续可微函数。正是因为曲面\(S\)的一阶标架场的选取享有这种自由度，使得它与曲面\(S\)的参数系的关系比较松弛，从而为处理曲面的问题带来很多便利，这就是所谓的活动标架的优越性。当然，曲面的几何量在用一阶标架场的相对分量表示时应该与一阶标架场的容许变换无关。</p> <p>我们先考虑曲面\(S\)的一阶标架场的相对分量在一阶标架场经受容许变换时的变换规律。用\(\tilde{\omega}^j\)，\(\tilde{\omega}_i^j\)记一阶标架场\(\{ \boldsymbol{r}; \tilde{\boldsymbol{e}}_1, \tilde{\boldsymbol{e}}_2, \tilde{\boldsymbol{e}}_3 \}\)的相对分量。容易得知</p> \[\tilde{\boldsymbol{e}}_3 = \tilde{\boldsymbol{e}}_1 \times \tilde{\boldsymbol{e}}_2 = \boldsymbol{e}_1 \times \boldsymbol{e}_2 = \boldsymbol{e}_3\] <p>因此</p> \[\begin{aligned} \mathrm{d} \boldsymbol{r} &amp;= \begin{pmatrix} \omega^1 &amp; \omega^2 \end{pmatrix} \cdot \begin{pmatrix} \boldsymbol{e}_1 \\ \boldsymbol{e}_2 \end{pmatrix} = \begin{pmatrix} \tilde{\omega}^1 &amp; \tilde{\omega}^2 \end{pmatrix} \cdot \begin{pmatrix} \tilde{\boldsymbol{e}}_1 \\ \tilde{\boldsymbol{e}}_2 \end{pmatrix} \\ &amp;= \begin{pmatrix} \tilde{\omega}^1 &amp; \tilde{\omega}^2 \end{pmatrix} \cdot \begin{pmatrix} \cos{\theta} &amp; \sin{\theta} \\ -\sin{\theta} &amp; \cos{\theta} \end{pmatrix} \cdot \begin{pmatrix} \boldsymbol{e}_1 \\ \boldsymbol{e}_2 \end{pmatrix} \end{aligned}\] <p>所以\(\tilde{\omega}_3 = \omega_3 = 0\)，并且</p> \[\begin{pmatrix} \omega^1 &amp; \omega^2 \end{pmatrix} = \begin{pmatrix} \tilde{\omega}^1 &amp; \tilde{\omega}^2 \end{pmatrix} \cdot \begin{pmatrix} \cos{\theta} &amp; \sin{\theta} \\ -\sin{\theta} &amp; \cos{\theta} \end{pmatrix}\] \[\begin{pmatrix} \tilde{\omega}^1 &amp; \tilde{\omega}^2 \end{pmatrix} = \begin{pmatrix} \omega^1 &amp; \omega^2 \end{pmatrix} \cdot \begin{pmatrix} \cos{\theta} &amp; -\sin{\theta} \\ \sin{\theta} &amp; \cos{\theta} \end{pmatrix}\] <p>根据协变微分，我们有</p> \[\mathrm{D} \tilde{\boldsymbol{e}}_1 = \tilde{\omega}_1^2 \tilde{\boldsymbol{e}}_2\] <p>因此</p> \[\begin{aligned} \tilde{\omega}_1^2 &amp;= \mathrm{D} \tilde{\boldsymbol{e}}_1 \cdot \tilde{\boldsymbol{e}}_2 = \mathrm{D} (\cos{\theta} \boldsymbol{e}_1 + \sin{\theta} \boldsymbol{e}_2) \cdot (-\sin{\theta} \boldsymbol{e}_1 + \cos{\theta} \boldsymbol{e}_2) \\ &amp;= [(-\sin{\theta} \boldsymbol{e}_1 + \cos{\theta} \boldsymbol{e}_2) \mathrm{d} \theta + \cos{\theta} \mathrm{D} \boldsymbol{e}_1 + \sin{\theta} \mathrm{D} \boldsymbol{e}_2] \\ &amp;\cdot (-\sin{\theta} \boldsymbol{e}_1 + \cos{\theta} \boldsymbol{e}_2) \\ &amp;= \mathrm{d} \theta + \omega_1^2 \end{aligned}\] <p>同理，因为\(\tilde{\boldsymbol{e}}_3 = \boldsymbol{e}_3\)，故</p> \[\begin{aligned} \mathrm{d} \tilde{\boldsymbol{e}}_3 &amp;= \mathrm{d} \boldsymbol{e}_3 = \begin{pmatrix} \omega_3^1 &amp; \omega_3^2 \end{pmatrix} \cdot \begin{pmatrix} \boldsymbol{e}_1 \\ \boldsymbol{e}_2 \end{pmatrix} = \begin{pmatrix} \tilde{\omega}_3^1 &amp; \tilde{\omega}_3^2 \end{pmatrix} \cdot \begin{pmatrix} \tilde{\boldsymbol{e}}_1 \\ \tilde{\boldsymbol{e}}_2 \end{pmatrix} \\ &amp;= \begin{pmatrix} \tilde{\omega}_3^1 &amp; \tilde{\omega}_3^2 \end{pmatrix} \cdot \begin{pmatrix} \cos{\theta} &amp; \sin{\theta} \\ -\sin{\theta} &amp; \cos{\theta} \end{pmatrix} \cdot \begin{pmatrix} \boldsymbol{e}_1 \\ \boldsymbol{e}_2 \end{pmatrix} \end{aligned}\] <p>因此</p> \[\begin{pmatrix} \omega_3^1 &amp; \omega_3^2 \end{pmatrix} = \begin{pmatrix} \tilde{\omega}_3^1 &amp; \tilde{\omega}_3^2 \end{pmatrix} \cdot \begin{pmatrix} \cos{\theta} &amp; \sin{\theta} \\ -\sin{\theta} &amp; \cos{\theta} \end{pmatrix}\] \[\begin{pmatrix} \tilde{\omega}_1^3 &amp; \tilde{\omega}_2^3 \end{pmatrix} = \begin{pmatrix} \omega_1^3 &amp; \omega_2^3 \end{pmatrix} \cdot \begin{pmatrix} \cos{\theta} &amp; -\sin{\theta} \\ \sin{\theta} &amp; \cos{\theta} \end{pmatrix}\] <p>假定</p> \[\begin{pmatrix} \tilde{\omega}_1^3 &amp; \tilde{\omega}_2^3 \end{pmatrix} = \begin{pmatrix} \tilde{\omega}^1 &amp; \tilde{\omega}^2 \end{pmatrix} \cdot \begin{pmatrix} \tilde{a} &amp; \tilde{b} \\ \tilde{b} &amp; \tilde{c} \\ \end{pmatrix}\] <p>通过计算可以得到</p> \[\begin{aligned} \begin{pmatrix} \omega^1 &amp; \omega^2 \end{pmatrix} &amp;\cdot \begin{pmatrix} \cos{\theta} &amp; -\sin{\theta} \\ \sin{\theta} &amp; \cos{\theta} \end{pmatrix} \cdot \begin{pmatrix} \tilde{a} &amp; \tilde{b} \\ \tilde{b} &amp; \tilde{c} \\ \end{pmatrix} \\ &amp;= \begin{pmatrix} \omega_1^3 &amp; \omega_2^3 \end{pmatrix} \cdot \begin{pmatrix} \cos{\theta} &amp; -\sin{\theta} \\ \sin{\theta} &amp; \cos{\theta} \end{pmatrix} \\ &amp;= \begin{pmatrix} \omega^1 &amp; \omega^2 \end{pmatrix} \cdot \begin{pmatrix} a &amp; b \\ b &amp; c \\ \end{pmatrix} \cdot \begin{pmatrix} \cos{\theta} &amp; -\sin{\theta} \\ \sin{\theta} &amp; \cos{\theta} \end{pmatrix} \end{aligned}\] <p>所以</p> \[\begin{pmatrix} \tilde{a} &amp; \tilde{b} \\ \tilde{b} &amp; \tilde{c} \\ \end{pmatrix} = \begin{pmatrix} \cos{\theta} &amp; \sin{\theta} \\ -\sin{\theta} &amp; \cos{\theta} \end{pmatrix} \cdot \begin{pmatrix} a &amp; b \\ b &amp; c \\ \end{pmatrix} \cdot \begin{pmatrix} \cos{\theta} &amp; -\sin{\theta} \\ \sin{\theta} &amp; \cos{\theta} \end{pmatrix}\] <p>即\((\omega_1^3, \omega_2^3)\)用\((\omega^1, \omega^2)\)表示时其系数矩阵在变换下经受一个相似变换(或合同变换)，其过渡矩阵就是标架场容许变换对应的旋转矩阵。</p> <blockquote class="block-theorem"> <h5 id="定理711">定理7.11</h5> <p>若曲面\(S\)上的一阶标架场\(\{ \boldsymbol{r}; \boldsymbol{e}_1, \boldsymbol{e}_2, \boldsymbol{e}_3 \}\)经受如下的变换</p> <center> $$ \begin{pmatrix} \tilde{\boldsymbol{e}}_1 \\ \tilde{\boldsymbol{e}}_2 \end{pmatrix} = \begin{pmatrix} \cos{\theta} &amp; \sin{\theta} \\ -\sin{\theta} &amp; \cos{\theta} \end{pmatrix} \cdot \begin{pmatrix} \boldsymbol{e}_1 \\ \boldsymbol{e}_2 \end{pmatrix}, \ \ \ \tilde{\boldsymbol{e}}_3 = \boldsymbol{e}_3 $$ </center> <p>则对应的相对分量按下列规律进行变换</p> <center> $$ \begin{pmatrix} \tilde{\omega}^1 &amp; \tilde{\omega}^2 \end{pmatrix} = \begin{pmatrix} \omega^1 &amp; \omega^2 \end{pmatrix} \cdot \begin{pmatrix} \cos{\theta} &amp; -\sin{\theta} \\ \sin{\theta} &amp; \cos{\theta} \end{pmatrix} $$ </center> <center> $$ \tilde{\omega}^3 = \omega^3 = 0 $$ </center> <center> $$ \tilde{\omega}_1^2 = \omega_1^2 + \mathrm{d} \theta $$ </center> <center> $$ \begin{pmatrix} \tilde{\omega}_1^3 &amp; \tilde{\omega}_2^3 \end{pmatrix} = \begin{pmatrix} \omega_1^3 &amp; \omega_2^3 \end{pmatrix} \cdot \begin{pmatrix} \cos{\theta} &amp; -\sin{\theta} \\ \sin{\theta} &amp; \cos{\theta} \end{pmatrix} $$ </center> </blockquote> <h2 id="曲面上的曲线">曲面上的曲线</h2> <p>在<a href="/blog/2024/DifferentialGeometry-NOTES-06/#%E6%B5%8B%E5%9C%B0%E6%9B%B2%E7%8E%87%E5%92%8C%E6%B5%8B%E5%9C%B0%E6%8C%A0%E7%8E%87">前面</a>我们曾经指出，落在曲面\(S\)上的曲线\(C\)受到曲面的制约，它的弯曲性质必然在某种程度上反映了曲面的弯曲情况。现在，我们要把上一节所建立的曲面的一阶标架场理论用于曲面上曲线的研究。</p> <p>假定在曲面\(S: \boldsymbol{r} = \boldsymbol{r} (u^1, u^2)\)上取定一个一阶标架场\(\{ \boldsymbol{r}; \boldsymbol{\alpha}_1, \boldsymbol{\alpha}_2, \boldsymbol{\alpha}_3 \}\)，其中\(\boldsymbol{\alpha}_3 = \boldsymbol{n}\)。设它的相对分量是\(\omega^1\)，\(\omega^2\)，\(\omega^3=0\)以及\(\omega_i^j = -\omega_j^i\)，它们都是参数\(u^1\)，\(u^2\)的一次微分式。</p> <p>设\(C\)是曲面\(S\)上的一条连续可微曲线，其参数方程为\(u^\alpha = u^\alpha (s)\)，\(\alpha = 1, 2\)，\(s\)为弧长参数。因此，曲线\(C\)的单位切向量是</p> \[\boldsymbol{e}_1 = \frac{\mathrm{d} \boldsymbol{r} (s)}{\mathrm{d} s} = \frac{\omega^1}{\mathrm{d} s} \boldsymbol{\alpha}_1 + \frac{\omega^2}{\mathrm{d} s} \boldsymbol{\alpha}_2\] <p>这里的\(\omega^1\)，\(\omega^2\)是曲面\(S\)的相对分量在曲线\(C\)上的限制。设\(\theta\)是\(\boldsymbol{e}_1\)与\(\boldsymbol{\alpha}_1\)所构成的方向角，即</p> \[\boldsymbol{e}_1 = \cos{\theta} \boldsymbol{\alpha}_1 + \sin{\theta} \boldsymbol{\alpha}_2\] <p>故沿曲线\(C\)有</p> \[\frac{\omega^1}{\mathrm{d} s} = \cos{\theta}, \ \ \ \frac{\omega^2}{\mathrm{d} s} = \sin{\theta}\] <p>命</p> \[\begin{aligned} \boldsymbol{e}_2 &amp;= \boldsymbol{n} \times \boldsymbol{e}_1 = \boldsymbol{\alpha}_3 \times (\cos{\theta} \boldsymbol{\alpha}_1 + \sin{\theta} \boldsymbol{\alpha}_2) \\ &amp;= -\sin{\theta} \boldsymbol{\alpha}_1 + \cos{\theta} \boldsymbol{\alpha}_2 \\ &amp;= -\frac{\omega^2}{\mathrm{d} s} \boldsymbol{\alpha}_1 + \frac{\omega^1}{\mathrm{d} s} \boldsymbol{\alpha}_2 \\ \boldsymbol{e}_3 &amp;= \boldsymbol{\alpha}_3 = \boldsymbol{n} \end{aligned}\] <p>于是\(\{ \boldsymbol{r}; \boldsymbol{e}_1, \boldsymbol{e}_2, \boldsymbol{e}_3 \}\)是沿曲面\(S\)上的曲线\(C\)所定义的单位正交标架场，它是曲面\(S\)的一阶标架场\(\{ \boldsymbol{r}; \boldsymbol{\alpha}_1, \boldsymbol{\alpha}_2, \boldsymbol{\alpha}_3 \}\)在曲线\(C\)上的限制、并在每一点转过一个角度\(\theta\)得到的。根据定义，曲线\(C\)的曲率向量是</p> \[\begin{aligned} \frac{\mathrm{d} \boldsymbol{e}_1}{\mathrm{d} s} &amp;= (-\sin{\theta} \boldsymbol{\alpha}_1 + \cos{\theta} \boldsymbol{\alpha}_2) \frac{\mathrm{d} \theta}{\mathrm{d} s} + \cos{\theta} \frac{\mathrm{d} \boldsymbol{\alpha}_1}{\mathrm{d} s} + \sin{\theta} \frac{\mathrm{d} \boldsymbol{\alpha}_2}{\mathrm{d} s} \\ &amp;= \bigg( \frac{\mathrm{d} \theta}{\mathrm{d} s} + \frac{\omega_1^2}{\mathrm{d} s}\bigg) \boldsymbol{e}_2 + \frac{\omega^1 \omega_1^3 + \omega^2 \omega_2^3}{\mathrm{d} s^2} \boldsymbol{e}_3 \end{aligned}\] <p>所以</p> \[\frac{\mathrm{D} \boldsymbol{e}_1}{\mathrm{d} s} = \bigg( \frac{\mathrm{d} \boldsymbol{e}_1}{\mathrm{d} s} \bigg)^\perp = \bigg( \frac{\mathrm{d} \theta}{\mathrm{d} s} + \frac{\omega_1^2}{\mathrm{d} s} \bigg) \boldsymbol{e}_2\] <p>故曲面\(S\)上的曲线\(C\)的测地曲率是</p> \[\kappa_g = \frac{\mathrm{d} \theta}{\mathrm{d} s} + \frac{\omega_1^2}{\mathrm{d} s}\] <p>法曲率是\(\kappa_n = \frac{\mathrm{d} \boldsymbol{e}_1}{\mathrm{d} s} \cdot \boldsymbol{n}\)，即</p> <p><a id="normal-curvature"></a></p> \[\kappa_n = \frac{\omega^1 \omega_1^3 + \omega^2 \omega_2^3}{\mathrm{d} s^2} = a \cos^2{\theta} + 2b \sin{\theta} \cos{\theta} + c \sin^2{\theta}\] <p>其中\(a\)，\(b\)，\(c\)是相对分量\(\omega_1^3\)，\(\omega_2^3\)用\(\omega^1\)，\(\omega^2\)线性表示时的<a href="#%E7%9B%B8%E5%AF%B9%E5%88%86%E9%87%8F%E7%9A%84%E7%BA%BF%E6%80%A7%E8%A1%A8%E7%A4%BA">系数</a>。为求得沿曲线\(C\)的单位正交标架场\(\{ \boldsymbol{r}; \boldsymbol{e}_1, \boldsymbol{e}_2, \boldsymbol{e}_3 \}\)的运动公式，还需要作如下计算：</p> \[\begin{aligned} \frac{\mathrm{d} \boldsymbol{e}_2}{\mathrm{d} s} &amp;= -(\cos{\theta} \boldsymbol{\alpha}_1 + \sin{\theta} \boldsymbol{\alpha}_2) \frac{\mathrm{d} \theta}{\mathrm{d} s} - \sin{\theta} \frac{\mathrm{d} \boldsymbol{\alpha}_1}{\mathrm{d} s} + \cos{\theta} \frac{\mathrm{d} \boldsymbol{\alpha}_2}{\mathrm{d} s} \\ &amp;= \bigg( \frac{\mathrm{d} \theta}{\mathrm{d} s} + \frac{\omega_1^2}{\mathrm{d} s}\bigg) \boldsymbol{e}_1 + \frac{\omega^1 \omega_2^3 - \omega^2 \omega_1^3}{\mathrm{d} s^2} \boldsymbol{e}_3 \end{aligned}\] <p>所以曲面\(S\)上的曲线\(C\)的测地挠率是</p> \[\tau_g = \frac{\omega^1 \omega_2^3 - \omega^2 \omega_1^3}{\mathrm{d} s^2} = b \cos^2{\theta} + (c-a) \cos{\theta} \sin{\theta} - b \sin^2{\theta}\] <p>前面推导的<a href="#normal-curvature">法曲率公式</a>可以看作切方向的方向角\(\theta\)的函数，使我们能够容易地考虑\(\kappa_n\)的极值性质。根据法曲率计算公式得到</p> \[\begin{aligned} \kappa_n &amp;= a \cdot \frac{1 + \cos{2 \theta}}{2} + b \sin{2 \theta} + c \cdot \frac{1 - \cos{2 \theta}}{2} \\ &amp;= \frac{a + c}{2} + \frac{a - c}{2} \cos{2 \theta} + b \sin{2 \theta} \end{aligned}\] <p>如果\(\frac{a - c}{2}\)，\(b\)同时为零，则\(\kappa_n = \frac{a+c}{2}\)与方向角\(\theta\)无关，即曲面\(S\)在该点沿各个切方向的法曲率都相同，因此该点是曲面\(S\)的脐点。假定\(\frac{a - c}{2}\)，\(b\)不同时为零，则可取\(\theta_0\)使得</p> \[\cos{2 \theta_0} = \frac{a-c}{\sqrt{(a-c)^2 + 4b^2}}, \ \ \ \sin{2 \theta_0} = \frac{2b}{\sqrt{(a-c)^2 + 4b^2}}\] <p>于是曲面\(S\)的法曲率\(\kappa_n\)可以写成</p> \[\kappa_n = \frac{a+c}{2} + \sqrt{\bigg( \frac{a-c}{2} \bigg)^2 + b^2} \cdot \cos{2 (\theta - \theta_0)}\] <p>由此可见，曲面\(S\)在一点的法曲率\(\kappa_n\)在\(\theta = \theta_0\)，\(\theta = \theta_0 + \pi\)时达到最大值</p> \[\kappa_1 = \frac{a+c}{2} + \sqrt{\bigg( \frac{a-c}{2} \bigg)^2 + b^2}\] <p>在\(\theta = \theta_0 + \frac{\pi}{2}\)，\(\theta = \theta_0 + \frac{3 \pi}{2}\)时达到最小值</p> \[\kappa_2 = \frac{a+c}{2} - \sqrt{\bigg( \frac{a-c}{2} \bigg)^2 + b^2}\] <p>换句话说，\(\kappa_1\)，\(\kappa_2\)是曲面\(S\)在一点的主曲率，\(\theta_0 + \frac{k \pi}{2}\)是曲面\(S\)在该点的主方向，而且对应于不同主曲率的主方向必定是彼此正交的。另外，从主曲率两个计算式得到</p> \[2 H = \kappa_1 + \kappa_2 = a + c, \ \ \ K = \kappa_1 \cdot \kappa_2 = ac - b^2\] <p><a href="#normal-curvature">法曲率公式</a>还能够进一步写成</p> \[\begin{aligned} \kappa_n &amp;= \frac{a+c}{2} + \sqrt{\bigg( \frac{a-c}{2} \bigg)^2 + b^2} \cdot (\cos^2{(\theta - \theta_0)} - \sin^2{(\theta - \theta_0)}) \\ &amp;= \bigg( \frac{a+c}{2} + \sqrt{\bigg( \frac{a-c}{2} \bigg)^2 + b^2} \bigg ) \cos^2{(\theta - \theta_0)} \\ &amp;+ \bigg( \frac{a+c}{2} - \sqrt{\bigg( \frac{a-c}{2} \bigg)^2 + b^2} \bigg) \sin^2{(\theta - \theta_0)} \\ &amp;= \kappa_1 \cos^2{(\theta - \theta_0)} + \kappa_2 \sin^2{(\theta - \theta_0)} \end{aligned}\] <p>这正是<a href="/blog/2023/DifferentialGeometry-NOTES-04/#euler%E5%85%AC%E5%BC%8F">Euler公式</a>的一般情形。如果取曲面\(S\)的一阶标架场\(\{ \boldsymbol{r}; \boldsymbol{\alpha}_1, \boldsymbol{\alpha}_2, \boldsymbol{\alpha}_3 \}\)使得\(\boldsymbol{\alpha}_1\)，\(\boldsymbol{\alpha}_2\)是曲面\(S\)的主方向，则这样的标架场称为曲面\(S\)的<strong>二阶标架场</strong>。对于曲面\(S\)的二阶标架场\(\{ \boldsymbol{r}; \boldsymbol{\alpha}_1, \boldsymbol{\alpha}_2, \boldsymbol{\alpha}_3 \}\)，显然有\(\theta_0 = 0\)，因此Euler公式成为</p> \[\kappa_n = \kappa_1 \cos^2{\theta} + \kappa_2 \sin^2{\theta}\] <p>这就是关于曲面\(S\)的法曲率的标准Euler公式。</p> <p>另外，当\(\frac{a - c}{2}\)，\(b\)不同时为零时，测地挠率能够改写成</p> \[\begin{aligned} \tau_g &amp;= b (\cos^2{\theta} - \sin^2{\theta}) + (c-a) \sin{\theta} \cos{\theta} \\ &amp;= b \cos{2 \theta} + \frac{c-a}{2} \sin{2 \theta} \\ &amp;= \sqrt{\bigg( \frac{a-c}{2} \bigg)^2 + b^2} \cdot (\sin{2 \theta_0} \cos{2 \theta} - \cos{2 \theta_0} \sin{2 \theta}) \\ &amp;= \frac{1}{2} (\kappa_2 - \kappa_1) \sin{2(\theta - \theta_0)} \end{aligned}\] <p>所以，曲面\(S\)在任意一点沿主方向\(\theta = \theta_0\)时总是有测地挠率\(\tau_g = 0\)。反之亦然，由此可见</p> \[\omega^1 \omega_2^3 - \omega^2 \omega_1^3 = 0\] <p>是曲面\(S\)上曲率线的微分方程。比较上式和<a href="#normal-curvature">法曲率计算公式</a>，不难知道</p> \[\frac{\mathrm{d} \kappa_n (\theta)}{\mathrm{d} \theta} = 2 \tau_g (\theta)\] <p>曲面\(S\)上的二阶标架场是与曲面\(S\)有更加密切关系的标架场。假定\(\{ \boldsymbol{r}; \boldsymbol{\alpha}_1, \boldsymbol{\alpha}_2, \boldsymbol{\alpha}_3 \}\)是曲面\(S\)的二阶标架场，则\(\theta_0 = 0\)，故\(b=0\)，因此</p> \[\omega_1^3 = a \omega^1, \ \ \ \omega_2^3 = c \omega^1\] <p>在\(a \geq c\)的假设下，我们有\(\kappa_1 = a\)，\(\kappa_2 = c\)，并且曲面\(S\)的第二基本形式成为</p> \[\mathrm{II} = \omega^1 \omega_1^3 + \omega^2 \omega_2^3 = \kappa_1 (\omega^1)^2 + \kappa_2 (\omega^2)^2\] <p>由此可见在曲面\(S\)的二阶标架场下，它的第一基本形式和第二基本形式有最简单的表达式。</p> </div> </article> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Bo Peng. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script defer src="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.js" integrity="sha256-4rppopQE9POKfukn2kEvhJ9Um25Cf6+IDVkARD0xh78=" crossorigin="anonymous"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-post",title:"Post",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-projects",title:"Projects",description:"A growing collection of my projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-cv",title:"CV",description:"\u4e2a\u4eba\u7b80\u5386",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"dropdown-formatting-guide",title:"Formatting Guide",description:"",section:"Dropdown",handler:()=>{window.location.href="/blog/"}},{id:"dropdown-leetcode",title:"LeetCode",description:"",section:"Dropdown",handler:()=>{window.location.href="/blog/"}},{id:"post-games001\u8bfe\u7a0b\u7b14\u8bb014-\u6df1\u5ea6\u5b66\u4e60",title:"GAMES001\u8bfe\u7a0b\u7b14\u8bb014-\u6df1\u5ea6\u5b66\u4e60",description:"\u751f\u6210\u5f0f\u6a21\u578b\u80cc\u540e\u7684\u6570\u5b66\u77e5\u8bc6",section:"Posts",handler:()=>{window.location.href="/blog/2024/GAMES001-NOTES-14/"}},{id:"post-games001\u8bfe\u7a0b\u7b14\u8bb013-\u4f18\u5316\u57fa\u7840",title:"GAMES001\u8bfe\u7a0b\u7b14\u8bb013-\u4f18\u5316\u57fa\u7840",description:"\u56fe\u5f62\u5b66\u4e2d\u5e38\u7528\u7684\u4f18\u5316\u65b9\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2024/GAMES001-NOTES-13/"}},{id:"post-games001\u8bfe\u7a0b\u7b14\u8bb012-\u7ebf\u6027\u7cfb\u7edf",title:"GAMES001\u8bfe\u7a0b\u7b14\u8bb012-\u7ebf\u6027\u7cfb\u7edf",description:"\u6c42\u89e3\u7ebf\u6027\u7cfb\u7edf\u7684\u76f8\u5173\u6280\u672f",section:"Posts",handler:()=>{window.location.href="/blog/2024/GAMES001-NOTES-12/"}},{id:"post-\u5fae\u5206\u51e0\u4f55\u7b14\u8bb007-\u6d3b\u52a8\u6807\u67b6\u548c\u5916\u5fae\u5206\u6cd5",title:"\u5fae\u5206\u51e0\u4f55\u7b14\u8bb007-\u6d3b\u52a8\u6807\u67b6\u548c\u5916\u5fae\u5206\u6cd5",description:"\u5fae\u5206\u51e0\u4f55\u4e2d\u7684\u5916\u5fae\u5206\u65b9\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2024/DifferentialGeometry-NOTES-07/"}},{id:"post-games001\u8bfe\u7a0b\u7b14\u8bb011-\u5fae\u5206\u65b9\u7a0b",title:"GAMES001\u8bfe\u7a0b\u7b14\u8bb011-\u5fae\u5206\u65b9\u7a0b",description:"\u5fae\u5206\u65b9\u7a0b\u7684\u6c42\u89e3\u65b9\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2024/GAMES001-NOTES-11/"}},{id:"post-games001\u8bfe\u7a0b\u7b14\u8bb010-\u53e4\u5178\u5fae\u5206\u51e0\u4f55",title:"GAMES001\u8bfe\u7a0b\u7b14\u8bb010-\u53e4\u5178\u5fae\u5206\u51e0\u4f55",description:"\u53e4\u5178\u5fae\u5206\u51e0\u4f55\u7684\u57fa\u672c\u77e5\u8bc6",section:"Posts",handler:()=>{window.location.href="/blog/2024/GAMES001-NOTES-10/"}},{id:"post-games001\u8bfe\u7a0b\u7b14\u8bb009-\u573a\u8bba\u521d\u6b65",title:"GAMES001\u8bfe\u7a0b\u7b14\u8bb009-\u573a\u8bba\u521d\u6b65",description:"\u573a\u8bba\u7684\u57fa\u672c\u77e5\u8bc6",section:"Posts",handler:()=>{window.location.href="/blog/2024/GAMES001-NOTES-09/"}},{id:"post-games001\u8bfe\u7a0b\u7b14\u8bb008-\u6982\u7387\u8bbaii",title:"GAMES001\u8bfe\u7a0b\u7b14\u8bb008-\u6982\u7387\u8bbaII",description:"\u6982\u7387\u8bba\u5728\u56fe\u5f62\u5b66\u4e2d\u7684\u5e94\u7528",section:"Posts",handler:()=>{window.location.href="/blog/2024/GAMES001-NOTES-08/"}},{id:"post-\u5fae\u5206\u51e0\u4f55\u7b14\u8bb006-\u6d4b\u5730\u66f2\u7387\u548c\u6d4b\u5730\u7ebf",title:"\u5fae\u5206\u51e0\u4f55\u7b14\u8bb006-\u6d4b\u5730\u66f2\u7387\u548c\u6d4b\u5730\u7ebf",description:"\u66f2\u9762\u7684\u5185\u8574\u51e0\u4f55",section:"Posts",handler:()=>{window.location.href="/blog/2024/DifferentialGeometry-NOTES-06/"}},{id:"post-a-post-with-tabs",title:"a post with tabs",description:"this is what included tabs in a post could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/tabs/"}},{id:"post-games001\u8bfe\u7a0b\u7b14\u8bb007-\u6982\u7387\u8bbai",title:"GAMES001\u8bfe\u7a0b\u7b14\u8bb007-\u6982\u7387\u8bbaI",description:"\u6982\u7387\u8bba\u57fa\u7840\u77e5\u8bc6",section:"Posts",handler:()=>{window.location.href="/blog/2024/GAMES001-NOTES-07/"}},{id:"post-a-post-with-typograms",title:"a post with typograms",description:"this is what included typograms code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/typograms/"}},{id:"post-a-post-that-can-be-cited",title:"a post that can be cited",description:"this is what a post that can be cited looks like",section:"Posts",handler:()=>{window.location.href="/blog/2024/post-citation/"}},{id:"post-games001\u8bfe\u7a0b\u7b14\u8bb006-\u5085\u91cc\u53f6\u53d8\u6362\u4e0e\u7403\u8c10\u51fd\u6570",title:"GAMES001\u8bfe\u7a0b\u7b14\u8bb006-\u5085\u91cc\u53f6\u53d8\u6362\u4e0e\u7403\u8c10\u51fd\u6570",description:"\u8c31\u53d8\u6362\u4e0e\u7403\u8c10\u51fd\u6570\u76f8\u5173\u77e5\u8bc6",section:"Posts",handler:()=>{window.location.href="/blog/2024/GAMES001-NOTES-06/"}},{id:"post-a-post-with-pseudo-code",title:"a post with pseudo code",description:"this is what included pseudo code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/pseudocode/"}},{id:"post-games001\u8bfe\u7a0b\u7b14\u8bb005-\u63d2\u503c-amp-\u62df\u5408",title:"GAMES001\u8bfe\u7a0b\u7b14\u8bb005-\u63d2\u503c&\u62df\u5408",description:"\u51fd\u6570\u63d2\u503c\u4e0e\u62df\u5408\u6280\u672f",section:"Posts",handler:()=>{window.location.href="/blog/2024/GAMES001-NOTES-05/"}},{id:"post-games001\u8bfe\u7a0b\u7b14\u8bb004-\u5947\u5f02\u503c\u5206\u89e3\u4e0e\u4e3b\u6210\u5206\u5206\u6790",title:"GAMES001\u8bfe\u7a0b\u7b14\u8bb004-\u5947\u5f02\u503c\u5206\u89e3\u4e0e\u4e3b\u6210\u5206\u5206\u6790",description:"SVD\u4e0ePCA\u80cc\u540e\u7684\u6570\u5b66",section:"Posts",handler:()=>{window.location.href="/blog/2024/GAMES001-NOTES-04/"}},{id:"post-games001\u8bfe\u7a0b\u7b14\u8bb003-\u65cb\u8f6c\u53d8\u6362",title:"GAMES001\u8bfe\u7a0b\u7b14\u8bb003-\u65cb\u8f6c\u53d8\u6362",description:"\u4e09\u7ef4\u65cb\u8f6c\u80cc\u540e\u7684\u6570\u5b66\u77e5\u8bc6",section:"Posts",handler:()=>{window.location.href="/blog/2024/GAMES001-NOTES-03/"}},{id:"post-games001\u8bfe\u7a0b\u7b14\u8bb002-\u8ba1\u7b97\u51e0\u4f55",title:"GAMES001\u8bfe\u7a0b\u7b14\u8bb002-\u8ba1\u7b97\u51e0\u4f55",description:"\u8ba1\u7b97\u51e0\u4f55\u76f8\u5173\u5185\u5bb9",section:"Posts",handler:()=>{window.location.href="/blog/2024/GAMES001-NOTES-02/"}},{id:"post-games001\u8bfe\u7a0b\u7b14\u8bb001-\u7ebf\u6027\u4ee3\u6570\u57fa\u7840",title:"GAMES001\u8bfe\u7a0b\u7b14\u8bb001-\u7ebf\u6027\u4ee3\u6570\u57fa\u7840",description:"\u7ebf\u6027\u4ee3\u6570\u57fa\u7840\u77e5\u8bc6",section:"Posts",handler:()=>{window.location.href="/blog/2024/GAMES001-NOTES-01/"}},{id:"post-a-post-with-code-diff",title:"a post with code diff",description:"this is how you can display code diffs",section:"Posts",handler:()=>{window.location.href="/blog/2024/code-diff/"}},{id:"post-a-post-with-advanced-image-components",title:"a post with advanced image components",description:"this is what advanced image components could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/advanced-images/"}},{id:"post-a-post-with-vega-lite",title:"a post with vega lite",description:"this is what included vega lite code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/vega-lite/"}},{id:"post-a-post-with-geojson",title:"a post with geojson",description:"this is what included geojson code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/geojson-map/"}},{id:"post-a-post-with-echarts",title:"a post with echarts",description:"this is what included echarts code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/echarts/"}},{id:"post-a-post-with-chart-js",title:"a post with chart.js",description:"this is what included chart.js code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/chartjs/"}},{id:"post-\u5fae\u5206\u51e0\u4f55\u7b14\u8bb005-\u66f2\u9762\u8bba\u57fa\u672c\u5b9a\u7406",title:"\u5fae\u5206\u51e0\u4f55\u7b14\u8bb005-\u66f2\u9762\u8bba\u57fa\u672c\u5b9a\u7406",description:"\u66f2\u9762\u8bba\u57fa\u672c\u5b9a\u7406",section:"Posts",handler:()=>{window.location.href="/blog/2023/DifferentialGeometry-NOTES-05/"}},{id:"post-a-post-with-tikzjax",title:"a post with TikZJax",description:"this is what included TikZ code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/tikzjax/"}},{id:"post-c-stl\u7b14\u8bb005-std-list\u53cc\u5411\u94fe\u8868",title:"C++ STL\u7b14\u8bb005-std::list\u53cc\u5411\u94fe\u8868",description:"\u52a8\u624b\u5b9e\u73b0std::list",section:"Posts",handler:()=>{window.location.href="/blog/2023/STL-NOTES-05/"}},{id:"post-c-stl\u7b14\u8bb004-std-vector\u52a8\u6001\u6570\u7ec4",title:"C++ STL\u7b14\u8bb004-std::vector\u52a8\u6001\u6570\u7ec4",description:"\u52a8\u624b\u5b9e\u73b0std::vector",section:"Posts",handler:()=>{window.location.href="/blog/2023/STL-NOTES-04/"}},{id:"post-\u5fae\u5206\u51e0\u4f55\u7b14\u8bb004-\u66f2\u9762\u7684\u7b2c\u4e8c\u57fa\u672c\u5f62\u5f0f",title:"\u5fae\u5206\u51e0\u4f55\u7b14\u8bb004-\u66f2\u9762\u7684\u7b2c\u4e8c\u57fa\u672c\u5f62\u5f0f",description:"\u66f2\u9762\u7684\u7b2c\u4e8c\u57fa\u672c\u5f62\u5f0f",section:"Posts",handler:()=>{window.location.href="/blog/2023/DifferentialGeometry-NOTES-04/"}},{id:"post-c-stl\u7b14\u8bb003-std-array\u6570\u7ec4",title:"C++ STL\u7b14\u8bb003-std::array\u6570\u7ec4",description:"\u52a8\u624b\u5b9e\u73b0std::array",section:"Posts",handler:()=>{window.location.href="/blog/2023/STL-NOTES-03/"}},{id:"post-\u5fae\u5206\u51e0\u4f55\u7b14\u8bb003-\u66f2\u9762\u7684\u7b2c\u4e00\u57fa\u672c\u5f62\u5f0f",title:"\u5fae\u5206\u51e0\u4f55\u7b14\u8bb003-\u66f2\u9762\u7684\u7b2c\u4e00\u57fa\u672c\u5f62\u5f0f",description:"\u66f2\u9762\u7684\u7b2c\u4e00\u57fa\u672c\u5f62\u5f0f",section:"Posts",handler:()=>{window.location.href="/blog/2023/DifferentialGeometry-NOTES-03/"}},{id:"post-c-stl\u7b14\u8bb002-std-unique-ptr\u72ec\u5360\u578b\u667a\u80fd\u6307\u9488",title:"C++ STL\u7b14\u8bb002-std::unique_ptr\u72ec\u5360\u578b\u667a\u80fd\u6307\u9488",description:"\u52a8\u624b\u5b9e\u73b0std::unique_ptr",section:"Posts",handler:()=>{window.location.href="/blog/2023/STL-NOTES-02/"}},{id:"post-c-stl\u7b14\u8bb001-std-function\u5bb9\u5668",title:"C++ STL\u7b14\u8bb001-std::function\u5bb9\u5668",description:"\u52a8\u624b\u5b9e\u73b0std::function",section:"Posts",handler:()=>{window.location.href="/blog/2023/STL-NOTES-01/"}},{id:"post-\u5fae\u5206\u51e0\u4f55\u7b14\u8bb002-\u66f2\u7ebf\u8bba",title:"\u5fae\u5206\u51e0\u4f55\u7b14\u8bb002-\u66f2\u7ebf\u8bba",description:"\u66f2\u7ebf\u8bba\u76f8\u5173\u77e5\u8bc6",section:"Posts",handler:()=>{window.location.href="/blog/2023/DifferentialGeometry-NOTES-02/"}},{id:"post-\u5fae\u5206\u51e0\u4f55\u7b14\u8bb001-\u9884\u5907\u77e5\u8bc6",title:"\u5fae\u5206\u51e0\u4f55\u7b14\u8bb001-\u9884\u5907\u77e5\u8bc6",description:"\u5fae\u5206\u51e0\u4f55\u9884\u5907\u77e5\u8bc6\u4e0e\u5e38\u7528\u7ed3\u8bba",section:"Posts",handler:()=>{window.location.href="/blog/2023/DifferentialGeometry-NOTES-01/"}},{id:"post-a-post-with-bibliography",title:"a post with bibliography",description:"an example of a blog post with bibliography",section:"Posts",handler:()=>{window.location.href="/blog/2023/post-bibliography/"}},{id:"post-a-post-with-jupyter-notebook",title:"a post with jupyter notebook",description:"an example of a blog post with jupyter notebook",section:"Posts",handler:()=>{window.location.href="/blog/2023/jupyter-notebook/"}},{id:"post-a-post-with-custom-blockquotes",title:"a post with custom blockquotes",description:"an example of a blog post with custom blockquotes",section:"Posts",handler:()=>{window.location.href="/blog/2023/custom-blockquotes/"}},{id:"post-a-post-with-table-of-contents-on-a-sidebar",title:"a post with table of contents on a sidebar",description:"an example of a blog post with table of contents on a sidebar",section:"Posts",handler:()=>{window.location.href="/blog/2023/sidebar-table-of-contents/"}},{id:"post-a-post-with-audios",title:"a post with audios",description:"this is what included audios could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/audios/"}},{id:"post-a-post-with-videos",title:"a post with videos",description:"this is what included videos could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/videos/"}},{id:"post-\u5e76\u67e5\u96c6",title:"\u5e76\u67e5\u96c6",description:"LeetCode\u5e76\u67e5\u96c6\u4e60\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/UnionFindSet/"}},{id:"post-\u56fe\u8bba",title:"\u56fe\u8bba",description:"LeetCode\u56fe\u8bba\u4e60\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/Graph/"}},{id:"post-\u5355\u8c03\u6808",title:"\u5355\u8c03\u6808",description:"LeetCode\u5355\u8c03\u6808\u4e60\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/MonotoneStack/"}},{id:"post-displaying-beautiful-tables-with-bootstrap-tables",title:"displaying beautiful tables with Bootstrap Tables",description:"an example of how to use Bootstrap Tables",section:"Posts",handler:()=>{window.location.href="/blog/2023/tables/"}},{id:"post-a-post-with-table-of-contents",title:"a post with table of contents",description:"an example of a blog post with table of contents",section:"Posts",handler:()=>{window.location.href="/blog/2023/table-of-contents/"}},{id:"post-\u52a8\u6001\u89c4\u5212",title:"\u52a8\u6001\u89c4\u5212",description:"LeetCode\u52a8\u6001\u89c4\u5212\u4e60\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/DynamicProgramming/"}},{id:"post-\u8d2a\u5fc3",title:"\u8d2a\u5fc3",description:"LeetCode\u8d2a\u5fc3\u4e60\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/Greedy/"}},{id:"post-\u56de\u6eaf",title:"\u56de\u6eaf",description:"LeetCode\u56de\u6eaf\u4e60\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/Backtracking/"}},{id:"post-shape-analysis\u8bfe\u7a0b\u7b14\u8bb021-consistent-correspondence",title:"Shape Analysis\u8bfe\u7a0b\u7b14\u8bb021-Consistent Correspondence",description:"\u66f2\u9762\u5bf9\u5e94\u7684\u4e00\u81f4\u6027\u95ee\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/SA-NOTES-21/"}},{id:"post-shape-analysis\u8bfe\u7a0b\u7b14\u8bb020-correspondence-problems",title:"Shape Analysis\u8bfe\u7a0b\u7b14\u8bb020-Correspondence Problems",description:"\u66f2\u9762\u5bf9\u5e94\u95ee\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/SA-NOTES-20/"}},{id:"post-\u4e8c\u53c9\u6811",title:"\u4e8c\u53c9\u6811",description:"LeetCode\u4e8c\u53c9\u6811\u4e60\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/BinaryTree/"}},{id:"post-\u6808\u4e0e\u961f\u5217",title:"\u6808\u4e0e\u961f\u5217",description:"LeetCode\u6808\u4e0e\u961f\u5217\u4e60\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/StackQueue/"}},{id:"post-\u53cc\u6307\u9488",title:"\u53cc\u6307\u9488",description:"LeetCode\u53cc\u6307\u9488\u4e60\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/TwoPointers/"}},{id:"post-\u5b57\u7b26\u4e32",title:"\u5b57\u7b26\u4e32",description:"LeetCode\u5b57\u7b26\u4e32\u4e60\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/String/"}},{id:"post-\u54c8\u5e0c\u8868",title:"\u54c8\u5e0c\u8868",description:"LeetCode\u54c8\u5e0c\u8868\u4e60\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/HashTable/"}},{id:"post-shape-analysis\u8bfe\u7a0b\u7b14\u8bb019-clustering-and-segmentation",title:"Shape Analysis\u8bfe\u7a0b\u7b14\u8bb019-Clustering and Segmentation",description:"\u805a\u7c7b\u548c\u5206\u5272\u95ee\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/SA-NOTES-19/"}},{id:"post-shape-analysis\u8bfe\u7a0b\u7b14\u8bb018-optimal-transport",title:"Shape Analysis\u8bfe\u7a0b\u7b14\u8bb018-Optimal Transport",description:"\u6700\u4f18\u8fd0\u8f93\u95ee\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/SA-NOTES-18/"}},{id:"post-shape-analysis\u8bfe\u7a0b\u7b14\u8bb017-optimization-on-manifolds",title:"Shape Analysis\u8bfe\u7a0b\u7b14\u8bb017-Optimization on Manifolds",description:"\u6d41\u5f62\u4e0a\u7684\u4f18\u5316",section:"Posts",handler:()=>{window.location.href="/blog/2023/SA-NOTES-17/"}},{id:"post-\u94fe\u8868",title:"\u94fe\u8868",description:"LeetCode\u94fe\u8868\u4e60\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/LinkedList/"}},{id:"post-\u6570\u7ec4",title:"\u6570\u7ec4",description:"LeetCode\u6570\u7ec4\u4e60\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2023/Array/"}},{id:"post-shape-analysis\u8bfe\u7a0b\u7b14\u8bb016-vector-fields-discretization",title:"Shape Analysis\u8bfe\u7a0b\u7b14\u8bb016-Vector Fields Discretization",description:"\u79bb\u6563\u66f2\u9762\u4e0a\u7684\u5411\u91cf\u573a",section:"Posts",handler:()=>{window.location.href="/blog/2022/SA-NOTES-16/"}},{id:"post-shape-analysis\u8bfe\u7a0b\u7b14\u8bb015-vector-fields-introduction",title:"Shape Analysis\u8bfe\u7a0b\u7b14\u8bb015-Vector Fields Introduction",description:"\u5411\u91cf\u573a",section:"Posts",handler:()=>{window.location.href="/blog/2022/SA-NOTES-15/"}},{id:"post-shape-analysis\u8bfe\u7a0b\u7b14\u8bb014-applications-of-the-laplacian",title:"Shape Analysis\u8bfe\u7a0b\u7b14\u8bb014-Applications of the Laplacian",description:"Laplace\u7b97\u5b50\u7684\u5e94\u7528",section:"Posts",handler:()=>{window.location.href="/blog/2022/SA-NOTES-14/"}},{id:"post-boundary-first-flattening-\u8bba\u6587\u7b14\u8bb0",title:"Boundary First Flattening \u8bba\u6587\u7b14\u8bb0",description:"\u4f5c\u4e1a4\u89e3\u6790\u4e0eBFF\u53c2\u6570\u5316\u7b97\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES301-BFF/"}},{id:"post-lscm-mean-value-coordinates-\u8bba\u6587\u7b14\u8bb0",title:"LSCM + Mean Value Coordinates \u8bba\u6587\u7b14\u8bb0",description:"\u4f5c\u4e1a3\u89e3\u6790\u4e0eLSCM\u53c2\u6570\u5316\u7b97\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES301-LSCM+MVC/"}},{id:"post-games104\u8bfe\u7a0b\u7b14\u8bb022-gpu-driven-geometry-pipeline-nanite",title:"GAMES104\u8bfe\u7a0b\u7b14\u8bb022-GPU-Driven Geometry Pipeline-Nanite",description:"GPU\u9a71\u52a8\u7684\u51e0\u4f55\u7ba1\u7ebf\u4e0eNanite\u6280\u672f",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES104-NOTES-22/"}},{id:"post-a-post-with-giscus-comments",title:"a post with giscus comments",description:"an example of a blog post with giscus comments",section:"Posts",handler:()=>{window.location.href="/blog/2022/giscus-comments/"}},{id:"post-analytic-eigensystems-for-isotropic-distortion-energies-\u8bba\u6587\u7b14\u8bb0",title:"Analytic Eigensystems for Isotropic Distortion Energies \u8bba\u6587\u7b14\u8bb0",description:"\u4f5c\u4e1a2\u89e3\u6790\u4e0eAES\u53c2\u6570\u5316\u7b97\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES301-AES/"}},{id:"post-games301\u8bfe\u7a0b\u7b14\u8bb015-\u53c2\u6570\u5316\u5728\u4ea7\u4e1a\u4e2d\u7684\u5e94\u75282",title:"GAMES301\u8bfe\u7a0b\u7b14\u8bb015-\u53c2\u6570\u5316\u5728\u4ea7\u4e1a\u4e2d\u7684\u5e94\u75282",description:"\u66f2\u9762\u53c2\u6570\u5316\u5728\u76f8\u5173\u4ea7\u4e1a\u4e2d\u7684\u5e94\u7528",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES301-NOTES-15/"}},{id:"post-games301\u8bfe\u7a0b\u7b14\u8bb014-\u53c2\u6570\u5316\u5728\u4ea7\u4e1a\u4e2d\u7684\u5e94\u75281",title:"GAMES301\u8bfe\u7a0b\u7b14\u8bb014-\u53c2\u6570\u5316\u5728\u4ea7\u4e1a\u4e2d\u7684\u5e94\u75281",description:"\u66f2\u9762\u53c2\u6570\u5316\u5728\u76f8\u5173\u4ea7\u4e1a\u4e2d\u7684\u5e94\u7528",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES301-NOTES-14/"}},{id:"post-games301\u8bfe\u7a0b\u7b14\u8bb013-\u53c2\u6570\u5316\u5e94\u75283-\u66f2\u9762\u5bf9\u5e94-\u9ad8\u9636\u591a\u9879\u5f0f\u6620\u5c04",title:"GAMES301\u8bfe\u7a0b\u7b14\u8bb013-\u53c2\u6570\u5316\u5e94\u75283(\u66f2\u9762\u5bf9\u5e94\u3001\u9ad8\u9636\u591a\u9879\u5f0f\u6620\u5c04)",description:"\u66f2\u9762\u53c2\u6570\u5316\u7684\u9ad8\u7ea7\u5e94\u7528",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES301-NOTES-13/"}},{id:"post-games301\u8bfe\u7a0b\u7b14\u8bb012-\u9525\u5947\u5f02\u70b9\u53c2\u6570\u5316\u5e94\u7528",title:"GAMES301\u8bfe\u7a0b\u7b14\u8bb012-\u9525\u5947\u5f02\u70b9\u53c2\u6570\u5316\u5e94\u7528",description:"\u9525\u5947\u5f02\u70b9\u53c2\u6570\u5316",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES301-NOTES-12/"}},{id:"post-games301\u8bfe\u7a0b\u7b14\u8bb011-\u5171\u5f62\u53c2\u6570\u53162-\u79bb\u6563\u5171\u5f62\u7b49\u4ef7\u7c7b-\u66f2\u7387\u6d41",title:"GAMES301\u8bfe\u7a0b\u7b14\u8bb011-\u5171\u5f62\u53c2\u6570\u53162(\u79bb\u6563\u5171\u5f62\u7b49\u4ef7\u7c7b\u3001\u66f2\u7387\u6d41)",description:"\u5171\u5f62\u53c2\u6570\u5316\u7684\u57fa\u672c\u7406\u8bba",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES301-NOTES-11/"}},{id:"post-games301\u8bfe\u7a0b\u7b14\u8bb010-\u5171\u5f62\u53c2\u6570\u53161-circle\u586b\u5145-\u67ef\u897f\u9ece\u66fc\u65b9\u7a0b",title:"GAMES301\u8bfe\u7a0b\u7b14\u8bb010-\u5171\u5f62\u53c2\u6570\u53161(Circle\u586b\u5145\u3001\u67ef\u897f\u9ece\u66fc\u65b9\u7a0b)",description:"\u5171\u5f62\u53c2\u6570\u5316\u7684\u57fa\u672c\u7406\u8bba",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES301-NOTES-10/"}},{id:"post-games301\u8bfe\u7a0b\u7b14\u8bb009-\u57fa\u4e8e\u8c03\u548c\u6620\u5c04\u7684\u9ad8\u8d28\u91cf\u5f62\u53d8",title:"GAMES301\u8bfe\u7a0b\u7b14\u8bb009-\u57fa\u4e8e\u8c03\u548c\u6620\u5c04\u7684\u9ad8\u8d28\u91cf\u5f62\u53d8",description:"\u57fa\u4e8e\u8c03\u548c\u6620\u5c04\u7684\u7f51\u683c\u5f62\u53d8\u6280\u672f",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES301-NOTES-09/"}},{id:"post-games301\u8bfe\u7a0b\u7b14\u8bb008-\u65e0\u7ffb\u8f6c\u5149\u6ed1\u6620\u5c04",title:"GAMES301\u8bfe\u7a0b\u7b14\u8bb008-\u65e0\u7ffb\u8f6c\u5149\u6ed1\u6620\u5c04",description:"\u7f51\u683c\u4e0a\u7684\u65e0\u7ffb\u8f6c\u5149\u6ed1\u6620\u5c04",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES301-NOTES-08/"}},{id:"post-games301\u8bfe\u7a0b\u7b14\u8bb007-\u53c2\u6570\u5316\u5e94\u75282-\u7f51\u683c\u751f\u6210",title:"GAMES301\u8bfe\u7a0b\u7b14\u8bb007-\u53c2\u6570\u5316\u5e94\u75282(\u7f51\u683c\u751f\u6210)",description:"\u66f2\u9762\u53c2\u6570\u5316\u5728\u7f51\u683c\u751f\u6210\u4e2d\u7684\u5e94\u7528",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES301-NOTES-07/"}},{id:"post-omscs-ga\u8bfe\u7a0b\u7b14\u8bb007-linear-programming",title:"OMSCS-GA\u8bfe\u7a0b\u7b14\u8bb007-Linear Programming",description:"\u7ebf\u6027\u89c4\u5212",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-GA-NOTES-07/"}},{id:"post-games301\u8bfe\u7a0b\u7b14\u8bb006-\u53c2\u6570\u5316\u5e94\u75281-atlas\u751f\u6210-\u827a\u672f\u8bbe\u8ba1",title:"GAMES301\u8bfe\u7a0b\u7b14\u8bb006-\u53c2\u6570\u5316\u5e94\u75281(Atlas\u751f\u6210\u3001\u827a\u672f\u8bbe\u8ba1)",description:"\u66f2\u9762\u53c2\u6570\u5316\u5728Atlas\u751f\u6210\u548c\u827a\u672f\u8bbe\u8ba1\u9886\u57df\u4e2d\u7684\u5e94\u7528",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES301-NOTES-06/"}},{id:"post-omscs-ga\u8bfe\u7a0b\u7b14\u8bb006-np-completeness",title:"OMSCS-GA\u8bfe\u7a0b\u7b14\u8bb006-NP Completeness",description:"NP\u5b8c\u5907\u7406\u8bba",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-GA-NOTES-06/"}},{id:"post-games301\u8bfe\u7a0b\u7b14\u8bb005-\u5168\u5c40\u5355\u5c04\u53c2\u6570\u5316\u65b9\u6cd5",title:"GAMES301\u8bfe\u7a0b\u7b14\u8bb005-\u5168\u5c40\u5355\u5c04\u53c2\u6570\u5316\u65b9\u6cd5",description:"\u5168\u5c40\u5355\u5c04\u53c2\u6570\u5316\u65b9\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES301-NOTES-05/"}},{id:"post-games301\u8bfe\u7a0b\u7b14\u8bb004-\u65e0\u7ffb\u8f6c\u53c2\u6570\u5316\u65b9\u6cd5-\u521d\u59cb\u65e0\u7ffb\u8f6c",title:"GAMES301\u8bfe\u7a0b\u7b14\u8bb004-\u65e0\u7ffb\u8f6c\u53c2\u6570\u5316\u65b9\u6cd5(\u521d\u59cb\u65e0\u7ffb\u8f6c)",description:"\u521d\u59cb\u65e0\u7ffb\u8f6c\u60c5\u51b5\u4e0b\u7684\u7684\u65e0\u7ffb\u8f6c\u53c2\u6570\u5316\u65b9\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES301-NOTES-04/"}},{id:"post-games301\u8bfe\u7a0b\u7b14\u8bb003-\u65e0\u7ffb\u8f6c\u53c2\u6570\u5316\u65b9\u6cd5-\u521d\u59cb\u5b58\u5728\u7ffb\u8f6c",title:"GAMES301\u8bfe\u7a0b\u7b14\u8bb003-\u65e0\u7ffb\u8f6c\u53c2\u6570\u5316\u65b9\u6cd5(\u521d\u59cb\u5b58\u5728\u7ffb\u8f6c)",description:"\u5b58\u5728\u521d\u59cb\u7ffb\u8f6c\u60c5\u51b5\u4e0b\u7684\u65e0\u7ffb\u8f6c\u53c2\u6570\u5316\u65b9\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES301-NOTES-03/"}},{id:"post-games301\u8bfe\u7a0b\u7b14\u8bb002-\u9762\u5411\u79bb\u6563\u7f51\u683c\u7684\u53c2\u6570\u5316\u6982\u8ff0",title:"GAMES301\u8bfe\u7a0b\u7b14\u8bb002-\u9762\u5411\u79bb\u6563\u7f51\u683c\u7684\u53c2\u6570\u5316\u6982\u8ff0",description:"\u79bb\u6563\u7f51\u683c\u7684\u53c2\u6570\u5316\u65b9\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES301-NOTES-02/"}},{id:"post-games301\u8bfe\u7a0b\u7b14\u8bb001-\u66f2\u9762\u53c2\u6570\u5316\u4ecb\u7ecd",title:"GAMES301\u8bfe\u7a0b\u7b14\u8bb001-\u66f2\u9762\u53c2\u6570\u5316\u4ecb\u7ecd",description:"\u66f2\u9762\u53c2\u6570\u5316\u7684\u6982\u5ff5\u53ca\u5e94\u7528",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES301-NOTES-01/"}},{id:"post-games104\u8bfe\u7a0b\u7b14\u8bb021-dynamic-global-illumination-and-lumen",title:"GAMES104\u8bfe\u7a0b\u7b14\u8bb021-Dynamic Global Illumination and Lumen",description:"\u73b0\u4ee3\u6e38\u620f\u5f15\u64ce\u4e2d\u7684\u5168\u5c40\u5149\u7167\u6280\u672f",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES104-NOTES-21/"}},{id:"post-omscs-ga\u8bfe\u7a0b\u7b14\u8bb005-randomized-algorithms",title:"OMSCS-GA\u8bfe\u7a0b\u7b14\u8bb005-Randomized Algorithms",description:"\u5bc6\u7801\u5b66\u4e0e\u968f\u673a\u7b97\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-GA-NOTES-05/"}},{id:"post-omscs-ga\u8bfe\u7a0b\u7b14\u8bb004-max-flow",title:"OMSCS-GA\u8bfe\u7a0b\u7b14\u8bb004-Max Flow",description:"\u6700\u5927\u6d41",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-GA-NOTES-04/"}},{id:"post-omscs-ga\u8bfe\u7a0b\u7b14\u8bb003-graph-algorithms",title:"OMSCS-GA\u8bfe\u7a0b\u7b14\u8bb003-Graph Algorithms",description:"\u56fe\u7b97\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-GA-NOTES-03/"}},{id:"post-shape-analysis\u8bfe\u7a0b\u7b14\u8bb013-discrete-laplacian-operators",title:"Shape Analysis\u8bfe\u7a0b\u7b14\u8bb013-Discrete Laplacian Operators",description:"\u79bb\u6563Laplace\u7b97\u5b50",section:"Posts",handler:()=>{window.location.href="/blog/2022/SA-NOTES-13/"}},{id:"post-shape-analysis\u8bfe\u7a0b\u7b14\u8bb012-the-laplacian-operator",title:"Shape Analysis\u8bfe\u7a0b\u7b14\u8bb012-The Laplacian Operator",description:"Laplace\u7b97\u5b50",section:"Posts",handler:()=>{window.location.href="/blog/2022/SA-NOTES-12/"}},{id:"post-omscs-ga\u8bfe\u7a0b\u7b14\u8bb002-divide-and-conquer",title:"OMSCS-GA\u8bfe\u7a0b\u7b14\u8bb002-Divide and Conquer",description:"\u5206\u6cbb\u7b97\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-GA-NOTES-02/"}},{id:"post-shape-analysis\u8bfe\u7a0b\u7b14\u8bb011-structure-preserving-embedding",title:"Shape Analysis\u8bfe\u7a0b\u7b14\u8bb011-Structure Preserving Embedding",description:"\u6d41\u5f62\u4e0a\u7684\u5d4c\u5165",section:"Posts",handler:()=>{window.location.href="/blog/2022/SA-NOTES-11/"}},{id:"post-games104\u8bfe\u7a0b\u7b14\u8bb020-data-oriented-programming-and-job-system",title:"GAMES104\u8bfe\u7a0b\u7b14\u8bb020-Data-Oriented Programming and Job System",description:"\u9762\u5411\u6570\u636e\u7f16\u7a0b\u4ee5\u53ca\u4efb\u52a1\u7cfb\u7edf",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES104-NOTES-20/"}},{id:"post-shape-analysis\u8bfe\u7a0b\u7b14\u8bb010-distance-metrics-and-embeddings",title:"Shape Analysis\u8bfe\u7a0b\u7b14\u8bb010-Distance Metrics and Embeddings",description:"\u5ea6\u91cf\u7a7a\u95f4",section:"Posts",handler:()=>{window.location.href="/blog/2022/SA-NOTES-10/"}},{id:"post-shape-analysis\u8bfe\u7a0b\u7b14\u8bb009-geodesic-distances-algorithms",title:"Shape Analysis\u8bfe\u7a0b\u7b14\u8bb009-Geodesic Distances Algorithms",description:"\u6d4b\u5730\u7ebf\u7684\u8ba1\u7b97",section:"Posts",handler:()=>{window.location.href="/blog/2022/SA-NOTES-09/"}},{id:"post-omscs-ga\u8bfe\u7a0b\u7b14\u8bb001-dynamic-programming",title:"OMSCS-GA\u8bfe\u7a0b\u7b14\u8bb001-Dynamic Programming",description:"\u52a8\u6001\u89c4\u5212",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-GA-NOTES-01/"}},{id:"post-shape-analysis\u8bfe\u7a0b\u7b14\u8bb008-geodesic-distances-intro-amp-theory",title:"Shape Analysis\u8bfe\u7a0b\u7b14\u8bb008-Geodesic Distances Intro & Theory",description:"\u6d4b\u5730\u7ebf",section:"Posts",handler:()=>{window.location.href="/blog/2022/SA-NOTES-08/"}},{id:"post-shape-analysis\u8bfe\u7a0b\u7b14\u8bb007-discrete-surface-curvature",title:"Shape Analysis\u8bfe\u7a0b\u7b14\u8bb007-Discrete Surface Curvature",description:"\u79bb\u6563\u66f2\u9762\u4e0a\u7684\u66f2\u7387",section:"Posts",handler:()=>{window.location.href="/blog/2022/SA-NOTES-07/"}},{id:"post-shape-analysis\u8bfe\u7a0b\u7b14\u8bb006-smooth-surface-curvature",title:"Shape Analysis\u8bfe\u7a0b\u7b14\u8bb006-Smooth Surface Curvature",description:"\u5149\u6ed1\u66f2\u9762\u4e0a\u7684\u66f2\u7387",section:"Posts",handler:()=>{window.location.href="/blog/2022/SA-NOTES-06/"}},{id:"post-games104\u8bfe\u7a0b\u7b14\u8bb019-online-gaming-architecture-advanced-topics",title:"GAMES104\u8bfe\u7a0b\u7b14\u8bb019-Online Gaming Architecture Advanced Topics",description:"\u7f51\u7edc\u6e38\u620f\u67b6\u6784\u7684\u9ad8\u7ea7\u6280\u672f",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES104-NOTES-19/"}},{id:"post-shape-analysis\u8bfe\u7a0b\u7b14\u8bb005-smooth-and-discrete-surface",title:"Shape Analysis\u8bfe\u7a0b\u7b14\u8bb005-Smooth and Discrete Surface",description:"\u66f2\u9762\u7406\u8bba",section:"Posts",handler:()=>{window.location.href="/blog/2022/SA-NOTES-05/"}},{id:"post-games104\u8bfe\u7a0b\u7b14\u8bb018-online-gaming-architecture-fundamentals",title:"GAMES104\u8bfe\u7a0b\u7b14\u8bb018-Online Gaming Architecture Fundamentals",description:"\u7f51\u7edc\u6e38\u620f\u7684\u67b6\u6784\u57fa\u7840",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES104-NOTES-18/"}},{id:"post-shape-analysis\u8bfe\u7a0b\u7b14\u8bb004-discrete-curves",title:"Shape Analysis\u8bfe\u7a0b\u7b14\u8bb004-Discrete Curves",description:"\u79bb\u6563\u66f2\u7ebf",section:"Posts",handler:()=>{window.location.href="/blog/2022/SA-NOTES-04/"}},{id:"post-shape-analysis\u8bfe\u7a0b\u7b14\u8bb003-continuous-curves",title:"Shape Analysis\u8bfe\u7a0b\u7b14\u8bb003-Continuous Curves",description:"\u8fde\u7eed\u66f2\u7ebf",section:"Posts",handler:()=>{window.location.href="/blog/2022/SA-NOTES-03/"}},{id:"post-shape-analysis\u8bfe\u7a0b\u7b14\u8bb002-linear-and-variational-problems",title:"Shape Analysis\u8bfe\u7a0b\u7b14\u8bb002-Linear and Variational Problems",description:"\u6570\u5b66\u57fa\u7840",section:"Posts",handler:()=>{window.location.href="/blog/2022/SA-NOTES-02/"}},{id:"post-shape-analysis\u8bfe\u7a0b\u7b14\u8bb001-introduction",title:"Shape Analysis\u8bfe\u7a0b\u7b14\u8bb001-Introduction",description:"\u8bfe\u7a0b\u7b80\u4ecb\u4e0e\u5927\u7eb2",section:"Posts",handler:()=>{window.location.href="/blog/2022/SA-NOTES-01/"}},{id:"post-games104\u8bfe\u7a0b\u7b14\u8bb017-advanced-artificial-intelligence",title:"GAMES104\u8bfe\u7a0b\u7b14\u8bb017-Advanced Artificial Intelligence",description:"\u6e38\u620fAI\u7684\u9ad8\u7ea7\u6280\u672f",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES104-NOTES-17/"}},{id:"post-games104\u8bfe\u7a0b\u7b14\u8bb016-basic-artificial-intelligence",title:"GAMES104\u8bfe\u7a0b\u7b14\u8bb016-Basic Artificial Intelligence",description:"\u6e38\u620fAI",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES104-NOTES-16/"}},{id:"post-games104\u8bfe\u7a0b\u7b14\u8bb015-gameplay-complexity-and-building-blocks",title:"GAMES104\u8bfe\u7a0b\u7b14\u8bb015-Gameplay Complexity and Building Blocks",description:"\u6e38\u620f\u5f15\u64ce\u4e2d\u7684\u73a9\u6cd5\u7cfb\u7edf",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES104-NOTES-15/"}},{id:"post-omscs-rl\u8bfe\u7a0b\u7b14\u8bb014-ccc",
title:"OMSCS-RL\u8bfe\u7a0b\u7b14\u8bb014-CCC",description:"\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-RL-NOTES-14/"}},{id:"post-omscs-rl\u8bfe\u7a0b\u7b14\u8bb013-game-theory-revolutions",title:"OMSCS-RL\u8bfe\u7a0b\u7b14\u8bb013-Game Theory Revolutions",description:"\u535a\u5f08\u8bba\u57fa\u7840III",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-RL-NOTES-13/"}},{id:"post-omscs-rl\u8bfe\u7a0b\u7b14\u8bb012-game-theory-reloaded",title:"OMSCS-RL\u8bfe\u7a0b\u7b14\u8bb012-Game Theory Reloaded",description:"\u535a\u5f08\u8bba\u57fa\u7840II",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-RL-NOTES-12/"}},{id:"post-games104\u8bfe\u7a0b\u7b14\u8bb014-applications-amp-advanced-topic",title:"GAMES104\u8bfe\u7a0b\u7b14\u8bb014-Applications & Advanced Topic",description:"\u5de5\u5177\u94fe\u7684\u5e94\u7528\u548c\u9ad8\u7ea7\u6280\u672f",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES104-NOTES-14/"}},{id:"post-games104\u8bfe\u7a0b\u7b14\u8bb013-foundation-of-tool-chains",title:"GAMES104\u8bfe\u7a0b\u7b14\u8bb013-Foundation of Tool Chains",description:"\u6e38\u620f\u5f15\u64ce\u4e2d\u7684\u5de5\u5177\u94fe",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES104-NOTES-13/"}},{id:"post-omscs-rl\u8bfe\u7a0b\u7b14\u8bb011-game-theory",title:"OMSCS-RL\u8bfe\u7a0b\u7b14\u8bb011-Game Theory",description:"\u535a\u5f08\u8bba\u57fa\u7840I",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-RL-NOTES-11/"}},{id:"post-omscs-rl\u8bfe\u7a0b\u7b14\u8bb010-generalizing-generalizing",title:"OMSCS-RL\u8bfe\u7a0b\u7b14\u8bb010-Generalizing Generalizing",description:"\u5f3a\u5316\u5b66\u4e60\u7684\u4e00\u4e9b\u96be\u70b9\u548c\u76f8\u5173\u7684\u5904\u7406\u65b9\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-RL-NOTES-10/"}},{id:"post-omscs-rl\u8bfe\u7a0b\u7b14\u8bb009-partially-observable-mdps",title:"OMSCS-RL\u8bfe\u7a0b\u7b14\u8bb009-Partially Observable MDPs",description:"\u90e8\u5206\u53ef\u89c2\u5bdfMDP",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-RL-NOTES-09/"}},{id:"post-omscs-rl\u8bfe\u7a0b\u7b14\u8bb008-generalization",title:"OMSCS-RL\u8bfe\u7a0b\u7b14\u8bb008-Generalization",description:"\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6cdb\u5316\u95ee\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-RL-NOTES-08/"}},{id:"post-games104\u8bfe\u7a0b\u7b14\u8bb012-effects",title:"GAMES104\u8bfe\u7a0b\u7b14\u8bb012-Effects",description:"\u7c92\u5b50\u548c\u58f0\u6548\u7cfb\u7edf",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES104-NOTES-12/"}},{id:"post-omscs-rl\u8bfe\u7a0b\u7b14\u8bb007-exploring-exploration",title:"OMSCS-RL\u8bfe\u7a0b\u7b14\u8bb007-Exploring Exploration",description:"\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u63a2\u7d22\u95ee\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-RL-NOTES-07/"}},{id:"post-omscs-rl\u8bfe\u7a0b\u7b14\u8bb006-messing-with-rewards",title:"OMSCS-RL\u8bfe\u7a0b\u7b14\u8bb006-Messing with Rewards",description:"\u5956\u52b1\u51fd\u6570",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-RL-NOTES-06/"}},{id:"post-omscs-rl\u8bfe\u7a0b\u7b14\u8bb005-aaa",title:"OMSCS-RL\u8bfe\u7a0b\u7b14\u8bb005-AAA",description:"\u5176\u5b83\u7c7b\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-RL-NOTES-05/"}},{id:"post-games104\u8bfe\u7a0b\u7b14\u8bb011-applications-in-physics-system",title:"GAMES104\u8bfe\u7a0b\u7b14\u8bb011-Applications in Physics System",description:"\u7269\u7406\u7cfb\u7edf\u5e94\u7528",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES104-NOTES-11/"}},{id:"post-omscs-rl\u8bfe\u7a0b\u7b14\u8bb004-convergence",title:"OMSCS-RL\u8bfe\u7a0b\u7b14\u8bb004-Convergence",description:"TD learning\u7b97\u6cd5\u7684\u6536\u655b\u6027",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-RL-NOTES-04/"}},{id:"post-omscs-rl\u8bfe\u7a0b\u7b14\u8bb003-td-and-friends",title:"OMSCS-RL\u8bfe\u7a0b\u7b14\u8bb003-TD and Friends",description:"TD learning\u7b97\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-RL-NOTES-03/"}},{id:"post-games104\u8bfe\u7a0b\u7b14\u8bb010-basics-concepts-in-physics-system",title:"GAMES104\u8bfe\u7a0b\u7b14\u8bb010-Basics Concepts in Physics System",description:"\u6e38\u620f\u5f15\u64ce\u4e2d\u7684\u7269\u7406\u7cfb\u7edf",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES104-NOTES-10/"}},{id:"post-omscs-rl\u8bfe\u7a0b\u7b14\u8bb002-reinforcement-learning-basics",title:"OMSCS-RL\u8bfe\u7a0b\u7b14\u8bb002-Reinforcement Learning Basics",description:"\u5f3a\u5316\u5b66\u4e60\u57fa\u7840II",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-RL-NOTES-02/"}},{id:"post-omscs-rl\u8bfe\u7a0b\u7b14\u8bb001-introduction",title:"OMSCS-RL\u8bfe\u7a0b\u7b14\u8bb001-Introduction",description:"\u5f3a\u5316\u5b66\u4e60\u57fa\u7840I",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-RL-NOTES-01/"}},{id:"post-games104\u8bfe\u7a0b\u7b14\u8bb009-advanced-animation-technology",title:"GAMES104\u8bfe\u7a0b\u7b14\u8bb009-Advanced Animation Technology",description:"\u52a8\u753b\u7cfb\u7edf\u524d\u6cbf",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES104-NOTES-09/"}},{id:"post-games104\u8bfe\u7a0b\u7b14\u8bb008-basics-of-animation-technology",title:"GAMES104\u8bfe\u7a0b\u7b14\u8bb008-Basics of Animation Technology",description:"\u73b0\u4ee3\u6e38\u620f\u5f15\u64ce\u4e2d\u7684\u52a8\u753b\u7cfb\u7edf",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES104-NOTES-08/"}},{id:"post-games104\u8bfe\u7a0b\u7b14\u8bb007-render-pipeline-post-process-and-everything",title:"GAMES104\u8bfe\u7a0b\u7b14\u8bb007-Render Pipeline, Post-process and Everything",description:"\u73b0\u4ee3\u6e38\u620f\u5f15\u64ce\u4e2d\u7684\u6e32\u67d3\u7ba1\u7ebf\u4ee5\u53ca\u5176\u5b83\u5e38\u7528\u7684\u6280\u672f",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES104-NOTES-07/"}},{id:"post-games104\u8bfe\u7a0b\u7b14\u8bb006-the-challenges-and-fun-of-rendering-the-beautiful-mother-nature",title:"GAMES104\u8bfe\u7a0b\u7b14\u8bb006-The Challenges and Fun of Rendering the Beautiful Mother Nature",description:"\u5730\u5f62\u548c\u5927\u6c14\u6e32\u67d3\u6280\u672f",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES104-NOTES-06/"}},{id:"post-games104\u8bfe\u7a0b\u7b14\u8bb005-lighting-materials-and-shaders",title:"GAMES104\u8bfe\u7a0b\u7b14\u8bb005-Lighting, Materials and Shaders",description:"\u73b0\u4ee3\u6e38\u620f\u5f15\u64ce\u7684\u5b9e\u65f6\u6e32\u67d3\u7b97\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES104-NOTES-05/"}},{id:"post-omscs-sim\u8bfe\u7a0b\u7b14\u8bb010-comparing-systems",title:"OMSCS-SIM\u8bfe\u7a0b\u7b14\u8bb010-Comparing Systems",description:"\u7cfb\u7edf\u8bc4\u4ef7",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-SIM-NOTES-10/"}},{id:"post-omscs-dl\u8bfe\u7a0b\u7b14\u8bb019-generative-models",title:"OMSCS-DL\u8bfe\u7a0b\u7b14\u8bb019-Generative Models",description:"\u751f\u6210\u5f0f\u6a21\u578b",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-DL-NOTES-19/"}},{id:"post-games104\u8bfe\u7a0b\u7b14\u8bb004-rendering-on-game-engine",title:"GAMES104\u8bfe\u7a0b\u7b14\u8bb004-Rendering on Game Engine",description:"\u73b0\u4ee3\u6e38\u620f\u5f15\u64ce\u7684\u6e32\u67d3\u7cfb\u7edf",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES104-NOTES-04/"}},{id:"post-omscs-sim\u8bfe\u7a0b\u7b14\u8bb009-output-analysis",title:"OMSCS-SIM\u8bfe\u7a0b\u7b14\u8bb009-Output Analysis",description:"\u8f93\u51fa\u5206\u6790",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-SIM-NOTES-09/"}},{id:"post-omscs-dl\u8bfe\u7a0b\u7b14\u8bb018-unsupervised-and-semi-supervised-learning",title:"OMSCS-DL\u8bfe\u7a0b\u7b14\u8bb018-Unsupervised and Semi-Supervised Learning",description:"\u65e0\u76d1\u7763\u5b66\u4e60\u548c\u534a\u76d1\u7763\u5b66\u4e60",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-DL-NOTES-18/"}},{id:"post-games104\u8bfe\u7a0b\u7b14\u8bb003-how-to-build-a-game-world",title:"GAMES104\u8bfe\u7a0b\u7b14\u8bb003-How to Build a Game World",description:"\u73b0\u4ee3\u6e38\u620f\u5f15\u64ce\u7684\u5bf9\u8c61\u8bbe\u8ba1\u548c\u7ba1\u7406\u65b9\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES104-NOTES-03/"}},{id:"post-omscs-sim\u8bfe\u7a0b\u7b14\u8bb008-input-analysis",title:"OMSCS-SIM\u8bfe\u7a0b\u7b14\u8bb008-Input Analysis",description:"\u8f93\u5165\u5206\u6790",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-SIM-NOTES-08/"}},{id:"post-omscs-dl\u8bfe\u7a0b\u7b14\u8bb017-deep-reinforcement-learning",title:"OMSCS-DL\u8bfe\u7a0b\u7b14\u8bb017-Deep Reinforcement Learning",description:"\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-DL-NOTES-17/"}},{id:"post-games104\u8bfe\u7a0b\u7b14\u8bb002-layered-architecture-of-game-engine",title:"GAMES104\u8bfe\u7a0b\u7b14\u8bb002-Layered Architecture of Game Engine",description:"\u73b0\u4ee3\u6e38\u620f\u5f15\u64ce\u7684\u5206\u5c42\u67b6\u6784",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES104-NOTES-02/"}},{id:"post-omscs-dl\u8bfe\u7a0b\u7b14\u8bb016-translation-at-facebook-and-automated-speech-recognition-asr",title:"OMSCS-DL\u8bfe\u7a0b\u7b14\u8bb016-Translation at Facebook and Automated Speech Recognition (ASR)",description:"\u673a\u5668\u7ffb\u8bd1\u548c\u8bed\u97f3\u8bc6\u522b",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-DL-NOTES-16/"}},{id:"post-omscs-dl\u8bfe\u7a0b\u7b14\u8bb015-neural-machine-translation",title:"OMSCS-DL\u8bfe\u7a0b\u7b14\u8bb015-Neural Machine Translation",description:"\u6df1\u5ea6\u5b66\u4e60\u4e0e\u673a\u5668\u7ffb\u8bd1",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-DL-NOTES-15/"}},{id:"post-games104\u8bfe\u7a0b\u7b14\u8bb001-overview-of-game-engine",title:"GAMES104\u8bfe\u7a0b\u7b14\u8bb001-Overview of Game Engine",description:"\u73b0\u4ee3\u6e38\u620f\u5f15\u64ce\u7684\u57fa\u672c\u6982\u5ff5",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES104-NOTES-01/"}},{id:"post-omscs-dl\u8bfe\u7a0b\u7b14\u8bb014-neural-attention-models",title:"OMSCS-DL\u8bfe\u7a0b\u7b14\u8bb014-Neural Attention Models",description:"\u6ce8\u610f\u529b\u6a21\u578b",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-DL-NOTES-14/"}},{id:"post-omscs-sim\u8bfe\u7a0b\u7b14\u8bb007-random-variate-generation",title:"OMSCS-SIM\u8bfe\u7a0b\u7b14\u8bb007-Random Variate Generation",description:"\u5e38\u7528\u7684\u968f\u673a\u53d8\u91cf\u751f\u6210\u65b9\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-SIM-NOTES-07/"}},{id:"post-omscs-dl\u8bfe\u7a0b\u7b14\u8bb013-embeddings",title:"OMSCS-DL\u8bfe\u7a0b\u7b14\u8bb013-Embeddings",description:"\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u5d4c\u5165",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-DL-NOTES-13/"}},{id:"post-omscs-sim\u8bfe\u7a0b\u7b14\u8bb006-random-number-generation",title:"OMSCS-SIM\u8bfe\u7a0b\u7b14\u8bb006-Random Number Generation",description:"\u5747\u5300\u5206\u5e03\u968f\u673a\u6570\u7684\u751f\u6210\u65b9\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-SIM-NOTES-06/"}},{id:"post-omscs-dl\u8bfe\u7a0b\u7b14\u8bb012-language-models",title:"OMSCS-DL\u8bfe\u7a0b\u7b14\u8bb012-Language Models",description:"\u8bed\u8a00\u6a21\u578b",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-DL-NOTES-12/"}},{id:"post-omscs-dl\u8bfe\u7a0b\u7b14\u8bb011-introduction-to-structured-representations",title:"OMSCS-DL\u8bfe\u7a0b\u7b14\u8bb011-Introduction to Structured Representations",description:"\u6df1\u5ea6\u5b66\u4e60\u7684\u7ed3\u6784\u5316\u8868\u793a",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-DL-NOTES-11/"}},{id:"post-omscs-dl\u8bfe\u7a0b\u7b14\u8bb010-bias-and-fairness",title:"OMSCS-DL\u8bfe\u7a0b\u7b14\u8bb010-Bias and Fairness",description:"\u6df1\u5ea6\u5b66\u4e60\u7684\u516c\u5e73\u6027",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-DL-NOTES-10/"}},{id:"post-omscs-dl\u8bfe\u7a0b\u7b14\u8bb009-advanced-computer-vision-architectures",title:"OMSCS-DL\u8bfe\u7a0b\u7b14\u8bb009-Advanced Computer Vision Architectures",description:"\u56fe\u50cf\u5206\u5272\u4e0e\u76ee\u6807\u68c0\u6d4b",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-DL-NOTES-09/"}},{id:"post-omscs-sim\u8bfe\u7a0b\u7b14\u8bb005-arena",title:"OMSCS-SIM\u8bfe\u7a0b\u7b14\u8bb005-Arena",description:"Arena\u8f6f\u4ef6\u7684\u4f7f\u7528",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-SIM-NOTES-05/"}},{id:"post-omscs-dl\u8bfe\u7a0b\u7b14\u8bb008-scalable-training",title:"OMSCS-DL\u8bfe\u7a0b\u7b14\u8bb008-Scalable Training",description:"PyTorch\u7684\u53ef\u62d3\u5c55\u6027",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-DL-NOTES-08/"}},{id:"post-omscs-dl\u8bfe\u7a0b\u7b14\u8bb007-visualization",title:"OMSCS-DL\u8bfe\u7a0b\u7b14\u8bb007-Visualization",description:"\u795e\u7ecf\u7f51\u7edc\u53ef\u89c6\u5316",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-DL-NOTES-07/"}},{id:"post-omscs-sim\u8bfe\u7a0b\u7b14\u8bb004-general-simulation-principles",title:"OMSCS-SIM\u8bfe\u7a0b\u7b14\u8bb004-General Simulation Principles",description:"\u968f\u673a\u6a21\u62df\u7684\u57fa\u672c\u539f\u5219",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-SIM-NOTES-04/"}},{id:"post-omscs-dl\u8bfe\u7a0b\u7b14\u8bb006-convolutional-neural-network-architectures",title:"OMSCS-DL\u8bfe\u7a0b\u7b14\u8bb006-Convolutional Neural Network Architectures",description:"\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u7ed3\u6784",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-DL-NOTES-06/"}},{id:"post-\u6df1\u84dd\u5b66\u9662-gnn\u8bfe\u7a0b\u7b14\u8bb013-\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u9ad8\u7ea7\u5e94\u7528",title:"\u6df1\u84dd\u5b66\u9662-GNN\u8bfe\u7a0b\u7b14\u8bb013-\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u9ad8\u7ea7\u5e94\u7528",description:"\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u9ad8\u7ea7\u5e94\u7528",section:"Posts",handler:()=>{window.location.href="/blog/2022/GNN-NOTES-13/"}},{id:"post-omscs-sim\u8bfe\u7a0b\u7b14\u8bb003-hand-and-spreadsheet-simulations",title:"OMSCS-SIM\u8bfe\u7a0b\u7b14\u8bb003-Hand and Spreadsheet Simulations",description:"\u968f\u673a\u6a21\u62df\u7684\u57fa\u672c\u65b9\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-SIM-NOTES-03/"}},{id:"post-a-post-with-redirect",title:"a post with redirect",description:"you can also redirect to assets like pdf",section:"Posts",handler:()=>{window.location.href="/assets/pdf/example_pdf.pdf"}},{id:"post-omscs-dl\u8bfe\u7a0b\u7b14\u8bb005-convolution-and-pooling-layers",title:"OMSCS-DL\u8bfe\u7a0b\u7b14\u8bb005-Convolution and Pooling Layers",description:"\u5377\u79ef\u795e\u7ecf\u7f51\u7edc",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-DL-NOTES-05/"}},{id:"post-omscs-dl\u8bfe\u7a0b\u7b14\u8bb004-data-wrangling",title:"OMSCS-DL\u8bfe\u7a0b\u7b14\u8bb004-Data Wrangling",description:"\u6570\u636e\u9884\u5904\u7406",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-DL-NOTES-04/"}},{id:"post-\u6df1\u84dd\u5b66\u9662-gnn\u8bfe\u7a0b\u7b14\u8bb012-\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u9ad8\u7ea7\u65b9\u6cd5",title:"\u6df1\u84dd\u5b66\u9662-GNN\u8bfe\u7a0b\u7b14\u8bb012-\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u9ad8\u7ea7\u65b9\u6cd5",description:"\u73b0\u4ee3\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u7814\u7a76\u70ed\u70b9",section:"Posts",handler:()=>{window.location.href="/blog/2022/GNN-NOTES-12/"}},{id:"post-omscs-dl\u8bfe\u7a0b\u7b14\u8bb003-optimization-of-deep-neural-networks",title:"OMSCS-DL\u8bfe\u7a0b\u7b14\u8bb003-Optimization of Deep Neural Networks",description:"\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u4f18\u5316\u7b97\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-DL-NOTES-03/"}},{id:"post-\u6df1\u84dd\u5b66\u9662-gnn\u8bfe\u7a0b\u7b14\u8bb011-\u751f\u7269\u5316\u5b66\u548c\u533b\u7597\u5065\u5eb7\u4e2d\u7684\u56fe\u795e\u7ecf\u7f51\u7edc",title:"\u6df1\u84dd\u5b66\u9662-GNN\u8bfe\u7a0b\u7b14\u8bb011-\u751f\u7269\u5316\u5b66\u548c\u533b\u7597\u5065\u5eb7\u4e2d\u7684\u56fe\u795e\u7ecf\u7f51\u7edc",description:"\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u751f\u7269\u5316\u5b66\u4e2d\u7684\u5e94\u7528",section:"Posts",handler:()=>{window.location.href="/blog/2022/GNN-NOTES-11/"}},{id:"post-omscs-sim\u8bfe\u7a0b\u7b14\u8bb002-calculus-probability-and-statistics-primers",title:"OMSCS-SIM\u8bfe\u7a0b\u7b14\u8bb002-Calculus, Probability, and Statistics Primers",description:"\u5fae\u79ef\u5206\u4e0e\u6982\u7387\u8bba\u57fa\u7840",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-SIM-NOTES-02/"}},{id:"post-omscs-dl\u8bfe\u7a0b\u7b14\u8bb002-neural-networks",title:"OMSCS-DL\u8bfe\u7a0b\u7b14\u8bb002-Neural Networks",description:"\u795e\u7ecf\u7f51\u7edc\u57fa\u7840",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-DL-NOTES-02/"}},{id:"post-games103\u8bfe\u7a0b\u7b14\u8bb012-smoothed-particle-hydrodynamics",title:"GAMES103\u8bfe\u7a0b\u7b14\u8bb012-Smoothed Particle Hydrodynamics",description:"SPH\u4e0e\u6d41\u4f53\u4eff\u771f",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES103-NOTES-12/"}},{id:"post-omscs-sim\u8bfe\u7a0b\u7b14\u8bb001-whirlwind-tour-of-simulation",title:"OMSCS-SIM\u8bfe\u7a0b\u7b14\u8bb001-Whirlwind Tour of Simulation",description:"\u8ba1\u7b97\u673a\u6a21\u62df\u57fa\u7840",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-SIM-NOTES-01/"}},{id:"post-omscs-dl\u8bfe\u7a0b\u7b14\u8bb001-linear-classifiers-and-gradient-descent",title:"OMSCS-DL\u8bfe\u7a0b\u7b14\u8bb001-Linear Classifiers and Gradient Descent",description:"\u7ebf\u6027\u5206\u7c7b\u5668\u4e0e\u68af\u5ea6\u4e0b\u964d\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2022/OMSCS-DL-NOTES-01/"}},{id:"post-games103\u8bfe\u7a0b\u7b14\u8bb011-eulerian-fluids",title:"GAMES103\u8bfe\u7a0b\u7b14\u8bb011-Eulerian Fluids",description:"\u4e0d\u53ef\u538b\u7f29\u6d41\u4f53\u4e0eNS\u65b9\u7a0b",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES103-NOTES-11/"}},{id:"post-\u6df1\u84dd\u5b66\u9662-gnn\u8bfe\u7a0b\u7b14\u8bb010-\u6570\u636e\u6316\u6398\u4e2d\u7684\u56fe\u795e\u7ecf\u7f51\u7edc",title:"\u6df1\u84dd\u5b66\u9662-GNN\u8bfe\u7a0b\u7b14\u8bb010-\u6570\u636e\u6316\u6398\u4e2d\u7684\u56fe\u795e\u7ecf\u7f51\u7edc",description:"\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u6570\u636e\u6316\u6398\u4e2d\u7684\u5e94\u7528",section:"Posts",handler:()=>{window.location.href="/blog/2022/GNN-NOTES-10/"}},{id:"post-games103\u8bfe\u7a0b\u7b14\u8bb010-surface-waves",title:"GAMES103\u8bfe\u7a0b\u7b14\u8bb010-Surface Waves",description:"\u6c34\u6ce2\u6a21\u62df",section:"Posts",handler:()=>{window.location.href="/blog/2022/GAMES103-NOTES-10/"}},{id:"post-games103\u8bfe\u7a0b\u7b14\u8bb009-collision-handling",title:"GAMES103\u8bfe\u7a0b\u7b14\u8bb009-Collision Handling",description:"\u7269\u7406\u4eff\u771f\u4e2d\u7684\u78b0\u649e\u68c0\u6d4b\u548c\u5904\u7406",section:"Posts",handler:()=>{window.location.href="/blog/2021/GAMES103-NOTES-09/"}},{id:"post-\u6df1\u84dd\u5b66\u9662-gnn\u8bfe\u7a0b\u7b14\u8bb009-\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u7684\u56fe\u795e\u7ecf\u7f51\u7edc",title:"\u6df1\u84dd\u5b66\u9662-GNN\u8bfe\u7a0b\u7b14\u8bb009-\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u7684\u56fe\u795e\u7ecf\u7f51\u7edc",description:"\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u7684\u5e94\u7528",section:"Posts",handler:()=>{window.location.href="/blog/2021/GNN-NOTES-09/"}},{id:"post-games103\u8bfe\u7a0b\u7b14\u8bb008-finite-element-method-ii",title:"GAMES103\u8bfe\u7a0b\u7b14\u8bb008-Finite Element Method II",description:"\u5f39\u6027\u4f53\u4eff\u771f\u4e0e\u6709\u9650\u5355\u5143\u6cd5II",section:"Posts",handler:()=>{window.location.href="/blog/2021/GAMES103-NOTES-08/"}},{id:"post-games103\u8bfe\u7a0b\u7b14\u8bb007-finite-element-method-i",title:"GAMES103\u8bfe\u7a0b\u7b14\u8bb007-Finite Element Method I",description:"\u5f39\u6027\u4f53\u4eff\u771f\u4e0e\u6709\u9650\u5355\u5143\u6cd5I",section:"Posts",handler:()=>{window.location.href="/blog/2021/GAMES103-NOTES-07/"}},{id:"post-\u6df1\u84dd\u5b66\u9662-gnn\u8bfe\u7a0b\u7b14\u8bb008-\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u7684\u56fe\u795e\u7ecf\u7f51\u7edc",title:"\u6df1\u84dd\u5b66\u9662-GNN\u8bfe\u7a0b\u7b14\u8bb008-\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u7684\u56fe\u795e\u7ecf\u7f51\u7edc",description:"\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u7684\u5e94\u7528",section:"Posts",handler:()=>{window.location.href="/blog/2021/GNN-NOTES-08/"}},{id:"post-games103\u8bfe\u7a0b\u7b14\u8bb006-constraint-approaches",title:"GAMES103\u8bfe\u7a0b\u7b14\u8bb006-Constraint Approaches",description:"\u5e03\u6599\u4eff\u771f\u4e2d\u7684\u7ea6\u675f\u65b9\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2021/GAMES103-NOTES-06/"}},{id:"post-games103\u8bfe\u7a0b\u7b14\u8bb005-physics-based-cloth-simulation",title:"GAMES103\u8bfe\u7a0b\u7b14\u8bb005-Physics-Based Cloth Simulation",description:"\u5e03\u6599\u4eff\u771f",section:"Posts",handler:()=>{window.location.href="/blog/2021/GAMES103-NOTES-05/"}},{id:"post-omscs-cv\u8bfe\u7a0b\u7b14\u8bb017-3d-perception",title:"OMSCS-CV\u8bfe\u7a0b\u7b14\u8bb017-3D Perception",description:"\u4e09\u7ef4\u611f\u77e5",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-CV-NOTES-17/"}},{id:"post-omscs-cv\u8bfe\u7a0b\u7b14\u8bb016-binary-morphology",title:"OMSCS-CV\u8bfe\u7a0b\u7b14\u8bb016-Binary Morphology",description:"\u6570\u5b66\u5f62\u6001\u5b66",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-CV-NOTES-16/"}},{id:"post-\u6df1\u84dd\u5b66\u9662-gnn\u8bfe\u7a0b\u7b14\u8bb007-\u56fe\u4e0a\u7684\u5176\u4ed6\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b",title:"\u6df1\u84dd\u5b66\u9662-GNN\u8bfe\u7a0b\u7b14\u8bb007-\u56fe\u4e0a\u7684\u5176\u4ed6\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b",description:"\u56fe\u795e\u7ecf\u7f51\u7edc\u4e4b\u5916\u7684\u5176\u5b83\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b",section:"Posts",handler:()=>{window.location.href="/blog/2021/GNN-NOTES-07/"}},{id:"post-games103\u8bfe\u7a0b\u7b14\u8bb004-rigid-body-contacts",title:"GAMES103\u8bfe\u7a0b\u7b14\u8bb004-Rigid Body Contacts",description:"\u521a\u4f53\u78b0\u649e\u4e0e\u63a5\u89e6",section:"Posts",handler:()=>{window.location.href="/blog/2021/GAMES103-NOTES-04/"}},{id:"post-omscs-cv\u8bfe\u7a0b\u7b14\u8bb015-color-spaces-and-segmentation",title:"OMSCS-CV\u8bfe\u7a0b\u7b14\u8bb015-Color Spaces and Segmentation",description:"\u989c\u8272\u7a7a\u95f4\u4e0e\u56fe\u50cf\u5206\u5272",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-CV-NOTES-15/"}},{id:"post-\u6df1\u84dd\u5b66\u9662-gnn\u8bfe\u7a0b\u7b14\u8bb006-\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u53ef\u6269\u5c55\u6027",title:"\u6df1\u84dd\u5b66\u9662-GNN\u8bfe\u7a0b\u7b14\u8bb006-\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u53ef\u6269\u5c55\u6027",description:"\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u53ef\u6269\u5c55\u6027",section:"Posts",handler:()=>{window.location.href="/blog/2021/GNN-NOTES-06/"}},{id:"post-games103\u8bfe\u7a0b\u7b14\u8bb003-rigid-body-dynamics",title:"GAMES103\u8bfe\u7a0b\u7b14\u8bb003-Rigid Body Dynamics",description:"\u521a\u4f53\u52a8\u529b\u5b66",section:"Posts",handler:()=>{window.location.href="/blog/2021/GAMES103-NOTES-03/"}},{id:"post-omscs-cv\u8bfe\u7a0b\u7b14\u8bb014-action-recognition",title:"OMSCS-CV\u8bfe\u7a0b\u7b14\u8bb014-Action Recognition",description:"\u89c6\u9891\u5206\u6790\u548c\u52a8\u4f5c\u8bc6\u522b",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-CV-NOTES-14/"}},{id:"post-games103\u8bfe\u7a0b\u7b14\u8bb002-math-background",title:"GAMES103\u8bfe\u7a0b\u7b14\u8bb002-Math Background",description:"\u6570\u5b66\u57fa\u7840",section:"Posts",handler:()=>{window.location.href="/blog/2021/GAMES103-NOTES-02/"}},{id:"post-omscs-cv\u8bfe\u7a0b\u7b14\u8bb013-discriminative-models",title:"OMSCS-CV\u8bfe\u7a0b\u7b14\u8bb013-Discriminative Models",description:"\u5224\u522b\u5f0f\u6a21\u578b",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-CV-NOTES-13/"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb015-game-theory",title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb015-Game Theory",description:"\u535a\u5f08\u8bba",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-15/"}},{id:"post-\u6df1\u84dd\u5b66\u9662-gnn\u8bfe\u7a0b\u7b14\u8bb005-\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u9c81\u68d2\u6027",title:"\u6df1\u84dd\u5b66\u9662-GNN\u8bfe\u7a0b\u7b14\u8bb005-\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u9c81\u68d2\u6027",description:"\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u5bf9\u6297\u653b\u51fb\u548c\u9632\u5fa1",section:"Posts",handler:()=>{window.location.href="/blog/2021/GNN-NOTES-05/"}},{id:"post-omscs-cv\u8bfe\u7a0b\u7b14\u8bb012-generative-models",title:"OMSCS-CV\u8bfe\u7a0b\u7b14\u8bb012-Generative Models",description:"\u56fe\u50cf\u8bc6\u522b\u548c\u751f\u6210\u5f0f\u6a21\u578b",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-CV-NOTES-12/"}},{id:"post-games103\u8bfe\u7a0b\u7b14\u8bb001-introduction",title:"GAMES103\u8bfe\u7a0b\u7b14\u8bb001-Introduction",description:"\u7269\u7406\u4eff\u771f\u6982\u8ff0",section:"Posts",handler:()=>{window.location.href="/blog/2021/GAMES103-NOTES-01/"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb014-reinforcement-learning",title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb014-Reinforcement Learning",description:"\u5f3a\u5316\u5b66\u4e60",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-14/"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb013-markov-decision-processes",title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb013-Markov Decision Processes",description:"Markov\u51b3\u7b56\u8fc7\u7a0b",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-13/"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb012-feature-selection-and-transform",title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb012-Feature Selection and Transform",description:"\u7279\u5f81\u9009\u62e9",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-12/"}},{id:"post-omscs-cv\u8bfe\u7a0b\u7b14\u8bb011-tracking",title:"OMSCS-CV\u8bfe\u7a0b\u7b14\u8bb011-Tracking",description:"\u76ee\u6807\u8ddf\u8e2a",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-CV-NOTES-11/"}},{id:"post-omscs-cv\u8bfe\u7a0b\u7b14\u8bb010-motion-detection",title:"OMSCS-CV\u8bfe\u7a0b\u7b14\u8bb010-Motion Detection",description:"\u8fd0\u52a8\u4f30\u8ba1\u4e0e\u5149\u6d41",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-CV-NOTES-10/"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb011-clustering",title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb011-Clustering",description:"\u805a\u7c7b\u7b97\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-11/"}},{id:"post-\u6df1\u84dd\u5b66\u9662-gnn\u8bfe\u7a0b\u7b14\u8bb004-\u56fe\u795e\u7ecf\u7f51\u7edc",title:"\u6df1\u84dd\u5b66\u9662-GNN\u8bfe\u7a0b\u7b14\u8bb004-\u56fe\u795e\u7ecf\u7f51\u7edc",description:"\u56fe\u795e\u7ecf\u7f51\u7edc",section:"Posts",handler:()=>{window.location.href="/blog/2021/GNN-NOTES-04/"}},{id:"post-omscs-cv\u8bfe\u7a0b\u7b14\u8bb009-lightness-and-brightness",title:"OMSCS-CV\u8bfe\u7a0b\u7b14\u8bb009-Lightness and Brightness",description:"\u5149\u7167\u548c\u7740\u8272",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-CV-NOTES-09/"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb010-randomized-optimization",title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb010-Randomized Optimization",description:"\u968f\u673a\u4f18\u5316",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-10/"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb009-information-theory",title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb009-Information Theory",description:"\u4fe1\u606f\u8bba",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-09/"}},{id:"post-omscs-cv\u8bfe\u7a0b\u7b14\u8bb008-feature-and-matching",title:"OMSCS-CV\u8bfe\u7a0b\u7b14\u8bb008-Feature and Matching",description:"\u56fe\u50cf\u7279\u5f81\u4e0e\u5339\u914d",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-CV-NOTES-08/"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb008-bayesian-learning-and-inference",title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb008-Bayesian Learning and Inference",description:"\u8d1d\u53f6\u65af\u5b66\u4e60",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-08/"}},{id:"post-\u6df1\u84dd\u5b66\u9662-gnn\u8bfe\u7a0b\u7b14\u8bb003-\u56fe\u5d4c\u5165",title:"\u6df1\u84dd\u5b66\u9662-GNN\u8bfe\u7a0b\u7b14\u8bb003-\u56fe\u5d4c\u5165",description:"\u56fe\u5d4c\u5165",section:"Posts",handler:()=>{window.location.href="/blog/2021/GNN-NOTES-03/"}},{id:"post-omscs-cv\u8bfe\u7a0b\u7b14\u8bb007-multiple-views",title:"OMSCS-CV\u8bfe\u7a0b\u7b14\u8bb007-Multiple Views",description:"\u591a\u89c6\u56fe\u51e0\u4f55",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-CV-NOTES-07/"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb007-computational-learning-theory",title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb007-Computational Learning Theory",description:"\u8ba1\u7b97\u5b66\u4e60\u7406\u8bba",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-07/"}},{id:"post-omscs-cv\u8bfe\u7a0b\u7b14\u8bb006-camera-calibration",title:"OMSCS-CV\u8bfe\u7a0b\u7b14\u8bb006-Camera Calibration",description:"\u76f8\u673a\u6807\u5b9a",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-CV-NOTES-06/"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb006-svm-and-kernel-methods",title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb006-SVM and Kernel Methods",description:"\u652f\u6301\u5411\u91cf\u673a",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-06/"}},{id:"post-\u6df1\u84dd\u5b66\u9662-gnn\u8bfe\u7a0b\u7b14\u8bb002-\u6df1\u5ea6\u5b66\u4e60\u57fa\u7840",title:"\u6df1\u84dd\u5b66\u9662-GNN\u8bfe\u7a0b\u7b14\u8bb002-\u6df1\u5ea6\u5b66\u4e60\u57fa\u7840",description:"\u6df1\u5ea6\u5b66\u4e60\u57fa\u7840",section:"Posts",handler:()=>{window.location.href="/blog/2021/GNN-NOTES-02/"}},{id:"post-omscs-cv\u8bfe\u7a0b\u7b14\u8bb005-stereo-geometry",title:"OMSCS-CV\u8bfe\u7a0b\u7b14\u8bb005-Stereo Geometry",description:"\u7acb\u4f53\u89c6\u89c9",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-CV-NOTES-05/"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb005-ensemble-learning",title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb005-Ensemble Learning",description:"\u96c6\u6210\u5b66\u4e60",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-05/"}},{id:"post-omscs-cv\u8bfe\u7a0b\u7b14\u8bb004-camera-models",title:"OMSCS-CV\u8bfe\u7a0b\u7b14\u8bb004-Camera Models",description:"\u76f8\u673a\u6a21\u578b",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-CV-NOTES-04/"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb004-instance-based-learning",title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb004-Instance Based Learning",description:"\u5b9e\u4f8b\u5b66\u4e60",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-04/"}},{id:"post-\u6df1\u84dd\u5b66\u9662-gnn\u8bfe\u7a0b\u7b14\u8bb001-\u56fe\u8bba\u57fa\u7840",title:"\u6df1\u84dd\u5b66\u9662-GNN\u8bfe\u7a0b\u7b14\u8bb001-\u56fe\u8bba\u57fa\u7840",description:"\u56fe\u8bba\u57fa\u7840",section:"Posts",handler:()=>{window.location.href="/blog/2021/GNN-NOTES-01/"}},{id:"post-omscs-cv\u8bfe\u7a0b\u7b14\u8bb003-frequency-domain-analysis",title:"OMSCS-CV\u8bfe\u7a0b\u7b14\u8bb003-Frequency Domain Analysis",description:"\u9891\u57df\u5206\u6790",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-CV-NOTES-03/"}},{id:"post-omscs-cv\u8bfe\u7a0b\u7b14\u8bb002-hough-transform",title:"OMSCS-CV\u8bfe\u7a0b\u7b14\u8bb002-Hough Transform",description:"\u970d\u592b\u53d8\u6362",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-CV-NOTES-02/"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb003-neural-networks",title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb003-Neural Networks",description:"\u795e\u7ecf\u7f51\u7edc",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-03/"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb002-regression",
title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb002-Regression",description:"\u56de\u5f52\u95ee\u9898",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-02/"}},{id:"post-omscs-cv\u8bfe\u7a0b\u7b14\u8bb001-linear-image-processing",title:"OMSCS-CV\u8bfe\u7a0b\u7b14\u8bb001-Linear Image Processing",description:"\u56fe\u50cf\u5904\u7406\u57fa\u7840",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-CV-NOTES-01/"}},{id:"post-omscs-ml\u8bfe\u7a0b\u7b14\u8bb001-decision-trees",title:"OMSCS-ML\u8bfe\u7a0b\u7b14\u8bb001-Decision Trees",description:"\u51b3\u7b56\u6811",section:"Posts",handler:()=>{window.location.href="/blog/2021/OMSCS-ML-NOTES-01/"}},{id:"post-ddg\u8bfe\u7a0b\u7b14\u8bb05-\u6d4b\u5730\u7ebf",title:"DDG\u8bfe\u7a0b\u7b14\u8bb05-\u6d4b\u5730\u7ebf",description:"\u6d4b\u5730\u7ebf\u4e0e\u6d4b\u5730\u8ddd\u79bb",section:"Posts",handler:()=>{window.location.href="/blog/2021/DDG-NOTES-5/"}},{id:"post-ddg\u8bfe\u7a0b\u7b14\u8bb04-\u66f2\u9762\u53c2\u6570\u5316",title:"DDG\u8bfe\u7a0b\u7b14\u8bb04-\u66f2\u9762\u53c2\u6570\u5316",description:"\u66f2\u9762\u53c2\u6570\u5316",section:"Posts",handler:()=>{window.location.href="/blog/2021/DDG-NOTES-4/"}},{id:"post-ddg\u8bfe\u7a0b\u7b14\u8bb03-laplace\u7b97\u5b50",title:"DDG\u8bfe\u7a0b\u7b14\u8bb03-Laplace\u7b97\u5b50",description:"\u66f2\u9762\u4e0a\u7684Laplace\u7b97\u5b50",section:"Posts",handler:()=>{window.location.href="/blog/2021/DDG-NOTES-3/"}},{id:"post-ddg\u8bfe\u7a0b\u7b14\u8bb02-\u66f2\u9762\u4e0e\u66f2\u7387",title:"DDG\u8bfe\u7a0b\u7b14\u8bb02-\u66f2\u9762\u4e0e\u66f2\u7387",description:"\u66f2\u9762\u4e0a\u7684\u66f2\u7387",section:"Posts",handler:()=>{window.location.href="/blog/2021/DDG-NOTES-2/"}},{id:"post-ddg\u8bfe\u7a0b\u7b14\u8bb01-\u5916\u4ee3\u6570\u4e0e\u5916\u5fae\u5206",title:"DDG\u8bfe\u7a0b\u7b14\u8bb01-\u5916\u4ee3\u6570\u4e0e\u5916\u5fae\u5206",description:"\u5916\u4ee3\u6570\u4e0e\u5916\u5fae\u5206\u57fa\u7840",section:"Posts",handler:()=>{window.location.href="/blog/2021/DDG-NOTES-1/"}},{id:"post-a-post-with-diagrams",title:"a post with diagrams",description:"an example of a blog post with diagrams",section:"Posts",handler:()=>{window.location.href="/blog/2021/diagrams/"}},{id:"post-a-distill-style-blog-post",title:"a distill-style blog post",description:"an example of a distill-style blog post and main elements",section:"Posts",handler:()=>{window.location.href="/blog/2021/distill/"}},{id:"post-a-post-with-github-metadata",title:"a post with github metadata",description:"a quick run down on accessing github metadata.",section:"Posts",handler:()=>{window.location.href="/blog/2020/github-metadata/"}},{id:"post-a-post-with-twitter",title:"a post with twitter",description:"an example of a blog post with twitter",section:"Posts",handler:()=>{window.location.href="/blog/2020/twitter/"}},{id:"post-a-post-with-disqus-comments",title:"a post with disqus comments",description:"an example of a blog post with disqus comments",section:"Posts",handler:()=>{window.location.href="/blog/2015/disqus-comments/"}},{id:"post-a-post-with-math",title:"a post with math",description:"an example of a blog post with some math",section:"Posts",handler:()=>{window.location.href="/blog/2015/math/"}},{id:"post-a-post-with-code",title:"a post with code",description:"an example of a blog post with some code",section:"Posts",handler:()=>{window.location.href="/blog/2015/code/"}},{id:"post-a-post-with-images",title:"a post with images",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2015/images/"}},{id:"post-a-post-with-formatting-and-links",title:"a post with formatting and links",description:"march & april, looking forward to summer",section:"Posts",handler:()=>{window.location.href="/blog/2015/formatting-and-links/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-games103-labs",title:"GAMES103 Labs",description:"Homeworks in GAMES 103: Intro to Physics Based Animation.",section:"Projects",handler:()=>{window.location.href="/projects/GAMES103/"}},{id:"projects-nerf-project",title:"NeRF Project",description:"Course project in CS 7643: Deep Learning. We implemented NeRF from scratch.",section:"Projects",handler:()=>{window.location.href="/projects/NeRF_Project/"}},{id:"projects-shape-analysis-homeworks",title:"Shape Analysis Homeworks",description:"Homeworks in MIT 6.838: Shape Analysis.",section:"Projects",handler:()=>{window.location.href="/projects/ShapeAnalysis/"}},{id:"projects-ai4r-projects",title:"AI4R Projects",description:"Course project in CS 7638: Artificial Intelligence for Robotics.",section:"Projects",handler:()=>{window.location.href="/projects/CS7638/"}},{id:"projects-games301-homeworks",title:"GAMES301 Homeworks",description:"Homeworks in GAMES 301: Surface Parameterization.",section:"Projects",handler:()=>{window.location.href="/projects/GAMES301/"}},{id:"projects-lbm-fluid-simulator",title:"LBM Fluid Simulator",description:"A real-time fluid simulator implemented with NVIDIA Warp.",section:"Projects",handler:()=>{window.location.href="/projects/LBM/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%62%70%31%36%35%37@%6E%79%75.%65%64%75","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/peng00bo00","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/bo-peng-9600a4175","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>